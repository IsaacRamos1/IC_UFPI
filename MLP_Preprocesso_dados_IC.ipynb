{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3a478219",
   "metadata": {
    "id": "b3ae055c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bab67c0b",
   "metadata": {
    "id": "bab67c0b"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('allvixm-val-data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dd09a967",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "dd09a967",
    "outputId": "71e3e304-31ba-416b-902a-cd0284250075",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>donor_id</th>\n",
       "      <th>donor_hla</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>patient_cpra</th>\n",
       "      <th>patient_hla</th>\n",
       "      <th>patient_single_cl1</th>\n",
       "      <th>patient_single_cl2</th>\n",
       "      <th>patient_mixed_cl1</th>\n",
       "      <th>patient_mixed_cl2</th>\n",
       "      <th>epv_result</th>\n",
       "      <th>cdc_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>558716</td>\n",
       "      <td>308155-126</td>\n",
       "      <td>A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...</td>\n",
       "      <td>71334-2660</td>\n",
       "      <td>91</td>\n",
       "      <td>A*29:02,A*30:02,B*51:01,B*58:01,DRB1*13:01,DRB...</td>\n",
       "      <td>A*01:01,A*02:01,A*02:03,A*02:06,A*11:01,A*11:0...</td>\n",
       "      <td>DPB1*01:01,DPB1*05:01,DPB1*03:01,DPB1*06:01,DP...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>558658</td>\n",
       "      <td>308155-126</td>\n",
       "      <td>A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...</td>\n",
       "      <td>205670-2660</td>\n",
       "      <td>75</td>\n",
       "      <td>A*02:01,A*02:01,B*15:16,B*40:04,DRB1*07:01,DRB...</td>\n",
       "      <td>A*01:01,A*23:01,A*24:02,A*24:03,A*80:01</td>\n",
       "      <td>DRB1*13:03,DRB1*12:02,DRB1*14:54,DRB1*14:01,DR...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>558657</td>\n",
       "      <td>308155-126</td>\n",
       "      <td>A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...</td>\n",
       "      <td>233572-2660</td>\n",
       "      <td>18</td>\n",
       "      <td>A*03:01,A*23:01,B*07:02,B*07:05,DRB1*07:01,DRB...</td>\n",
       "      <td>B*35:01,B*51:01,B*53:01,B*78:01</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>558656</td>\n",
       "      <td>308155-126</td>\n",
       "      <td>A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...</td>\n",
       "      <td>235844-2660</td>\n",
       "      <td>0</td>\n",
       "      <td>A*02:01,A*30:02,B*35:01,B*45:01,DRB1*07:01,DRB...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>558655</td>\n",
       "      <td>308155-126</td>\n",
       "      <td>A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...</td>\n",
       "      <td>242776-2660</td>\n",
       "      <td>0</td>\n",
       "      <td>A*03:01,A*23:01,B*35:01,B*45:01,DRB1*01:01,DRB...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>558654</td>\n",
       "      <td>308155-126</td>\n",
       "      <td>A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...</td>\n",
       "      <td>235944-2660</td>\n",
       "      <td>49</td>\n",
       "      <td>A*02:01,A*74:01,B*35:01,B*50:01,DRB1*07:01,DRB...</td>\n",
       "      <td>A*23:01,A*24:02,A*24:03,A*25:01,A*29:01,B*27:0...</td>\n",
       "      <td>DRB1*03:01,DRB1*03:02,DRB1*08:01,DRB1*11:01,DR...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>558653</td>\n",
       "      <td>308155-126</td>\n",
       "      <td>A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...</td>\n",
       "      <td>234324-2660</td>\n",
       "      <td>0</td>\n",
       "      <td>A*29:02,A*68:01,B*35:01,B*35:01,DRB1*07:01,DRB...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>558652</td>\n",
       "      <td>308155-126</td>\n",
       "      <td>A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...</td>\n",
       "      <td>237374-2660</td>\n",
       "      <td>0</td>\n",
       "      <td>A*02:01,A*30:02,B*07:02,B*44:02,DRB1*07:01,DRB...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>558651</td>\n",
       "      <td>308155-126</td>\n",
       "      <td>A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...</td>\n",
       "      <td>213948-2660</td>\n",
       "      <td>6</td>\n",
       "      <td>A*02:01,A*23:01,B*41:01,B*44:03,DRB1*07:01,DRB...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>558649</td>\n",
       "      <td>308155-126</td>\n",
       "      <td>A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...</td>\n",
       "      <td>217269-2660</td>\n",
       "      <td>0</td>\n",
       "      <td>A*24:02,A*29:02,B*44:03,B*50:01,DRB1*07:01,DRB...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    donor_id                                          donor_hla  \\\n",
       "0  558716  308155-126  A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...   \n",
       "1  558658  308155-126  A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...   \n",
       "2  558657  308155-126  A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...   \n",
       "3  558656  308155-126  A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...   \n",
       "4  558655  308155-126  A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...   \n",
       "5  558654  308155-126  A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...   \n",
       "6  558653  308155-126  A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...   \n",
       "7  558652  308155-126  A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...   \n",
       "8  558651  308155-126  A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...   \n",
       "9  558649  308155-126  A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...   \n",
       "\n",
       "    patient_id  patient_cpra  \\\n",
       "0   71334-2660            91   \n",
       "1  205670-2660            75   \n",
       "2  233572-2660            18   \n",
       "3  235844-2660             0   \n",
       "4  242776-2660             0   \n",
       "5  235944-2660            49   \n",
       "6  234324-2660             0   \n",
       "7  237374-2660             0   \n",
       "8  213948-2660             6   \n",
       "9  217269-2660             0   \n",
       "\n",
       "                                         patient_hla  \\\n",
       "0  A*29:02,A*30:02,B*51:01,B*58:01,DRB1*13:01,DRB...   \n",
       "1  A*02:01,A*02:01,B*15:16,B*40:04,DRB1*07:01,DRB...   \n",
       "2  A*03:01,A*23:01,B*07:02,B*07:05,DRB1*07:01,DRB...   \n",
       "3  A*02:01,A*30:02,B*35:01,B*45:01,DRB1*07:01,DRB...   \n",
       "4  A*03:01,A*23:01,B*35:01,B*45:01,DRB1*01:01,DRB...   \n",
       "5  A*02:01,A*74:01,B*35:01,B*50:01,DRB1*07:01,DRB...   \n",
       "6  A*29:02,A*68:01,B*35:01,B*35:01,DRB1*07:01,DRB...   \n",
       "7  A*02:01,A*30:02,B*07:02,B*44:02,DRB1*07:01,DRB...   \n",
       "8  A*02:01,A*23:01,B*41:01,B*44:03,DRB1*07:01,DRB...   \n",
       "9  A*24:02,A*29:02,B*44:03,B*50:01,DRB1*07:01,DRB...   \n",
       "\n",
       "                                  patient_single_cl1  \\\n",
       "0  A*01:01,A*02:01,A*02:03,A*02:06,A*11:01,A*11:0...   \n",
       "1            A*01:01,A*23:01,A*24:02,A*24:03,A*80:01   \n",
       "2                    B*35:01,B*51:01,B*53:01,B*78:01   \n",
       "3                                                  -   \n",
       "4                                                  -   \n",
       "5  A*23:01,A*24:02,A*24:03,A*25:01,A*29:01,B*27:0...   \n",
       "6                                                  -   \n",
       "7                                                  -   \n",
       "8                                                NaN   \n",
       "9                                                  -   \n",
       "\n",
       "                                  patient_single_cl2 patient_mixed_cl1  \\\n",
       "0  DPB1*01:01,DPB1*05:01,DPB1*03:01,DPB1*06:01,DP...                 1   \n",
       "1  DRB1*13:03,DRB1*12:02,DRB1*14:54,DRB1*14:01,DR...                 -   \n",
       "2                                                  -                 1   \n",
       "3                                                  -                 0   \n",
       "4                                                  -                 0   \n",
       "5  DRB1*03:01,DRB1*03:02,DRB1*08:01,DRB1*11:01,DR...                 -   \n",
       "6                                                  -                 0   \n",
       "7                                                  -                 0   \n",
       "8                                                  -                 1   \n",
       "9                                                  -                 0   \n",
       "\n",
       "  patient_mixed_cl2 epv_result  cdc_result  \n",
       "0                 1          0           0  \n",
       "1                 -          1           0  \n",
       "2                 0          1           1  \n",
       "3                 0          -           0  \n",
       "4                 0          -           0  \n",
       "5                 -          1           1  \n",
       "6                 0          -           0  \n",
       "7                 0          -           0  \n",
       "8                 0          0           0  \n",
       "9                 0          -           0  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2e4ecbf0",
   "metadata": {
    "id": "2e4ecbf0"
   },
   "outputs": [],
   "source": [
    "def classificarColuna(nome):\n",
    "    data_array = [] ## array para pegar todas os dados diferentes da coluna\n",
    "    dict_dif_data = {} ## dict para classificar os 196 diferentes\n",
    "\n",
    "    for x in df[nome]:\n",
    "        if x not in data_array:\n",
    "            if x == 'NaN':\n",
    "                continue\n",
    "            else:\n",
    "                data_array.append(x)\n",
    "                \n",
    "    print(len(data_array))\n",
    "    \n",
    "    count = 0\n",
    "    for x in data_array:\n",
    "        dict_dif_data[x] = count\n",
    "        count += 1\n",
    "    \n",
    "    for x in range(len(df[nome])):\n",
    "        if str(dict_dif_data[df[nome][x]]) == 'nan':\n",
    "            continue\n",
    "        else:\n",
    "            df[nome][x] = str(dict_dif_data[df[nome][x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2318ca7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2318ca7d",
    "outputId": "d89784e6-2979-4f84-ff7c-f19557062208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n",
      "146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isac_\\anaconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "classificarColuna('patient_single_cl1')\n",
    "classificarColuna('patient_single_cl2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9ab6d760",
   "metadata": {
    "id": "9ab6d760"
   },
   "outputs": [],
   "source": [
    "df_mod = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2ec27436",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "2ec27436",
    "outputId": "f5248ee3-3d2f-4a69-9e58-b2f1ba19541a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>donor_id</th>\n",
       "      <th>donor_hla</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>patient_cpra</th>\n",
       "      <th>patient_hla</th>\n",
       "      <th>patient_single_cl1</th>\n",
       "      <th>patient_single_cl2</th>\n",
       "      <th>patient_mixed_cl1</th>\n",
       "      <th>patient_mixed_cl2</th>\n",
       "      <th>epv_result</th>\n",
       "      <th>cdc_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>558716</td>\n",
       "      <td>308155-126</td>\n",
       "      <td>A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...</td>\n",
       "      <td>71334-2660</td>\n",
       "      <td>91</td>\n",
       "      <td>A*29:02,A*30:02,B*51:01,B*58:01,DRB1*13:01,DRB...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>558658</td>\n",
       "      <td>308155-126</td>\n",
       "      <td>A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...</td>\n",
       "      <td>205670-2660</td>\n",
       "      <td>75</td>\n",
       "      <td>A*02:01,A*02:01,B*15:16,B*40:04,DRB1*07:01,DRB...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>558657</td>\n",
       "      <td>308155-126</td>\n",
       "      <td>A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...</td>\n",
       "      <td>233572-2660</td>\n",
       "      <td>18</td>\n",
       "      <td>A*03:01,A*23:01,B*07:02,B*07:05,DRB1*07:01,DRB...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>558656</td>\n",
       "      <td>308155-126</td>\n",
       "      <td>A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...</td>\n",
       "      <td>235844-2660</td>\n",
       "      <td>0</td>\n",
       "      <td>A*02:01,A*30:02,B*35:01,B*45:01,DRB1*07:01,DRB...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>558655</td>\n",
       "      <td>308155-126</td>\n",
       "      <td>A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...</td>\n",
       "      <td>242776-2660</td>\n",
       "      <td>0</td>\n",
       "      <td>A*03:01,A*23:01,B*35:01,B*45:01,DRB1*01:01,DRB...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    donor_id                                          donor_hla  \\\n",
       "0  558716  308155-126  A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...   \n",
       "1  558658  308155-126  A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...   \n",
       "2  558657  308155-126  A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...   \n",
       "3  558656  308155-126  A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...   \n",
       "4  558655  308155-126  A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...   \n",
       "\n",
       "    patient_id  patient_cpra  \\\n",
       "0   71334-2660            91   \n",
       "1  205670-2660            75   \n",
       "2  233572-2660            18   \n",
       "3  235844-2660             0   \n",
       "4  242776-2660             0   \n",
       "\n",
       "                                         patient_hla patient_single_cl1  \\\n",
       "0  A*29:02,A*30:02,B*51:01,B*58:01,DRB1*13:01,DRB...                  0   \n",
       "1  A*02:01,A*02:01,B*15:16,B*40:04,DRB1*07:01,DRB...                  1   \n",
       "2  A*03:01,A*23:01,B*07:02,B*07:05,DRB1*07:01,DRB...                  2   \n",
       "3  A*02:01,A*30:02,B*35:01,B*45:01,DRB1*07:01,DRB...                  3   \n",
       "4  A*03:01,A*23:01,B*35:01,B*45:01,DRB1*01:01,DRB...                  3   \n",
       "\n",
       "  patient_single_cl2 patient_mixed_cl1 patient_mixed_cl2 epv_result  \\\n",
       "0                  0                 1                 1          0   \n",
       "1                  1                 -                 -          1   \n",
       "2                  2                 1                 0          1   \n",
       "3                  2                 0                 0          -   \n",
       "4                  2                 0                 0          -   \n",
       "\n",
       "   cdc_result  \n",
       "0           0  \n",
       "1           0  \n",
       "2           1  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "bba2e468",
   "metadata": {
    "id": "bba2e468"
   },
   "outputs": [],
   "source": [
    "def classificarPatientHla():\n",
    "    for j in range(6): ## 6 novas colunas para patient_hla\n",
    "        lista = []\n",
    "        for i in range(len(df_mod['patient_hla'])): ## criação da nova coluna\n",
    "            patient_hla = df_mod['patient_hla'][i].split(',')\n",
    "            lista.append(','.join(patient_hla[j:j+2]))\n",
    "        print(len(lista))\n",
    "        break\n",
    "    return\n",
    "\n",
    "def classificarDonorHla(): # 9 novas colunas para donor_hla\n",
    "    for j in range(9): \n",
    "        lista = []\n",
    "        for i in range(len(df_mod['donor_hla'])): ## criação da nova coluna\n",
    "            donor_hla = df_mod['donor_hla'][i].split(',')\n",
    "            lista.append(','.join(donor_hla[j:j+2]))\n",
    "        print(len(lista))\n",
    "        break\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f410cb05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f410cb05",
    "outputId": "4e1bad83-313d-4afd-e1ca-5d8e06e96c71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "942\n",
      "942\n"
     ]
    }
   ],
   "source": [
    "classificarPatientHla()\n",
    "classificarDonorHla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1c338cda",
   "metadata": {
    "id": "1c338cda"
   },
   "outputs": [],
   "source": [
    "def pares(iterable):\n",
    "    a = iter(iterable)\n",
    "    return zip(a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f1c65f68",
   "metadata": {
    "id": "f1c65f68"
   },
   "outputs": [],
   "source": [
    "for x in range(6):\n",
    "    df_mod['patient_hla'+str(x)] = \" \"\n",
    "    \n",
    "for x in range(9):\n",
    "    df_mod['donor_hla'+str(x)] = \" \"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2944247b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "2944247b",
    "outputId": "e6895231-014b-44b0-a45a-37e7c52385bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>donor_id</th>\n",
       "      <th>donor_hla</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>patient_cpra</th>\n",
       "      <th>patient_hla</th>\n",
       "      <th>patient_single_cl1</th>\n",
       "      <th>patient_single_cl2</th>\n",
       "      <th>patient_mixed_cl1</th>\n",
       "      <th>patient_mixed_cl2</th>\n",
       "      <th>...</th>\n",
       "      <th>patient_hla5</th>\n",
       "      <th>donor_hla0</th>\n",
       "      <th>donor_hla1</th>\n",
       "      <th>donor_hla2</th>\n",
       "      <th>donor_hla3</th>\n",
       "      <th>donor_hla4</th>\n",
       "      <th>donor_hla5</th>\n",
       "      <th>donor_hla6</th>\n",
       "      <th>donor_hla7</th>\n",
       "      <th>donor_hla8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>558716</td>\n",
       "      <td>308155-126</td>\n",
       "      <td>A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...</td>\n",
       "      <td>71334-2660</td>\n",
       "      <td>91</td>\n",
       "      <td>A*29:02,A*30:02,B*51:01,B*58:01,DRB1*13:01,DRB...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>558658</td>\n",
       "      <td>308155-126</td>\n",
       "      <td>A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...</td>\n",
       "      <td>205670-2660</td>\n",
       "      <td>75</td>\n",
       "      <td>A*02:01,A*02:01,B*15:16,B*40:04,DRB1*07:01,DRB...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>558657</td>\n",
       "      <td>308155-126</td>\n",
       "      <td>A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...</td>\n",
       "      <td>233572-2660</td>\n",
       "      <td>18</td>\n",
       "      <td>A*03:01,A*23:01,B*07:02,B*07:05,DRB1*07:01,DRB...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>558656</td>\n",
       "      <td>308155-126</td>\n",
       "      <td>A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...</td>\n",
       "      <td>235844-2660</td>\n",
       "      <td>0</td>\n",
       "      <td>A*02:01,A*30:02,B*35:01,B*45:01,DRB1*07:01,DRB...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>558655</td>\n",
       "      <td>308155-126</td>\n",
       "      <td>A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...</td>\n",
       "      <td>242776-2660</td>\n",
       "      <td>0</td>\n",
       "      <td>A*03:01,A*23:01,B*35:01,B*45:01,DRB1*01:01,DRB...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    donor_id                                          donor_hla  \\\n",
       "0  558716  308155-126  A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...   \n",
       "1  558658  308155-126  A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...   \n",
       "2  558657  308155-126  A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...   \n",
       "3  558656  308155-126  A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...   \n",
       "4  558655  308155-126  A*03:01,A*80:01,B*35:03,B*44:03,CW*04:01,CW*04...   \n",
       "\n",
       "    patient_id  patient_cpra  \\\n",
       "0   71334-2660            91   \n",
       "1  205670-2660            75   \n",
       "2  233572-2660            18   \n",
       "3  235844-2660             0   \n",
       "4  242776-2660             0   \n",
       "\n",
       "                                         patient_hla patient_single_cl1  \\\n",
       "0  A*29:02,A*30:02,B*51:01,B*58:01,DRB1*13:01,DRB...                  0   \n",
       "1  A*02:01,A*02:01,B*15:16,B*40:04,DRB1*07:01,DRB...                  1   \n",
       "2  A*03:01,A*23:01,B*07:02,B*07:05,DRB1*07:01,DRB...                  2   \n",
       "3  A*02:01,A*30:02,B*35:01,B*45:01,DRB1*07:01,DRB...                  3   \n",
       "4  A*03:01,A*23:01,B*35:01,B*45:01,DRB1*01:01,DRB...                  3   \n",
       "\n",
       "  patient_single_cl2 patient_mixed_cl1 patient_mixed_cl2  ... patient_hla5  \\\n",
       "0                  0                 1                 1  ...                \n",
       "1                  1                 -                 -  ...                \n",
       "2                  2                 1                 0  ...                \n",
       "3                  2                 0                 0  ...                \n",
       "4                  2                 0                 0  ...                \n",
       "\n",
       "   donor_hla0 donor_hla1 donor_hla2 donor_hla3 donor_hla4 donor_hla5  \\\n",
       "0                                                                      \n",
       "1                                                                      \n",
       "2                                                                      \n",
       "3                                                                      \n",
       "4                                                                      \n",
       "\n",
       "  donor_hla6 donor_hla7 donor_hla8  \n",
       "0                                   \n",
       "1                                   \n",
       "2                                   \n",
       "3                                   \n",
       "4                                   \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6a289ce7",
   "metadata": {
    "id": "6a289ce7"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f88756ec",
   "metadata": {
    "id": "f88756ec"
   },
   "outputs": [],
   "source": [
    "def dividir_patient_hla(j):\n",
    "    transform = []\n",
    "    for i in range(len(df_mod)):\n",
    "        patient_hla = df_mod['patient_hla'][i].split(\",\")\n",
    "        \n",
    "        if len(patient_hla) < 12:\n",
    "            for z in range(12 - len(patient_hla)):\n",
    "                patient_hla.append(\"-\")\n",
    "                \n",
    "        for x, y in pares(patient_hla):\n",
    "            transform.append([x,y])\n",
    "            \n",
    "        df_mod['patient_hla'+str(j)][i] = ','.join(transform[j])\n",
    "        transform = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "cc60339f",
   "metadata": {
    "id": "cc60339f"
   },
   "outputs": [],
   "source": [
    "def dividir_donor_hla(j):\n",
    "    transform = []\n",
    "    for i in range(len(df_mod)):\n",
    "        donor_hla = df_mod['donor_hla'][i].split(\",\")\n",
    "        \n",
    "        if len(donor_hla) < 18:\n",
    "            for z in range(18 - len(donor_hla)):\n",
    "                donor_hla.append(\"-\")\n",
    "                \n",
    "        for x, y in pares(donor_hla):\n",
    "            transform.append([x,y])\n",
    "            \n",
    "        df_mod['donor_hla'+str(j)][i] = ','.join(transform[j])\n",
    "        transform = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "782ff51e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "782ff51e",
    "outputId": "92df4f48-3f13-43b1-feed-f16583ca3c77"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isac_\\anaconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(6): # vai de 0 a 5\n",
    "    dividir_patient_hla(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2884f2ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2884f2ef",
    "outputId": "ab20def3-3a70-4b8d-fc89-08c80b3a4728"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isac_\\anaconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(9): # vai de 0 a 8\n",
    "    dividir_donor_hla(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0bbb2120",
   "metadata": {
    "id": "0bbb2120"
   },
   "outputs": [],
   "source": [
    "df_mod.drop('id', inplace=True, axis=1)\n",
    "df_mod.drop('donor_id', inplace=True, axis=1)\n",
    "df_mod.drop('patient_id', inplace=True, axis=1)\n",
    "df_mod.drop('patient_cpra', inplace=True, axis=1)\n",
    "df_mod.drop('patient_hla', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "02fc978f",
   "metadata": {
    "id": "02fc978f"
   },
   "outputs": [],
   "source": [
    "df['patient_hla0'] = df['patient_hla0'].str.replace(',','/')\n",
    "df['patient_hla1'] = df['patient_hla1'].str.replace(',','/')\n",
    "df['patient_hla2'] = df['patient_hla2'].str.replace(',','/')\n",
    "df['patient_hla3'] = df['patient_hla3'].str.replace(',','/')\n",
    "df['patient_hla4'] = df['patient_hla4'].str.replace(',','/')\n",
    "df['patient_hla5'] = df['patient_hla5'].str.replace(',','/')\n",
    "\n",
    "for i in range(9):\n",
    "    df['donor_hla'+str(i)] = df['donor_hla'+str(i)].str.replace(',','/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "05b8217a",
   "metadata": {
    "id": "05b8217a"
   },
   "outputs": [],
   "source": [
    "df_mod.drop('donor_hla', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4f485d21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "4f485d21",
    "outputId": "d7c75138-8635-46ef-d5f4-169aed3d83a3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_single_cl1</th>\n",
       "      <th>patient_single_cl2</th>\n",
       "      <th>patient_mixed_cl1</th>\n",
       "      <th>patient_mixed_cl2</th>\n",
       "      <th>epv_result</th>\n",
       "      <th>cdc_result</th>\n",
       "      <th>patient_hla0</th>\n",
       "      <th>patient_hla1</th>\n",
       "      <th>patient_hla2</th>\n",
       "      <th>patient_hla3</th>\n",
       "      <th>...</th>\n",
       "      <th>patient_hla5</th>\n",
       "      <th>donor_hla0</th>\n",
       "      <th>donor_hla1</th>\n",
       "      <th>donor_hla2</th>\n",
       "      <th>donor_hla3</th>\n",
       "      <th>donor_hla4</th>\n",
       "      <th>donor_hla5</th>\n",
       "      <th>donor_hla6</th>\n",
       "      <th>donor_hla7</th>\n",
       "      <th>donor_hla8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A*29:02/A*30:02</td>\n",
       "      <td>B*51:01/B*58:01</td>\n",
       "      <td>DRB1*13:01/DRB1*15:01</td>\n",
       "      <td>DRB3*01:01/DRB5*01:01</td>\n",
       "      <td>...</td>\n",
       "      <td>DQB1*06:03/DQB1*06:02</td>\n",
       "      <td>A*03:01/A*80:01</td>\n",
       "      <td>B*35:03/B*44:03</td>\n",
       "      <td>CW*04:01/CW*04:01</td>\n",
       "      <td>DRB1*07:01/DRB1*15:01</td>\n",
       "      <td>DRB4*01:01/DRB5*01:01</td>\n",
       "      <td>DQA1*01:02/DQA1*02:01</td>\n",
       "      <td>DQB1*02:02/DQB1*06:02</td>\n",
       "      <td>DPA1*01:03/DPA1*01:03</td>\n",
       "      <td>DPB1*02:01/DPB1*13:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A*02:01/A*02:01</td>\n",
       "      <td>B*15:16/B*40:04</td>\n",
       "      <td>DRB1*07:01/DRB1*15:01</td>\n",
       "      <td>DRB4*01:01/DRB5*01:01</td>\n",
       "      <td>...</td>\n",
       "      <td>DQB1*02:02/DQB1*06:02</td>\n",
       "      <td>A*03:01/A*80:01</td>\n",
       "      <td>B*35:03/B*44:03</td>\n",
       "      <td>CW*04:01/CW*04:01</td>\n",
       "      <td>DRB1*07:01/DRB1*15:01</td>\n",
       "      <td>DRB4*01:01/DRB5*01:01</td>\n",
       "      <td>DQA1*01:02/DQA1*02:01</td>\n",
       "      <td>DQB1*02:02/DQB1*06:02</td>\n",
       "      <td>DPA1*01:03/DPA1*01:03</td>\n",
       "      <td>DPB1*02:01/DPB1*13:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A*03:01/A*23:01</td>\n",
       "      <td>B*07:02/B*07:05</td>\n",
       "      <td>DRB1*07:01/DRB1*15:03</td>\n",
       "      <td>DRB4*01:01/DRB5*01:01</td>\n",
       "      <td>...</td>\n",
       "      <td>DQB1*02:02/DQB1*06:02</td>\n",
       "      <td>A*03:01/A*80:01</td>\n",
       "      <td>B*35:03/B*44:03</td>\n",
       "      <td>CW*04:01/CW*04:01</td>\n",
       "      <td>DRB1*07:01/DRB1*15:01</td>\n",
       "      <td>DRB4*01:01/DRB5*01:01</td>\n",
       "      <td>DQA1*01:02/DQA1*02:01</td>\n",
       "      <td>DQB1*02:02/DQB1*06:02</td>\n",
       "      <td>DPA1*01:03/DPA1*01:03</td>\n",
       "      <td>DPB1*02:01/DPB1*13:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>A*02:01/A*30:02</td>\n",
       "      <td>B*35:01/B*45:01</td>\n",
       "      <td>DRB1*07:01/DRB1*13:01</td>\n",
       "      <td>DRB3*01:01/DRB4*01:01</td>\n",
       "      <td>...</td>\n",
       "      <td>DQB1*02:02/DQB1*06:03</td>\n",
       "      <td>A*03:01/A*80:01</td>\n",
       "      <td>B*35:03/B*44:03</td>\n",
       "      <td>CW*04:01/CW*04:01</td>\n",
       "      <td>DRB1*07:01/DRB1*15:01</td>\n",
       "      <td>DRB4*01:01/DRB5*01:01</td>\n",
       "      <td>DQA1*01:02/DQA1*02:01</td>\n",
       "      <td>DQB1*02:02/DQB1*06:02</td>\n",
       "      <td>DPA1*01:03/DPA1*01:03</td>\n",
       "      <td>DPB1*02:01/DPB1*13:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>A*03:01/A*23:01</td>\n",
       "      <td>B*35:01/B*45:01</td>\n",
       "      <td>DRB1*01:01/DRB1*15:01</td>\n",
       "      <td>DRB5*01:01/DQA1*01:01</td>\n",
       "      <td>...</td>\n",
       "      <td>DQB1*06:02/-</td>\n",
       "      <td>A*03:01/A*80:01</td>\n",
       "      <td>B*35:03/B*44:03</td>\n",
       "      <td>CW*04:01/CW*04:01</td>\n",
       "      <td>DRB1*07:01/DRB1*15:01</td>\n",
       "      <td>DRB4*01:01/DRB5*01:01</td>\n",
       "      <td>DQA1*01:02/DQA1*02:01</td>\n",
       "      <td>DQB1*02:02/DQB1*06:02</td>\n",
       "      <td>DPA1*01:03/DPA1*01:03</td>\n",
       "      <td>DPB1*02:01/DPB1*13:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_single_cl1 patient_single_cl2 patient_mixed_cl1 patient_mixed_cl2  \\\n",
       "0                  0                  0                 1                 1   \n",
       "1                  1                  1                 -                 -   \n",
       "2                  2                  2                 1                 0   \n",
       "3                  3                  2                 0                 0   \n",
       "4                  3                  2                 0                 0   \n",
       "\n",
       "  epv_result  cdc_result     patient_hla0     patient_hla1  \\\n",
       "0          0           0  A*29:02/A*30:02  B*51:01/B*58:01   \n",
       "1          1           0  A*02:01/A*02:01  B*15:16/B*40:04   \n",
       "2          1           1  A*03:01/A*23:01  B*07:02/B*07:05   \n",
       "3          -           0  A*02:01/A*30:02  B*35:01/B*45:01   \n",
       "4          -           0  A*03:01/A*23:01  B*35:01/B*45:01   \n",
       "\n",
       "            patient_hla2           patient_hla3  ...           patient_hla5  \\\n",
       "0  DRB1*13:01/DRB1*15:01  DRB3*01:01/DRB5*01:01  ...  DQB1*06:03/DQB1*06:02   \n",
       "1  DRB1*07:01/DRB1*15:01  DRB4*01:01/DRB5*01:01  ...  DQB1*02:02/DQB1*06:02   \n",
       "2  DRB1*07:01/DRB1*15:03  DRB4*01:01/DRB5*01:01  ...  DQB1*02:02/DQB1*06:02   \n",
       "3  DRB1*07:01/DRB1*13:01  DRB3*01:01/DRB4*01:01  ...  DQB1*02:02/DQB1*06:03   \n",
       "4  DRB1*01:01/DRB1*15:01  DRB5*01:01/DQA1*01:01  ...           DQB1*06:02/-   \n",
       "\n",
       "        donor_hla0       donor_hla1         donor_hla2             donor_hla3  \\\n",
       "0  A*03:01/A*80:01  B*35:03/B*44:03  CW*04:01/CW*04:01  DRB1*07:01/DRB1*15:01   \n",
       "1  A*03:01/A*80:01  B*35:03/B*44:03  CW*04:01/CW*04:01  DRB1*07:01/DRB1*15:01   \n",
       "2  A*03:01/A*80:01  B*35:03/B*44:03  CW*04:01/CW*04:01  DRB1*07:01/DRB1*15:01   \n",
       "3  A*03:01/A*80:01  B*35:03/B*44:03  CW*04:01/CW*04:01  DRB1*07:01/DRB1*15:01   \n",
       "4  A*03:01/A*80:01  B*35:03/B*44:03  CW*04:01/CW*04:01  DRB1*07:01/DRB1*15:01   \n",
       "\n",
       "              donor_hla4             donor_hla5             donor_hla6  \\\n",
       "0  DRB4*01:01/DRB5*01:01  DQA1*01:02/DQA1*02:01  DQB1*02:02/DQB1*06:02   \n",
       "1  DRB4*01:01/DRB5*01:01  DQA1*01:02/DQA1*02:01  DQB1*02:02/DQB1*06:02   \n",
       "2  DRB4*01:01/DRB5*01:01  DQA1*01:02/DQA1*02:01  DQB1*02:02/DQB1*06:02   \n",
       "3  DRB4*01:01/DRB5*01:01  DQA1*01:02/DQA1*02:01  DQB1*02:02/DQB1*06:02   \n",
       "4  DRB4*01:01/DRB5*01:01  DQA1*01:02/DQA1*02:01  DQB1*02:02/DQB1*06:02   \n",
       "\n",
       "              donor_hla7             donor_hla8  \n",
       "0  DPA1*01:03/DPA1*01:03  DPB1*02:01/DPB1*13:01  \n",
       "1  DPA1*01:03/DPA1*01:03  DPB1*02:01/DPB1*13:01  \n",
       "2  DPA1*01:03/DPA1*01:03  DPB1*02:01/DPB1*13:01  \n",
       "3  DPA1*01:03/DPA1*01:03  DPB1*02:01/DPB1*13:01  \n",
       "4  DPA1*01:03/DPA1*01:03  DPB1*02:01/DPB1*13:01  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c577c7d5",
   "metadata": {
    "id": "c577c7d5"
   },
   "outputs": [],
   "source": [
    "df_mod = df_mod[['donor_hla0', 'donor_hla1', 'donor_hla2', 'donor_hla3', 'donor_hla4', 'donor_hla5', 'donor_hla6','donor_hla7','donor_hla8','patient_single_cl1', 'patient_single_cl2', 'patient_mixed_cl1', 'patient_mixed_cl2',\n",
    "                'epv_result', 'patient_hla0', 'patient_hla1', 'patient_hla2', 'patient_hla3', 'patient_hla4', 'patient_hla5',\n",
    "                'cdc_result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5cd794b6",
   "metadata": {
    "id": "5cd794b6"
   },
   "outputs": [],
   "source": [
    "def classificarColunaDfMod(nome):\n",
    "    data_array = []\n",
    "    dict_dif_data = {}\n",
    "\n",
    "    for x in df_mod[nome]:\n",
    "        if x not in data_array:\n",
    "            if x == 'NaN':\n",
    "                continue\n",
    "            else:\n",
    "                data_array.append(x)\n",
    "    \n",
    "    count = 0\n",
    "    for x in data_array:\n",
    "        dict_dif_data[x] = count\n",
    "        count += 1\n",
    "    \n",
    "    for x in range(len(df[nome])):\n",
    "        if str(dict_dif_data[df_mod[nome][x]]) == 'nan':\n",
    "            continue\n",
    "        else:\n",
    "            df_mod[nome][x] = str(dict_dif_data[df_mod[nome][x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0d31bfb7",
   "metadata": {
    "id": "0d31bfb7"
   },
   "outputs": [],
   "source": [
    "df_mod = df_mod[df_mod['patient_mixed_cl1'].str.contains(\"-\") == False]\n",
    "df_mod = df_mod[df_mod['patient_mixed_cl2'].str.contains(\"-\") == False]\n",
    "df_mod = df_mod[df_mod['patient_single_cl1'].str.contains(\"-\") == False]\n",
    "df_mod = df_mod[df_mod['patient_single_cl2'].str.contains(\"-\") == False]\n",
    "df_mod = df_mod[df_mod['epv_result'].str.contains(\"-\") == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1c7419df",
   "metadata": {
    "id": "1c7419df"
   },
   "outputs": [],
   "source": [
    "df_mod['patient_single_cl1'] = df_mod['patient_single_cl1'].astype('int64')\n",
    "df_mod['patient_single_cl2'] = df_mod['patient_single_cl2'].astype('int64')\n",
    "df_mod['patient_mixed_cl1'] = df_mod['patient_mixed_cl1'].astype('int64')\n",
    "df_mod['patient_mixed_cl2'] = df_mod['patient_mixed_cl2'].astype('int64')\n",
    "df_mod['epv_result'] = df_mod['epv_result'].astype('int64')\n",
    "df_mod['cdc_result'] = df_mod['cdc_result'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "32d55c7f",
   "metadata": {
    "id": "32d55c7f"
   },
   "outputs": [],
   "source": [
    "def unique(list1):\n",
    "      \n",
    "    # insert the list to the set\n",
    "    list_set = set(df_mod[list1])\n",
    "    # convert the set to the list\n",
    "    unique_list = (list(list_set))\n",
    "    \n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "4569773f",
   "metadata": {
    "id": "4569773f"
   },
   "outputs": [],
   "source": [
    "donor_hla0 = unique('donor_hla0')\n",
    "donor_hla1 = unique('donor_hla1')\n",
    "donor_hla2 = unique('donor_hla2')\n",
    "donor_hla3 = unique('donor_hla3')\n",
    "donor_hla4 = unique('donor_hla4')\n",
    "donor_hla5 = unique('donor_hla5')\n",
    "donor_hla6 = unique('donor_hla6')\n",
    "donor_hla7 = unique('donor_hla7')\n",
    "donor_hla8 = unique('donor_hla8')\n",
    "patient_single_cl1 = unique('patient_single_cl1')\n",
    "patient_single_cl2 = unique('patient_single_cl2')\n",
    "patient_mixed_cl1 = unique('patient_mixed_cl1')\n",
    "patient_mixed_cl2 = unique('patient_mixed_cl2')\n",
    "epv_result = unique('epv_result')\n",
    "cdc_result = unique('cdc_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ce4a3a53",
   "metadata": {
    "id": "ce4a3a53"
   },
   "outputs": [],
   "source": [
    "patient_hla0 = unique('patient_hla0')\n",
    "patient_hla1 = unique('patient_hla1')\n",
    "patient_hla2 = unique('patient_hla2')\n",
    "patient_hla3 = unique('patient_hla3')\n",
    "patient_hla4 = unique('patient_hla4')\n",
    "patient_hla5 = unique('patient_hla5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fcae0d",
   "metadata": {
    "id": "88fcae0d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9f46f7f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "id": "9f46f7f0",
    "outputId": "a3697beb-4459-49de-ea7d-420e4bf6fcc0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>donor_hla0</th>\n",
       "      <th>donor_hla1</th>\n",
       "      <th>donor_hla2</th>\n",
       "      <th>donor_hla3</th>\n",
       "      <th>donor_hla4</th>\n",
       "      <th>donor_hla5</th>\n",
       "      <th>donor_hla6</th>\n",
       "      <th>donor_hla7</th>\n",
       "      <th>donor_hla8</th>\n",
       "      <th>patient_single_cl1</th>\n",
       "      <th>...</th>\n",
       "      <th>patient_mixed_cl1</th>\n",
       "      <th>patient_mixed_cl2</th>\n",
       "      <th>epv_result</th>\n",
       "      <th>patient_hla0</th>\n",
       "      <th>patient_hla1</th>\n",
       "      <th>patient_hla2</th>\n",
       "      <th>patient_hla3</th>\n",
       "      <th>patient_hla4</th>\n",
       "      <th>patient_hla5</th>\n",
       "      <th>cdc_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A*03:01/A*80:01</td>\n",
       "      <td>B*35:03/B*44:03</td>\n",
       "      <td>CW*04:01/CW*04:01</td>\n",
       "      <td>DRB1*07:01/DRB1*15:01</td>\n",
       "      <td>DRB4*01:01/DRB5*01:01</td>\n",
       "      <td>DQA1*01:02/DQA1*02:01</td>\n",
       "      <td>DQB1*02:02/DQB1*06:02</td>\n",
       "      <td>DPA1*01:03/DPA1*01:03</td>\n",
       "      <td>DPB1*02:01/DPB1*13:01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A*29:02/A*30:02</td>\n",
       "      <td>B*51:01/B*58:01</td>\n",
       "      <td>DRB1*13:01/DRB1*15:01</td>\n",
       "      <td>DRB3*01:01/DRB5*01:01</td>\n",
       "      <td>DQA1*01:03/DQA1*01:02</td>\n",
       "      <td>DQB1*06:03/DQB1*06:02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A*03:01/A*80:01</td>\n",
       "      <td>B*35:03/B*44:03</td>\n",
       "      <td>CW*04:01/CW*04:01</td>\n",
       "      <td>DRB1*07:01/DRB1*15:01</td>\n",
       "      <td>DRB4*01:01/DRB5*01:01</td>\n",
       "      <td>DQA1*01:02/DQA1*02:01</td>\n",
       "      <td>DQB1*02:02/DQB1*06:02</td>\n",
       "      <td>DPA1*01:03/DPA1*01:03</td>\n",
       "      <td>DPB1*02:01/DPB1*13:01</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A*03:01/A*23:01</td>\n",
       "      <td>B*07:02/B*07:05</td>\n",
       "      <td>DRB1*07:01/DRB1*15:03</td>\n",
       "      <td>DRB4*01:01/DRB5*01:01</td>\n",
       "      <td>DQA1*02:01/DQA1*01:02</td>\n",
       "      <td>DQB1*02:02/DQB1*06:02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A*03:01/A*80:01</td>\n",
       "      <td>B*35:03/B*44:03</td>\n",
       "      <td>CW*04:01/CW*04:01</td>\n",
       "      <td>DRB1*07:01/DRB1*15:01</td>\n",
       "      <td>DRB4*01:01/DRB5*01:01</td>\n",
       "      <td>DQA1*01:02/DQA1*02:01</td>\n",
       "      <td>DQB1*02:02/DQB1*06:02</td>\n",
       "      <td>DPA1*01:03/DPA1*01:03</td>\n",
       "      <td>DPB1*02:01/DPB1*13:01</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A*02:01/A*23:01</td>\n",
       "      <td>B*41:01/B*44:03</td>\n",
       "      <td>DRB1*07:01/DRB1*15:01</td>\n",
       "      <td>DRB4*01:01/DRB5*01:01</td>\n",
       "      <td>DQA1*02:01/DQA1*01:02</td>\n",
       "      <td>DQB1*02:02/DQB1*06:02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A*31:01/A*31:01</td>\n",
       "      <td>B*15:01/B*35:01</td>\n",
       "      <td>CW*03:03/CW*04:01</td>\n",
       "      <td>DRB1*04:01/DRB1*14:33</td>\n",
       "      <td>DRB4*01:01/DRB4*01:01</td>\n",
       "      <td>DQA1*03:01/DQA1*03:01</td>\n",
       "      <td>DQB1*02:02/DQB1*03:02</td>\n",
       "      <td>DPA1*01:03/DPA1*02:02</td>\n",
       "      <td>DPB1*02:01/DPB1*05:01</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A*30:02/A*68:01</td>\n",
       "      <td>B*18:01/B*35:01</td>\n",
       "      <td>DRB1*08:01/DRB1*14:01</td>\n",
       "      <td>DRB3*02:02/DQA1*04:01</td>\n",
       "      <td>DQA1*01:04/DQB1*04:02</td>\n",
       "      <td>DQB1*05:03/-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A*31:01/A*31:01</td>\n",
       "      <td>B*15:01/B*35:01</td>\n",
       "      <td>CW*03:03/CW*04:01</td>\n",
       "      <td>DRB1*04:01/DRB1*14:33</td>\n",
       "      <td>DRB4*01:01/DRB4*01:01</td>\n",
       "      <td>DQA1*03:01/DQA1*03:01</td>\n",
       "      <td>DQB1*02:02/DQB1*03:02</td>\n",
       "      <td>DPA1*01:03/DPA1*02:02</td>\n",
       "      <td>DPB1*02:01/DPB1*05:01</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A*24:02/A*30:09</td>\n",
       "      <td>B*15:16/B*35:08</td>\n",
       "      <td>DRB1*14:01/DRB1*14:01</td>\n",
       "      <td>DRB3*02:02/DRB3*02:02</td>\n",
       "      <td>DQA1*01:04/DQA1*01:04</td>\n",
       "      <td>DQB1*05:03/DQB1*05:03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A*31:01/A*31:01</td>\n",
       "      <td>B*15:01/B*35:01</td>\n",
       "      <td>CW*03:03/CW*04:01</td>\n",
       "      <td>DRB1*04:01/DRB1*14:33</td>\n",
       "      <td>DRB4*01:01/DRB4*01:01</td>\n",
       "      <td>DQA1*03:01/DQA1*03:01</td>\n",
       "      <td>DQB1*02:02/DQB1*03:02</td>\n",
       "      <td>DPA1*01:03/DPA1*02:02</td>\n",
       "      <td>DPB1*02:01/DPB1*05:01</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A*02:01/A*24:02</td>\n",
       "      <td>B*35:05/B*39:09</td>\n",
       "      <td>DRB1*04:11/DRB1*14:06</td>\n",
       "      <td>DRB3*01:01/DRB4*01:01</td>\n",
       "      <td>DQA1*05:01/DQB1*03:02</td>\n",
       "      <td>DQB1*03:01/-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A*24:02/A*33:01</td>\n",
       "      <td>B*14:02/B*57:01</td>\n",
       "      <td>DRB1*07:01/DRB1*16:03</td>\n",
       "      <td>DRB4*01:01/DQA1*02:01</td>\n",
       "      <td>DQB1*02:02/-</td>\n",
       "      <td>-/-</td>\n",
       "      <td>-/-</td>\n",
       "      <td>-/-</td>\n",
       "      <td>-/-</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A*01:01/A*01:01</td>\n",
       "      <td>B*15:01/B*51:01</td>\n",
       "      <td>DRB1*13:01/DRB1*16:01</td>\n",
       "      <td>DRB3*01:01/DRB5*02:02</td>\n",
       "      <td>DQA1*01:03/DQA1*01:02</td>\n",
       "      <td>DQB1*06:03/DQB1*05:02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A*24:02/A*33:01</td>\n",
       "      <td>B*14:02/B*57:01</td>\n",
       "      <td>DRB1*07:01/DRB1*16:03</td>\n",
       "      <td>DRB4*01:01/DQA1*02:01</td>\n",
       "      <td>DQB1*02:02/-</td>\n",
       "      <td>-/-</td>\n",
       "      <td>-/-</td>\n",
       "      <td>-/-</td>\n",
       "      <td>-/-</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A*03:01/A*26:01</td>\n",
       "      <td>B*07:02/B*08:01</td>\n",
       "      <td>DRB1*13:01/DRB1*16:02</td>\n",
       "      <td>DRB3*01:01/DRB5*02:02</td>\n",
       "      <td>DQA1*01:03/DQA1*05:01</td>\n",
       "      <td>DQB1*06:03/DQB1*03:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A*24:02/A*33:01</td>\n",
       "      <td>B*14:02/B*57:01</td>\n",
       "      <td>DRB1*07:01/DRB1*16:03</td>\n",
       "      <td>DRB4*01:01/DQA1*02:01</td>\n",
       "      <td>DQB1*02:02/-</td>\n",
       "      <td>-/-</td>\n",
       "      <td>-/-</td>\n",
       "      <td>-/-</td>\n",
       "      <td>-/-</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A*30:01/A*68:02</td>\n",
       "      <td>B*07:02/B*15:47</td>\n",
       "      <td>CW*02:02/CW*07:02</td>\n",
       "      <td>DRB1*15:03/DRB1*15:03</td>\n",
       "      <td>DRB5*01:01/DRB5*01:01</td>\n",
       "      <td>DQA1*01:01/DQA1*01:02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A*24:02/A*33:01</td>\n",
       "      <td>B*14:02/B*57:01</td>\n",
       "      <td>DRB1*07:01/DRB1*16:03</td>\n",
       "      <td>DRB4*01:01/DQA1*02:01</td>\n",
       "      <td>DQB1*02:02/-</td>\n",
       "      <td>-/-</td>\n",
       "      <td>-/-</td>\n",
       "      <td>-/-</td>\n",
       "      <td>-/-</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A*23:01/A*68:02</td>\n",
       "      <td>B*14:02/B*44:03</td>\n",
       "      <td>DRB1*07:01/DRB1*11:02</td>\n",
       "      <td>DRB3*02:02/DRB4*01:01</td>\n",
       "      <td>DQA1*02:01/DQA1*05:01</td>\n",
       "      <td>DQB1*02:02/DQB1*03:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         donor_hla0       donor_hla1             donor_hla2  \\\n",
       "0   A*03:01/A*80:01  B*35:03/B*44:03      CW*04:01/CW*04:01   \n",
       "2   A*03:01/A*80:01  B*35:03/B*44:03      CW*04:01/CW*04:01   \n",
       "8   A*03:01/A*80:01  B*35:03/B*44:03      CW*04:01/CW*04:01   \n",
       "13  A*31:01/A*31:01  B*15:01/B*35:01      CW*03:03/CW*04:01   \n",
       "16  A*31:01/A*31:01  B*15:01/B*35:01      CW*03:03/CW*04:01   \n",
       "17  A*31:01/A*31:01  B*15:01/B*35:01      CW*03:03/CW*04:01   \n",
       "18  A*24:02/A*33:01  B*14:02/B*57:01  DRB1*07:01/DRB1*16:03   \n",
       "19  A*24:02/A*33:01  B*14:02/B*57:01  DRB1*07:01/DRB1*16:03   \n",
       "21  A*24:02/A*33:01  B*14:02/B*57:01  DRB1*07:01/DRB1*16:03   \n",
       "26  A*24:02/A*33:01  B*14:02/B*57:01  DRB1*07:01/DRB1*16:03   \n",
       "\n",
       "               donor_hla3             donor_hla4             donor_hla5  \\\n",
       "0   DRB1*07:01/DRB1*15:01  DRB4*01:01/DRB5*01:01  DQA1*01:02/DQA1*02:01   \n",
       "2   DRB1*07:01/DRB1*15:01  DRB4*01:01/DRB5*01:01  DQA1*01:02/DQA1*02:01   \n",
       "8   DRB1*07:01/DRB1*15:01  DRB4*01:01/DRB5*01:01  DQA1*01:02/DQA1*02:01   \n",
       "13  DRB1*04:01/DRB1*14:33  DRB4*01:01/DRB4*01:01  DQA1*03:01/DQA1*03:01   \n",
       "16  DRB1*04:01/DRB1*14:33  DRB4*01:01/DRB4*01:01  DQA1*03:01/DQA1*03:01   \n",
       "17  DRB1*04:01/DRB1*14:33  DRB4*01:01/DRB4*01:01  DQA1*03:01/DQA1*03:01   \n",
       "18  DRB4*01:01/DQA1*02:01           DQB1*02:02/-                    -/-   \n",
       "19  DRB4*01:01/DQA1*02:01           DQB1*02:02/-                    -/-   \n",
       "21  DRB4*01:01/DQA1*02:01           DQB1*02:02/-                    -/-   \n",
       "26  DRB4*01:01/DQA1*02:01           DQB1*02:02/-                    -/-   \n",
       "\n",
       "               donor_hla6             donor_hla7             donor_hla8  \\\n",
       "0   DQB1*02:02/DQB1*06:02  DPA1*01:03/DPA1*01:03  DPB1*02:01/DPB1*13:01   \n",
       "2   DQB1*02:02/DQB1*06:02  DPA1*01:03/DPA1*01:03  DPB1*02:01/DPB1*13:01   \n",
       "8   DQB1*02:02/DQB1*06:02  DPA1*01:03/DPA1*01:03  DPB1*02:01/DPB1*13:01   \n",
       "13  DQB1*02:02/DQB1*03:02  DPA1*01:03/DPA1*02:02  DPB1*02:01/DPB1*05:01   \n",
       "16  DQB1*02:02/DQB1*03:02  DPA1*01:03/DPA1*02:02  DPB1*02:01/DPB1*05:01   \n",
       "17  DQB1*02:02/DQB1*03:02  DPA1*01:03/DPA1*02:02  DPB1*02:01/DPB1*05:01   \n",
       "18                    -/-                    -/-                    -/-   \n",
       "19                    -/-                    -/-                    -/-   \n",
       "21                    -/-                    -/-                    -/-   \n",
       "26                    -/-                    -/-                    -/-   \n",
       "\n",
       "    patient_single_cl1  ...  patient_mixed_cl1  patient_mixed_cl2  epv_result  \\\n",
       "0                    0  ...                  1                  1           0   \n",
       "2                    2  ...                  1                  0           1   \n",
       "8                    5  ...                  1                  0           0   \n",
       "13                   6  ...                  1                  1           1   \n",
       "16                   8  ...                  1                  1           0   \n",
       "17                   9  ...                  1                  1           0   \n",
       "18                   5  ...                  1                  1           0   \n",
       "19                  10  ...                  1                  0           0   \n",
       "21                  11  ...                  1                  1           1   \n",
       "26                  12  ...                  1                  1           1   \n",
       "\n",
       "       patient_hla0     patient_hla1           patient_hla2  \\\n",
       "0   A*29:02/A*30:02  B*51:01/B*58:01  DRB1*13:01/DRB1*15:01   \n",
       "2   A*03:01/A*23:01  B*07:02/B*07:05  DRB1*07:01/DRB1*15:03   \n",
       "8   A*02:01/A*23:01  B*41:01/B*44:03  DRB1*07:01/DRB1*15:01   \n",
       "13  A*30:02/A*68:01  B*18:01/B*35:01  DRB1*08:01/DRB1*14:01   \n",
       "16  A*24:02/A*30:09  B*15:16/B*35:08  DRB1*14:01/DRB1*14:01   \n",
       "17  A*02:01/A*24:02  B*35:05/B*39:09  DRB1*04:11/DRB1*14:06   \n",
       "18  A*01:01/A*01:01  B*15:01/B*51:01  DRB1*13:01/DRB1*16:01   \n",
       "19  A*03:01/A*26:01  B*07:02/B*08:01  DRB1*13:01/DRB1*16:02   \n",
       "21  A*30:01/A*68:02  B*07:02/B*15:47      CW*02:02/CW*07:02   \n",
       "26  A*23:01/A*68:02  B*14:02/B*44:03  DRB1*07:01/DRB1*11:02   \n",
       "\n",
       "             patient_hla3           patient_hla4           patient_hla5  \\\n",
       "0   DRB3*01:01/DRB5*01:01  DQA1*01:03/DQA1*01:02  DQB1*06:03/DQB1*06:02   \n",
       "2   DRB4*01:01/DRB5*01:01  DQA1*02:01/DQA1*01:02  DQB1*02:02/DQB1*06:02   \n",
       "8   DRB4*01:01/DRB5*01:01  DQA1*02:01/DQA1*01:02  DQB1*02:02/DQB1*06:02   \n",
       "13  DRB3*02:02/DQA1*04:01  DQA1*01:04/DQB1*04:02           DQB1*05:03/-   \n",
       "16  DRB3*02:02/DRB3*02:02  DQA1*01:04/DQA1*01:04  DQB1*05:03/DQB1*05:03   \n",
       "17  DRB3*01:01/DRB4*01:01  DQA1*05:01/DQB1*03:02           DQB1*03:01/-   \n",
       "18  DRB3*01:01/DRB5*02:02  DQA1*01:03/DQA1*01:02  DQB1*06:03/DQB1*05:02   \n",
       "19  DRB3*01:01/DRB5*02:02  DQA1*01:03/DQA1*05:01  DQB1*06:03/DQB1*03:01   \n",
       "21  DRB1*15:03/DRB1*15:03  DRB5*01:01/DRB5*01:01  DQA1*01:01/DQA1*01:02   \n",
       "26  DRB3*02:02/DRB4*01:01  DQA1*02:01/DQA1*05:01  DQB1*02:02/DQB1*03:01   \n",
       "\n",
       "   cdc_result  \n",
       "0           0  \n",
       "2           1  \n",
       "8           0  \n",
       "13          0  \n",
       "16          0  \n",
       "17          0  \n",
       "18          0  \n",
       "19          0  \n",
       "21          0  \n",
       "26          0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mod.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "599c9962",
   "metadata": {
    "id": "599c9962"
   },
   "outputs": [],
   "source": [
    "#temp_df = []\n",
    "#for row in df_mod.itertuples(index=False):\n",
    "#    if row.cdc_result:\n",
    "#        temp_df.extend([list(row)]*2) ## duplicar/triplicar o número de linhas com 1 para rearranjar o data frame\n",
    "#    else:\n",
    "#        temp_df.append(list(row))\n",
    "\n",
    "#df_mod = pd.DataFrame(temp_df, columns=df_mod.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c5398439",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "c5398439",
    "outputId": "3859610d-f638-4230-bcf8-54d5e6fec09b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>donor_hla0</th>\n",
       "      <th>donor_hla1</th>\n",
       "      <th>donor_hla2</th>\n",
       "      <th>donor_hla3</th>\n",
       "      <th>donor_hla4</th>\n",
       "      <th>donor_hla5</th>\n",
       "      <th>donor_hla6</th>\n",
       "      <th>donor_hla7</th>\n",
       "      <th>donor_hla8</th>\n",
       "      <th>patient_single_cl1</th>\n",
       "      <th>...</th>\n",
       "      <th>patient_mixed_cl1</th>\n",
       "      <th>patient_mixed_cl2</th>\n",
       "      <th>epv_result</th>\n",
       "      <th>patient_hla0</th>\n",
       "      <th>patient_hla1</th>\n",
       "      <th>patient_hla2</th>\n",
       "      <th>patient_hla3</th>\n",
       "      <th>patient_hla4</th>\n",
       "      <th>patient_hla5</th>\n",
       "      <th>cdc_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A*03:01/A*80:01</td>\n",
       "      <td>B*35:03/B*44:03</td>\n",
       "      <td>CW*04:01/CW*04:01</td>\n",
       "      <td>DRB1*07:01/DRB1*15:01</td>\n",
       "      <td>DRB4*01:01/DRB5*01:01</td>\n",
       "      <td>DQA1*01:02/DQA1*02:01</td>\n",
       "      <td>DQB1*02:02/DQB1*06:02</td>\n",
       "      <td>DPA1*01:03/DPA1*01:03</td>\n",
       "      <td>DPB1*02:01/DPB1*13:01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A*29:02/A*30:02</td>\n",
       "      <td>B*51:01/B*58:01</td>\n",
       "      <td>DRB1*13:01/DRB1*15:01</td>\n",
       "      <td>DRB3*01:01/DRB5*01:01</td>\n",
       "      <td>DQA1*01:03/DQA1*01:02</td>\n",
       "      <td>DQB1*06:03/DQB1*06:02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A*03:01/A*80:01</td>\n",
       "      <td>B*35:03/B*44:03</td>\n",
       "      <td>CW*04:01/CW*04:01</td>\n",
       "      <td>DRB1*07:01/DRB1*15:01</td>\n",
       "      <td>DRB4*01:01/DRB5*01:01</td>\n",
       "      <td>DQA1*01:02/DQA1*02:01</td>\n",
       "      <td>DQB1*02:02/DQB1*06:02</td>\n",
       "      <td>DPA1*01:03/DPA1*01:03</td>\n",
       "      <td>DPB1*02:01/DPB1*13:01</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A*03:01/A*23:01</td>\n",
       "      <td>B*07:02/B*07:05</td>\n",
       "      <td>DRB1*07:01/DRB1*15:03</td>\n",
       "      <td>DRB4*01:01/DRB5*01:01</td>\n",
       "      <td>DQA1*02:01/DQA1*01:02</td>\n",
       "      <td>DQB1*02:02/DQB1*06:02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A*03:01/A*80:01</td>\n",
       "      <td>B*35:03/B*44:03</td>\n",
       "      <td>CW*04:01/CW*04:01</td>\n",
       "      <td>DRB1*07:01/DRB1*15:01</td>\n",
       "      <td>DRB4*01:01/DRB5*01:01</td>\n",
       "      <td>DQA1*01:02/DQA1*02:01</td>\n",
       "      <td>DQB1*02:02/DQB1*06:02</td>\n",
       "      <td>DPA1*01:03/DPA1*01:03</td>\n",
       "      <td>DPB1*02:01/DPB1*13:01</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A*02:01/A*23:01</td>\n",
       "      <td>B*41:01/B*44:03</td>\n",
       "      <td>DRB1*07:01/DRB1*15:01</td>\n",
       "      <td>DRB4*01:01/DRB5*01:01</td>\n",
       "      <td>DQA1*02:01/DQA1*01:02</td>\n",
       "      <td>DQB1*02:02/DQB1*06:02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A*31:01/A*31:01</td>\n",
       "      <td>B*15:01/B*35:01</td>\n",
       "      <td>CW*03:03/CW*04:01</td>\n",
       "      <td>DRB1*04:01/DRB1*14:33</td>\n",
       "      <td>DRB4*01:01/DRB4*01:01</td>\n",
       "      <td>DQA1*03:01/DQA1*03:01</td>\n",
       "      <td>DQB1*02:02/DQB1*03:02</td>\n",
       "      <td>DPA1*01:03/DPA1*02:02</td>\n",
       "      <td>DPB1*02:01/DPB1*05:01</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A*30:02/A*68:01</td>\n",
       "      <td>B*18:01/B*35:01</td>\n",
       "      <td>DRB1*08:01/DRB1*14:01</td>\n",
       "      <td>DRB3*02:02/DQA1*04:01</td>\n",
       "      <td>DQA1*01:04/DQB1*04:02</td>\n",
       "      <td>DQB1*05:03/-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A*31:01/A*31:01</td>\n",
       "      <td>B*15:01/B*35:01</td>\n",
       "      <td>CW*03:03/CW*04:01</td>\n",
       "      <td>DRB1*04:01/DRB1*14:33</td>\n",
       "      <td>DRB4*01:01/DRB4*01:01</td>\n",
       "      <td>DQA1*03:01/DQA1*03:01</td>\n",
       "      <td>DQB1*02:02/DQB1*03:02</td>\n",
       "      <td>DPA1*01:03/DPA1*02:02</td>\n",
       "      <td>DPB1*02:01/DPB1*05:01</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A*24:02/A*30:09</td>\n",
       "      <td>B*15:16/B*35:08</td>\n",
       "      <td>DRB1*14:01/DRB1*14:01</td>\n",
       "      <td>DRB3*02:02/DRB3*02:02</td>\n",
       "      <td>DQA1*01:04/DQA1*01:04</td>\n",
       "      <td>DQB1*05:03/DQB1*05:03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>A*24:02/A*32:01</td>\n",
       "      <td>B*07:02/B*40:02</td>\n",
       "      <td>CW*02:02/CW*07:02</td>\n",
       "      <td>DRB1*04:05/DRB1*15:01</td>\n",
       "      <td>DRB4*01:01/DRB5*01:01</td>\n",
       "      <td>DQA1*01:02/DQA1*03:01</td>\n",
       "      <td>DQB1*03:02/DQB1*06:02</td>\n",
       "      <td>DPA1*01:03/DPA1*02:01</td>\n",
       "      <td>DPB1*04:01/DPB1*13:01</td>\n",
       "      <td>179</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A*03:01/A*30:02</td>\n",
       "      <td>B*07:02/B*13:02</td>\n",
       "      <td>CW*03:04/CW*08:01</td>\n",
       "      <td>DRB1*08:04/DRB1*15:01</td>\n",
       "      <td>DRB5*01:01/DRB5*01:01</td>\n",
       "      <td>DQA1*01:02/DQA1*04:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>A*02:01/A*23:01</td>\n",
       "      <td>B*44:03/B*51:01</td>\n",
       "      <td>CW*04:01/CW*14:02</td>\n",
       "      <td>DRB1*07:01/DRB1*08:01</td>\n",
       "      <td>DRB4*01:01/DRB4*01:01</td>\n",
       "      <td>DQA1*02:01/DQA1*04:01</td>\n",
       "      <td>DQB1*02:02/DQB1*04:02</td>\n",
       "      <td>DPA1*01:03/DPA1*02:01</td>\n",
       "      <td>DPB1*04:01/DPB1*13:01</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A*02:01/A*11:01</td>\n",
       "      <td>B*15:01/B*51:01</td>\n",
       "      <td>DRB1*08:02/DRB1*14:06</td>\n",
       "      <td>DRB3*01:01/DQA1*04:01</td>\n",
       "      <td>DQA1*05:01/DQB1*04:02</td>\n",
       "      <td>DQB1*03:01/-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>A*03:01/A*74:01</td>\n",
       "      <td>B*35:01/B*53:01</td>\n",
       "      <td>DRB1*11:01/DRB1*15:03</td>\n",
       "      <td>DRB3*02:02/DRB5*01:01</td>\n",
       "      <td>DQA1*05:01/DQA1*01:02</td>\n",
       "      <td>DQB1*03:01/DQB1*06:02</td>\n",
       "      <td>-/-</td>\n",
       "      <td>-/-</td>\n",
       "      <td>-/-</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A*02:01/A*03:01</td>\n",
       "      <td>B*14:01/B*35:08</td>\n",
       "      <td>DRB1*11:01/DRB1*12:01</td>\n",
       "      <td>DRB3*02:02/DRB3*02:02</td>\n",
       "      <td>DQA1*05:01/DQA1*05:01</td>\n",
       "      <td>DQB1*03:01/DQB1*03:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>A*02:01/A*29:02</td>\n",
       "      <td>B*44:02/B*44:03</td>\n",
       "      <td>CW*05:01/CW*16:01</td>\n",
       "      <td>DRB1*01:01/DRB1*07:01</td>\n",
       "      <td>DRB4*01:01/DRB4*01:01</td>\n",
       "      <td>DQA1*01:01/DQA1*02:01</td>\n",
       "      <td>DQB1*02:02/DQB1*05:01</td>\n",
       "      <td>DPA1*02:01/DPA1*02:01</td>\n",
       "      <td>DPB1*10:01/DPB1*11:01</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A*01:01/A*02:01</td>\n",
       "      <td>B*14:02/B*35:01</td>\n",
       "      <td>DRB1*01:01/DRB1*13:01</td>\n",
       "      <td>DRB3*01:01/DQA1*01:01</td>\n",
       "      <td>DQA1*01:03/DQB1*05:01</td>\n",
       "      <td>DQB1*06:03/-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>A*02:01/A*29:02</td>\n",
       "      <td>B*44:02/B*44:03</td>\n",
       "      <td>CW*05:01/CW*16:01</td>\n",
       "      <td>DRB1*01:01/DRB1*07:01</td>\n",
       "      <td>DRB4*01:01/DRB4*01:01</td>\n",
       "      <td>DQA1*01:01/DQA1*02:01</td>\n",
       "      <td>DQB1*02:02/DQB1*05:01</td>\n",
       "      <td>DPA1*02:01/DPA1*02:01</td>\n",
       "      <td>DPB1*10:01/DPB1*11:01</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A*02:01/A*31:01</td>\n",
       "      <td>B*35:01/B*51:01</td>\n",
       "      <td>DRB1*01:01/DRB1*07:01</td>\n",
       "      <td>DRB4*01:01/DQA1*01:01</td>\n",
       "      <td>DQA1*02:01/DQB1*05:01</td>\n",
       "      <td>DQB1*02:02/-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          donor_hla0       donor_hla1             donor_hla2  \\\n",
       "0    A*03:01/A*80:01  B*35:03/B*44:03      CW*04:01/CW*04:01   \n",
       "2    A*03:01/A*80:01  B*35:03/B*44:03      CW*04:01/CW*04:01   \n",
       "8    A*03:01/A*80:01  B*35:03/B*44:03      CW*04:01/CW*04:01   \n",
       "13   A*31:01/A*31:01  B*15:01/B*35:01      CW*03:03/CW*04:01   \n",
       "16   A*31:01/A*31:01  B*15:01/B*35:01      CW*03:03/CW*04:01   \n",
       "..               ...              ...                    ...   \n",
       "922  A*24:02/A*32:01  B*07:02/B*40:02      CW*02:02/CW*07:02   \n",
       "923  A*02:01/A*23:01  B*44:03/B*51:01      CW*04:01/CW*14:02   \n",
       "929  A*03:01/A*74:01  B*35:01/B*53:01  DRB1*11:01/DRB1*15:03   \n",
       "937  A*02:01/A*29:02  B*44:02/B*44:03      CW*05:01/CW*16:01   \n",
       "938  A*02:01/A*29:02  B*44:02/B*44:03      CW*05:01/CW*16:01   \n",
       "\n",
       "                donor_hla3             donor_hla4             donor_hla5  \\\n",
       "0    DRB1*07:01/DRB1*15:01  DRB4*01:01/DRB5*01:01  DQA1*01:02/DQA1*02:01   \n",
       "2    DRB1*07:01/DRB1*15:01  DRB4*01:01/DRB5*01:01  DQA1*01:02/DQA1*02:01   \n",
       "8    DRB1*07:01/DRB1*15:01  DRB4*01:01/DRB5*01:01  DQA1*01:02/DQA1*02:01   \n",
       "13   DRB1*04:01/DRB1*14:33  DRB4*01:01/DRB4*01:01  DQA1*03:01/DQA1*03:01   \n",
       "16   DRB1*04:01/DRB1*14:33  DRB4*01:01/DRB4*01:01  DQA1*03:01/DQA1*03:01   \n",
       "..                     ...                    ...                    ...   \n",
       "922  DRB1*04:05/DRB1*15:01  DRB4*01:01/DRB5*01:01  DQA1*01:02/DQA1*03:01   \n",
       "923  DRB1*07:01/DRB1*08:01  DRB4*01:01/DRB4*01:01  DQA1*02:01/DQA1*04:01   \n",
       "929  DRB3*02:02/DRB5*01:01  DQA1*05:01/DQA1*01:02  DQB1*03:01/DQB1*06:02   \n",
       "937  DRB1*01:01/DRB1*07:01  DRB4*01:01/DRB4*01:01  DQA1*01:01/DQA1*02:01   \n",
       "938  DRB1*01:01/DRB1*07:01  DRB4*01:01/DRB4*01:01  DQA1*01:01/DQA1*02:01   \n",
       "\n",
       "                donor_hla6             donor_hla7             donor_hla8  \\\n",
       "0    DQB1*02:02/DQB1*06:02  DPA1*01:03/DPA1*01:03  DPB1*02:01/DPB1*13:01   \n",
       "2    DQB1*02:02/DQB1*06:02  DPA1*01:03/DPA1*01:03  DPB1*02:01/DPB1*13:01   \n",
       "8    DQB1*02:02/DQB1*06:02  DPA1*01:03/DPA1*01:03  DPB1*02:01/DPB1*13:01   \n",
       "13   DQB1*02:02/DQB1*03:02  DPA1*01:03/DPA1*02:02  DPB1*02:01/DPB1*05:01   \n",
       "16   DQB1*02:02/DQB1*03:02  DPA1*01:03/DPA1*02:02  DPB1*02:01/DPB1*05:01   \n",
       "..                     ...                    ...                    ...   \n",
       "922  DQB1*03:02/DQB1*06:02  DPA1*01:03/DPA1*02:01  DPB1*04:01/DPB1*13:01   \n",
       "923  DQB1*02:02/DQB1*04:02  DPA1*01:03/DPA1*02:01  DPB1*04:01/DPB1*13:01   \n",
       "929                    -/-                    -/-                    -/-   \n",
       "937  DQB1*02:02/DQB1*05:01  DPA1*02:01/DPA1*02:01  DPB1*10:01/DPB1*11:01   \n",
       "938  DQB1*02:02/DQB1*05:01  DPA1*02:01/DPA1*02:01  DPB1*10:01/DPB1*11:01   \n",
       "\n",
       "     patient_single_cl1  ...  patient_mixed_cl1  patient_mixed_cl2  \\\n",
       "0                     0  ...                  1                  1   \n",
       "2                     2  ...                  1                  0   \n",
       "8                     5  ...                  1                  0   \n",
       "13                    6  ...                  1                  1   \n",
       "16                    8  ...                  1                  1   \n",
       "..                  ...  ...                ...                ...   \n",
       "922                 179  ...                  1                  0   \n",
       "923                   5  ...                  1                  1   \n",
       "929                   3  ...                  0                  1   \n",
       "937                   5  ...                  0                  1   \n",
       "938                   5  ...                  0                  0   \n",
       "\n",
       "     epv_result     patient_hla0     patient_hla1           patient_hla2  \\\n",
       "0             0  A*29:02/A*30:02  B*51:01/B*58:01  DRB1*13:01/DRB1*15:01   \n",
       "2             1  A*03:01/A*23:01  B*07:02/B*07:05  DRB1*07:01/DRB1*15:03   \n",
       "8             0  A*02:01/A*23:01  B*41:01/B*44:03  DRB1*07:01/DRB1*15:01   \n",
       "13            1  A*30:02/A*68:01  B*18:01/B*35:01  DRB1*08:01/DRB1*14:01   \n",
       "16            0  A*24:02/A*30:09  B*15:16/B*35:08  DRB1*14:01/DRB1*14:01   \n",
       "..          ...              ...              ...                    ...   \n",
       "922           1  A*03:01/A*30:02  B*07:02/B*13:02      CW*03:04/CW*08:01   \n",
       "923           0  A*02:01/A*11:01  B*15:01/B*51:01  DRB1*08:02/DRB1*14:06   \n",
       "929           0  A*02:01/A*03:01  B*14:01/B*35:08  DRB1*11:01/DRB1*12:01   \n",
       "937           0  A*01:01/A*02:01  B*14:02/B*35:01  DRB1*01:01/DRB1*13:01   \n",
       "938           0  A*02:01/A*31:01  B*35:01/B*51:01  DRB1*01:01/DRB1*07:01   \n",
       "\n",
       "              patient_hla3           patient_hla4           patient_hla5  \\\n",
       "0    DRB3*01:01/DRB5*01:01  DQA1*01:03/DQA1*01:02  DQB1*06:03/DQB1*06:02   \n",
       "2    DRB4*01:01/DRB5*01:01  DQA1*02:01/DQA1*01:02  DQB1*02:02/DQB1*06:02   \n",
       "8    DRB4*01:01/DRB5*01:01  DQA1*02:01/DQA1*01:02  DQB1*02:02/DQB1*06:02   \n",
       "13   DRB3*02:02/DQA1*04:01  DQA1*01:04/DQB1*04:02           DQB1*05:03/-   \n",
       "16   DRB3*02:02/DRB3*02:02  DQA1*01:04/DQA1*01:04  DQB1*05:03/DQB1*05:03   \n",
       "..                     ...                    ...                    ...   \n",
       "922  DRB1*08:04/DRB1*15:01  DRB5*01:01/DRB5*01:01  DQA1*01:02/DQA1*04:01   \n",
       "923  DRB3*01:01/DQA1*04:01  DQA1*05:01/DQB1*04:02           DQB1*03:01/-   \n",
       "929  DRB3*02:02/DRB3*02:02  DQA1*05:01/DQA1*05:01  DQB1*03:01/DQB1*03:01   \n",
       "937  DRB3*01:01/DQA1*01:01  DQA1*01:03/DQB1*05:01           DQB1*06:03/-   \n",
       "938  DRB4*01:01/DQA1*01:01  DQA1*02:01/DQB1*05:01           DQB1*02:02/-   \n",
       "\n",
       "    cdc_result  \n",
       "0            0  \n",
       "2            1  \n",
       "8            0  \n",
       "13           0  \n",
       "16           0  \n",
       "..         ...  \n",
       "922          1  \n",
       "923          0  \n",
       "929          0  \n",
       "937          0  \n",
       "938          0  \n",
       "\n",
       "[357 rows x 21 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7504ecaa",
   "metadata": {
    "id": "7504ecaa"
   },
   "outputs": [],
   "source": [
    "count0 = (df_mod['cdc_result'] == 0).sum()\n",
    "count1 = (df_mod['cdc_result'] == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "93ac22e8",
   "metadata": {
    "id": "93ac22e8"
   },
   "outputs": [],
   "source": [
    "df_mod = pd.get_dummies(df_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "67ab122a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "67ab122a",
    "outputId": "d74fe725-9b49-40cb-da36-fafc6609b95b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_single_cl1</th>\n",
       "      <th>patient_single_cl2</th>\n",
       "      <th>patient_mixed_cl1</th>\n",
       "      <th>patient_mixed_cl2</th>\n",
       "      <th>epv_result</th>\n",
       "      <th>cdc_result</th>\n",
       "      <th>donor_hla0_A*01:01/A*01:01</th>\n",
       "      <th>donor_hla0_A*01:01/A*02:01</th>\n",
       "      <th>donor_hla0_A*01:01/A*03:01</th>\n",
       "      <th>donor_hla0_A*01:01/A*11:01</th>\n",
       "      <th>...</th>\n",
       "      <th>patient_hla5_DQB1*06:03/DQB1*05:02</th>\n",
       "      <th>patient_hla5_DQB1*06:03/DQB1*06:01</th>\n",
       "      <th>patient_hla5_DQB1*06:03/DQB1*06:02</th>\n",
       "      <th>patient_hla5_DQB1*06:03/DQB1*06:03</th>\n",
       "      <th>patient_hla5_DQB1*06:03/DQB1*06:04</th>\n",
       "      <th>patient_hla5_DQB1*06:04/-</th>\n",
       "      <th>patient_hla5_DQB1*06:04/DQB1*06:02</th>\n",
       "      <th>patient_hla5_DQB1*06:04/DQB1*06:04</th>\n",
       "      <th>patient_hla5_DRB4*01:01/DQA1*01:01</th>\n",
       "      <th>patient_hla5_DRB5*01:01/DQA1*01:02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1588 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    patient_single_cl1  patient_single_cl2  patient_mixed_cl1  \\\n",
       "0                    0                   0                  1   \n",
       "2                    2                   2                  1   \n",
       "8                    5                   2                  1   \n",
       "13                   6                   4                  1   \n",
       "16                   8                   6                  1   \n",
       "\n",
       "    patient_mixed_cl2  epv_result  cdc_result  donor_hla0_A*01:01/A*01:01  \\\n",
       "0                   1           0           0                           0   \n",
       "2                   0           1           1                           0   \n",
       "8                   0           0           0                           0   \n",
       "13                  1           1           0                           0   \n",
       "16                  1           0           0                           0   \n",
       "\n",
       "    donor_hla0_A*01:01/A*02:01  donor_hla0_A*01:01/A*03:01  \\\n",
       "0                            0                           0   \n",
       "2                            0                           0   \n",
       "8                            0                           0   \n",
       "13                           0                           0   \n",
       "16                           0                           0   \n",
       "\n",
       "    donor_hla0_A*01:01/A*11:01  ...  patient_hla5_DQB1*06:03/DQB1*05:02  \\\n",
       "0                            0  ...                                   0   \n",
       "2                            0  ...                                   0   \n",
       "8                            0  ...                                   0   \n",
       "13                           0  ...                                   0   \n",
       "16                           0  ...                                   0   \n",
       "\n",
       "    patient_hla5_DQB1*06:03/DQB1*06:01  patient_hla5_DQB1*06:03/DQB1*06:02  \\\n",
       "0                                    0                                   1   \n",
       "2                                    0                                   0   \n",
       "8                                    0                                   0   \n",
       "13                                   0                                   0   \n",
       "16                                   0                                   0   \n",
       "\n",
       "    patient_hla5_DQB1*06:03/DQB1*06:03  patient_hla5_DQB1*06:03/DQB1*06:04  \\\n",
       "0                                    0                                   0   \n",
       "2                                    0                                   0   \n",
       "8                                    0                                   0   \n",
       "13                                   0                                   0   \n",
       "16                                   0                                   0   \n",
       "\n",
       "    patient_hla5_DQB1*06:04/-  patient_hla5_DQB1*06:04/DQB1*06:02  \\\n",
       "0                           0                                   0   \n",
       "2                           0                                   0   \n",
       "8                           0                                   0   \n",
       "13                          0                                   0   \n",
       "16                          0                                   0   \n",
       "\n",
       "    patient_hla5_DQB1*06:04/DQB1*06:04  patient_hla5_DRB4*01:01/DQA1*01:01  \\\n",
       "0                                    0                                   0   \n",
       "2                                    0                                   0   \n",
       "8                                    0                                   0   \n",
       "13                                   0                                   0   \n",
       "16                                   0                                   0   \n",
       "\n",
       "    patient_hla5_DRB5*01:01/DQA1*01:02  \n",
       "0                                    0  \n",
       "2                                    0  \n",
       "8                                    0  \n",
       "13                                   0  \n",
       "16                                   0  \n",
       "\n",
       "[5 rows x 1588 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mod.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8072a052",
   "metadata": {
    "id": "8072a052"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample,shuffle\n",
    "\n",
    "#labels = df_mod['cdc_result']\n",
    "#df_mod = df_mod.drop('cdc_result', axis = 1)\n",
    "#feature_list = list(df_mod.columns)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df_mod, labels, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "51240dd9",
   "metadata": {
    "id": "51240dd9"
   },
   "outputs": [],
   "source": [
    "#print('Training Features Shape:', X_train.shape)\n",
    "#print('Training Labels Shape:', y_train.shape)\n",
    "#print('Testing Features Shape:', X_test.shape)\n",
    "#print('Testing Labels Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ddcbddfa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddcbddfa",
    "outputId": "cad08269-6eb1-403f-97c9-878bcffc25e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    287\n",
       "0    287\n",
       "Name: cdc_result, dtype: int64"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_class_0, count_class_1 = df_mod.cdc_result.value_counts()\n",
    "\n",
    "df_class_0 = df_mod[df_mod['cdc_result'] == 0]\n",
    "df_class_1 = df_mod[df_mod['cdc_result'] == 1]\n",
    "\n",
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "\n",
    "df_1_upsampled = resample(df_class_1, random_state=42, n_samples=len(df_class_0), replace=True)\n",
    "df_upsampled = pd.concat([df_1_upsampled, df_class_0])\n",
    "df_upsampled.cdc_result.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "cd78cc6c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "cd78cc6c",
    "outputId": "c9692585-087f-412f-905c-69b42541d1bb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_single_cl1</th>\n",
       "      <th>patient_single_cl2</th>\n",
       "      <th>patient_mixed_cl1</th>\n",
       "      <th>patient_mixed_cl2</th>\n",
       "      <th>epv_result</th>\n",
       "      <th>cdc_result</th>\n",
       "      <th>donor_hla0_A*01:01/A*01:01</th>\n",
       "      <th>donor_hla0_A*01:01/A*02:01</th>\n",
       "      <th>donor_hla0_A*01:01/A*03:01</th>\n",
       "      <th>donor_hla0_A*01:01/A*11:01</th>\n",
       "      <th>...</th>\n",
       "      <th>patient_hla5_DQB1*06:03/DQB1*05:02</th>\n",
       "      <th>patient_hla5_DQB1*06:03/DQB1*06:01</th>\n",
       "      <th>patient_hla5_DQB1*06:03/DQB1*06:02</th>\n",
       "      <th>patient_hla5_DQB1*06:03/DQB1*06:03</th>\n",
       "      <th>patient_hla5_DQB1*06:03/DQB1*06:04</th>\n",
       "      <th>patient_hla5_DQB1*06:04/-</th>\n",
       "      <th>patient_hla5_DQB1*06:04/DQB1*06:02</th>\n",
       "      <th>patient_hla5_DQB1*06:04/DQB1*06:04</th>\n",
       "      <th>patient_hla5_DRB4*01:01/DQA1*01:01</th>\n",
       "      <th>patient_hla5_DRB5*01:01/DQA1*01:02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>136</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>156</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>77</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>5</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>5</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>574 rows × 1588 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     patient_single_cl1  patient_single_cl2  patient_mixed_cl1  \\\n",
       "609                 136                  93                  1   \n",
       "185                  59                   2                  1   \n",
       "759                 156                   2                  1   \n",
       "253                  73                   2                  1   \n",
       "265                  77                   6                  1   \n",
       "..                  ...                 ...                ...   \n",
       "921                   5                   2                  1   \n",
       "923                   5                 144                  1   \n",
       "929                   3                   6                  0   \n",
       "937                   5                 145                  0   \n",
       "938                   5                   2                  0   \n",
       "\n",
       "     patient_mixed_cl2  epv_result  cdc_result  donor_hla0_A*01:01/A*01:01  \\\n",
       "609                  0           1           1                           0   \n",
       "185                  1           1           1                           0   \n",
       "759                  0           1           1                           0   \n",
       "253                  0           1           1                           0   \n",
       "265                  1           1           1                           0   \n",
       "..                 ...         ...         ...                         ...   \n",
       "921                  0           0           0                           0   \n",
       "923                  1           0           0                           0   \n",
       "929                  1           0           0                           0   \n",
       "937                  1           0           0                           0   \n",
       "938                  0           0           0                           0   \n",
       "\n",
       "     donor_hla0_A*01:01/A*02:01  donor_hla0_A*01:01/A*03:01  \\\n",
       "609                           0                           0   \n",
       "185                           0                           0   \n",
       "759                           0                           0   \n",
       "253                           0                           0   \n",
       "265                           0                           0   \n",
       "..                          ...                         ...   \n",
       "921                           0                           0   \n",
       "923                           0                           0   \n",
       "929                           0                           0   \n",
       "937                           0                           0   \n",
       "938                           0                           0   \n",
       "\n",
       "     donor_hla0_A*01:01/A*11:01  ...  patient_hla5_DQB1*06:03/DQB1*05:02  \\\n",
       "609                           0  ...                                   0   \n",
       "185                           0  ...                                   0   \n",
       "759                           0  ...                                   0   \n",
       "253                           0  ...                                   0   \n",
       "265                           0  ...                                   0   \n",
       "..                          ...  ...                                 ...   \n",
       "921                           0  ...                                   0   \n",
       "923                           0  ...                                   0   \n",
       "929                           0  ...                                   0   \n",
       "937                           0  ...                                   0   \n",
       "938                           0  ...                                   0   \n",
       "\n",
       "     patient_hla5_DQB1*06:03/DQB1*06:01  patient_hla5_DQB1*06:03/DQB1*06:02  \\\n",
       "609                                   0                                   0   \n",
       "185                                   0                                   0   \n",
       "759                                   0                                   0   \n",
       "253                                   0                                   0   \n",
       "265                                   0                                   0   \n",
       "..                                  ...                                 ...   \n",
       "921                                   0                                   0   \n",
       "923                                   0                                   0   \n",
       "929                                   0                                   0   \n",
       "937                                   0                                   0   \n",
       "938                                   0                                   0   \n",
       "\n",
       "     patient_hla5_DQB1*06:03/DQB1*06:03  patient_hla5_DQB1*06:03/DQB1*06:04  \\\n",
       "609                                   0                                   0   \n",
       "185                                   0                                   0   \n",
       "759                                   0                                   0   \n",
       "253                                   0                                   0   \n",
       "265                                   0                                   0   \n",
       "..                                  ...                                 ...   \n",
       "921                                   0                                   0   \n",
       "923                                   0                                   0   \n",
       "929                                   0                                   0   \n",
       "937                                   0                                   0   \n",
       "938                                   0                                   0   \n",
       "\n",
       "     patient_hla5_DQB1*06:04/-  patient_hla5_DQB1*06:04/DQB1*06:02  \\\n",
       "609                          0                                   0   \n",
       "185                          0                                   0   \n",
       "759                          0                                   0   \n",
       "253                          0                                   0   \n",
       "265                          0                                   0   \n",
       "..                         ...                                 ...   \n",
       "921                          0                                   0   \n",
       "923                          0                                   0   \n",
       "929                          0                                   0   \n",
       "937                          0                                   0   \n",
       "938                          0                                   0   \n",
       "\n",
       "     patient_hla5_DQB1*06:04/DQB1*06:04  patient_hla5_DRB4*01:01/DQA1*01:01  \\\n",
       "609                                   0                                   0   \n",
       "185                                   0                                   0   \n",
       "759                                   0                                   0   \n",
       "253                                   0                                   0   \n",
       "265                                   0                                   0   \n",
       "..                                  ...                                 ...   \n",
       "921                                   0                                   0   \n",
       "923                                   0                                   0   \n",
       "929                                   0                                   0   \n",
       "937                                   0                                   0   \n",
       "938                                   0                                   0   \n",
       "\n",
       "     patient_hla5_DRB5*01:01/DQA1*01:02  \n",
       "609                                   0  \n",
       "185                                   0  \n",
       "759                                   0  \n",
       "253                                   0  \n",
       "265                                   0  \n",
       "..                                  ...  \n",
       "921                                   0  \n",
       "923                                   0  \n",
       "929                                   0  \n",
       "937                                   0  \n",
       "938                                   0  \n",
       "\n",
       "[574 rows x 1588 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0cdf1c97",
   "metadata": {
    "id": "0cdf1c97"
   },
   "outputs": [],
   "source": [
    "labels = df_upsampled['cdc_result'].to_numpy()\n",
    "df_upsampled = df_upsampled.drop('cdc_result', axis = 1).to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_upsampled, labels, test_size = 0.40, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "62068ba2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62068ba2",
    "outputId": "14f6519e-f160-4689-e1f7-89d54245608a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (344, 1587)\n",
      "Training Labels Shape: (344,)\n",
      "Testing Features Shape: (230, 1587)\n",
      "Testing Labels Shape: (230,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', X_train.shape)\n",
    "print('Training Labels Shape:', y_train.shape)\n",
    "print('Testing Features Shape:', X_test.shape)\n",
    "print('Testing Labels Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "52b9879c",
   "metadata": {
    "id": "52b9879c"
   },
   "outputs": [],
   "source": [
    "#y = df_upsampled.cdc_result\n",
    "#X = df_upsampled.drop('cdc_result', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "Sa1OKOWO7V4x",
   "metadata": {
    "id": "Sa1OKOWO7V4x"
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "from sklearn.decomposition import PCA as sklearnPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "MK-fekir8Z7p",
   "metadata": {
    "id": "MK-fekir8Z7p"
   },
   "outputs": [],
   "source": [
    "enter = list(X_train[0].shape)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6ug2xf89GQN5",
   "metadata": {
    "id": "6ug2xf89GQN5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "WcaK71xSF9KF",
   "metadata": {
    "id": "WcaK71xSF9KF"
   },
   "outputs": [],
   "source": [
    "y_train = np.expand_dims(y_train,axis=-1)\n",
    "y_test = np.expand_dims(y_test,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bWstzYxs71tq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bWstzYxs71tq",
    "outputId": "2a7644a2-8ebc-4821-de6a-5281524a962d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========Data Summary===========\n",
      "Training Data : (344, 1587)\n",
      "Testing Data : (230, 1587)\n",
      "=========== RUN 0=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 7.266\tAcc: 47.96512%\n",
      "Step:   100\tLoss: 1.018\tAcc: 71.51163%\n",
      "Step:   200\tLoss: 0.582\tAcc: 78.48837%\n",
      "Step:   300\tLoss: 0.420\tAcc: 81.68604%\n",
      "Step:   400\tLoss: 0.345\tAcc: 84.59302%\n",
      "Step:   500\tLoss: 0.299\tAcc: 86.33721%\n",
      "Step:   600\tLoss: 0.267\tAcc: 87.50000%\n",
      "Step:   700\tLoss: 0.242\tAcc: 90.40698%\n",
      "Step:   800\tLoss: 0.218\tAcc: 93.02326%\n",
      "Step:   900\tLoss: 0.203\tAcc: 93.60465%\n",
      "Step:  1000\tLoss: 0.190\tAcc: 93.89535%\n",
      "Step:  1100\tLoss: 0.180\tAcc: 94.47674%\n",
      "Step:  1200\tLoss: 0.170\tAcc: 95.05814%\n",
      "Step:  1300\tLoss: 0.162\tAcc: 95.34883%\n",
      "Step:  1400\tLoss: 0.155\tAcc: 95.93023%\n",
      "Step:  1500\tLoss: 0.149\tAcc: 96.22093%\n",
      "Step:  1600\tLoss: 0.143\tAcc: 96.80232%\n",
      "Step:  1700\tLoss: 0.138\tAcc: 97.09302%\n",
      "Step:  1800\tLoss: 0.133\tAcc: 97.96512%\n",
      "Step:  1900\tLoss: 0.129\tAcc: 97.96512%\n",
      "Step:  2000\tLoss: 0.125\tAcc: 98.25581%\n",
      "Step:  2100\tLoss: 0.122\tAcc: 98.54651%\n",
      "Step:  2200\tLoss: 0.118\tAcc: 98.54651%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9854651\n",
      "Test Prediction = 0.87391305\n",
      "=========== RUN 1=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 10.820\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 2.876\tAcc: 50.58140%\n",
      "Step:   200\tLoss: 1.529\tAcc: 64.53488%\n",
      "Step:   300\tLoss: 1.049\tAcc: 69.76744%\n",
      "Step:   400\tLoss: 0.758\tAcc: 74.41860%\n",
      "Step:   500\tLoss: 0.581\tAcc: 82.84883%\n",
      "Step:   600\tLoss: 0.467\tAcc: 86.62791%\n",
      "Step:   700\tLoss: 0.383\tAcc: 89.24419%\n",
      "Step:   800\tLoss: 0.322\tAcc: 91.27907%\n",
      "Step:   900\tLoss: 0.280\tAcc: 91.56977%\n",
      "Step:  1000\tLoss: 0.249\tAcc: 92.15117%\n",
      "Step:  1100\tLoss: 0.225\tAcc: 93.02326%\n",
      "Step:  1200\tLoss: 0.207\tAcc: 93.60465%\n",
      "Step:  1300\tLoss: 0.193\tAcc: 94.47674%\n",
      "Step:  1400\tLoss: 0.181\tAcc: 95.63953%\n",
      "Step:  1500\tLoss: 0.171\tAcc: 95.93023%\n",
      "Step:  1600\tLoss: 0.163\tAcc: 95.63953%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.95348835\n",
      "Test Prediction = 0.8521739\n",
      "=========== RUN 2=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 13.273\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 3.475\tAcc: 48.83721%\n",
      "Step:   200\tLoss: 1.237\tAcc: 64.53488%\n",
      "Step:   300\tLoss: 0.786\tAcc: 72.96512%\n",
      "Step:   400\tLoss: 0.577\tAcc: 82.55814%\n",
      "Step:   500\tLoss: 0.464\tAcc: 88.08140%\n",
      "Step:   600\tLoss: 0.389\tAcc: 91.27907%\n",
      "Step:   700\tLoss: 0.339\tAcc: 92.44186%\n",
      "Step:   800\tLoss: 0.301\tAcc: 93.02326%\n",
      "Step:   900\tLoss: 0.272\tAcc: 93.89535%\n",
      "Step:  1000\tLoss: 0.250\tAcc: 94.47674%\n",
      "Step:  1100\tLoss: 0.232\tAcc: 95.05814%\n",
      "Step:  1200\tLoss: 0.216\tAcc: 94.76744%\n",
      "Step:  1300\tLoss: 0.202\tAcc: 95.34883%\n",
      "Step:  1400\tLoss: 0.189\tAcc: 95.63953%\n",
      "Step:  1500\tLoss: 0.177\tAcc: 95.63953%\n",
      "Step:  1600\tLoss: 0.167\tAcc: 95.63953%\n",
      "Step:  1700\tLoss: 0.158\tAcc: 96.22093%\n",
      "Step:  1800\tLoss: 0.150\tAcc: 96.51163%\n",
      "Step:  1900\tLoss: 0.143\tAcc: 96.51163%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.96511626\n",
      "Test Prediction = 0.8608696\n",
      "=========== RUN 3=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 3.300\tAcc: 52.90698%\n",
      "Step:   100\tLoss: 1.051\tAcc: 70.93023%\n",
      "Step:   200\tLoss: 0.674\tAcc: 80.23256%\n",
      "Step:   300\tLoss: 0.508\tAcc: 85.75581%\n",
      "Step:   400\tLoss: 0.409\tAcc: 88.95349%\n",
      "Step:   500\tLoss: 0.346\tAcc: 90.40698%\n",
      "Step:   600\tLoss: 0.302\tAcc: 91.27907%\n",
      "Step:   700\tLoss: 0.271\tAcc: 91.86047%\n",
      "Step:   800\tLoss: 0.251\tAcc: 93.60465%\n",
      "Step:   900\tLoss: 0.235\tAcc: 93.60465%\n",
      "Step:  1000\tLoss: 0.221\tAcc: 93.89535%\n",
      "Step:  1100\tLoss: 0.209\tAcc: 94.47674%\n",
      "Step:  1200\tLoss: 0.199\tAcc: 94.47674%\n",
      "Step:  1300\tLoss: 0.190\tAcc: 95.34883%\n",
      "Step:  1400\tLoss: 0.181\tAcc: 95.93023%\n",
      "Step:  1500\tLoss: 0.173\tAcc: 95.93023%\n",
      "Step:  1600\tLoss: 0.166\tAcc: 95.93023%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9593023\n",
      "Test Prediction = 0.83913046\n",
      "=========== RUN 4=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 6.653\tAcc: 52.32558%\n",
      "Step:   100\tLoss: 0.723\tAcc: 77.03488%\n",
      "Step:   200\tLoss: 0.486\tAcc: 80.52326%\n",
      "Step:   300\tLoss: 0.408\tAcc: 83.72093%\n",
      "Step:   400\tLoss: 0.353\tAcc: 88.95349%\n",
      "Step:   500\tLoss: 0.315\tAcc: 91.27907%\n",
      "Step:   600\tLoss: 0.285\tAcc: 93.02326%\n",
      "Step:   700\tLoss: 0.258\tAcc: 93.02326%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9302326\n",
      "Test Prediction = 0.8347826\n",
      "=========== RUN 5=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 2.940\tAcc: 52.03488%\n",
      "Step:   100\tLoss: 1.114\tAcc: 61.33721%\n",
      "Step:   200\tLoss: 0.710\tAcc: 75.58140%\n",
      "Step:   300\tLoss: 0.524\tAcc: 81.68604%\n",
      "Step:   400\tLoss: 0.425\tAcc: 88.37209%\n",
      "Step:   500\tLoss: 0.360\tAcc: 88.95349%\n",
      "Step:   600\tLoss: 0.312\tAcc: 90.98837%\n",
      "Step:   700\tLoss: 0.276\tAcc: 93.02326%\n",
      "Step:   800\tLoss: 0.245\tAcc: 93.31396%\n",
      "Step:   900\tLoss: 0.221\tAcc: 94.76744%\n",
      "Step:  1000\tLoss: 0.200\tAcc: 95.63953%\n",
      "Step:  1100\tLoss: 0.183\tAcc: 96.80232%\n",
      "Step:  1200\tLoss: 0.168\tAcc: 96.80232%\n",
      "Step:  1300\tLoss: 0.156\tAcc: 97.09302%\n",
      "Step:  1400\tLoss: 0.145\tAcc: 97.09302%\n",
      "Step:  1500\tLoss: 0.136\tAcc: 97.38372%\n",
      "Step:  1600\tLoss: 0.127\tAcc: 97.67442%\n",
      "Step:  1700\tLoss: 0.119\tAcc: 98.25581%\n",
      "Step:  1800\tLoss: 0.113\tAcc: 98.25581%\n",
      "Step:  1900\tLoss: 0.108\tAcc: 98.25581%\n",
      "Step:  2000\tLoss: 0.103\tAcc: 98.54651%\n",
      "Step:  2100\tLoss: 0.099\tAcc: 98.54651%\n",
      "Step:  2200\tLoss: 0.095\tAcc: 98.83721%\n",
      "Step:  2300\tLoss: 0.091\tAcc: 98.83721%\n",
      "Step:  2400\tLoss: 0.088\tAcc: 98.83721%\n",
      "Step:  2500\tLoss: 0.085\tAcc: 98.83721%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9883721\n",
      "Test Prediction = 0.8608696\n",
      "=========== RUN 6=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 16.152\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 7.691\tAcc: 47.96512%\n",
      "Step:   200\tLoss: 3.239\tAcc: 55.52326%\n",
      "Step:   300\tLoss: 1.796\tAcc: 61.91860%\n",
      "Step:   400\tLoss: 1.142\tAcc: 70.05814%\n",
      "Step:   500\tLoss: 0.826\tAcc: 74.70930%\n",
      "Step:   600\tLoss: 0.642\tAcc: 79.65117%\n",
      "Step:   700\tLoss: 0.526\tAcc: 84.88372%\n",
      "Step:   800\tLoss: 0.435\tAcc: 88.08140%\n",
      "Step:   900\tLoss: 0.368\tAcc: 89.24419%\n",
      "Step:  1000\tLoss: 0.319\tAcc: 90.40698%\n",
      "Step:  1100\tLoss: 0.280\tAcc: 91.27907%\n",
      "Step:  1200\tLoss: 0.246\tAcc: 91.27907%\n",
      "Step:  1300\tLoss: 0.220\tAcc: 93.60465%\n",
      "Step:  1400\tLoss: 0.199\tAcc: 94.47674%\n",
      "Step:  1500\tLoss: 0.182\tAcc: 95.05814%\n",
      "Step:  1600\tLoss: 0.169\tAcc: 95.63953%\n",
      "Step:  1700\tLoss: 0.158\tAcc: 96.51163%\n",
      "Step:  1800\tLoss: 0.149\tAcc: 97.38372%\n",
      "Step:  1900\tLoss: 0.140\tAcc: 97.38372%\n",
      "Step:  2000\tLoss: 0.133\tAcc: 97.67442%\n",
      "Step:  2100\tLoss: 0.127\tAcc: 98.25581%\n",
      "Step:  2200\tLoss: 0.121\tAcc: 98.25581%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.98255813\n",
      "Test Prediction = 0.8347826\n",
      "=========== RUN 7=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 6.187\tAcc: 46.80233%\n",
      "Step:   100\tLoss: 0.728\tAcc: 76.74419%\n",
      "Step:   200\tLoss: 0.571\tAcc: 82.26744%\n",
      "Step:   300\tLoss: 0.471\tAcc: 85.17442%\n",
      "Step:   400\tLoss: 0.400\tAcc: 87.50000%\n",
      "Step:   500\tLoss: 0.348\tAcc: 89.24419%\n",
      "Step:   600\tLoss: 0.309\tAcc: 89.82558%\n",
      "Step:   700\tLoss: 0.279\tAcc: 90.69768%\n",
      "Step:   800\tLoss: 0.253\tAcc: 92.15117%\n",
      "Step:   900\tLoss: 0.232\tAcc: 92.44186%\n",
      "Step:  1000\tLoss: 0.214\tAcc: 93.60465%\n",
      "Step:  1100\tLoss: 0.199\tAcc: 93.60465%\n",
      "Step:  1200\tLoss: 0.186\tAcc: 94.18604%\n",
      "Step:  1300\tLoss: 0.175\tAcc: 94.18604%\n",
      "Step:  1400\tLoss: 0.165\tAcc: 95.34883%\n",
      "Step:  1500\tLoss: 0.156\tAcc: 95.63953%\n",
      "Step:  1600\tLoss: 0.149\tAcc: 95.93023%\n",
      "Step:  1700\tLoss: 0.142\tAcc: 96.22093%\n",
      "Step:  1800\tLoss: 0.136\tAcc: 96.22093%\n",
      "Step:  1900\tLoss: 0.131\tAcc: 96.51163%\n",
      "Step:  2000\tLoss: 0.126\tAcc: 96.51163%\n",
      "Step:  2100\tLoss: 0.122\tAcc: 96.51163%\n",
      "Step:  2200\tLoss: 0.118\tAcc: 96.51163%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.96511626\n",
      "Test Prediction = 0.87826085\n",
      "=========== RUN 8=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 12.469\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 4.290\tAcc: 45.93023%\n",
      "Step:   200\tLoss: 1.840\tAcc: 66.27907%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:   300\tLoss: 1.073\tAcc: 75.58140%\n",
      "Step:   400\tLoss: 0.669\tAcc: 82.84883%\n",
      "Step:   500\tLoss: 0.513\tAcc: 84.88372%\n",
      "Step:   600\tLoss: 0.419\tAcc: 89.53488%\n",
      "Step:   700\tLoss: 0.353\tAcc: 91.27907%\n",
      "Step:   800\tLoss: 0.305\tAcc: 93.60465%\n",
      "Step:   900\tLoss: 0.272\tAcc: 93.60465%\n",
      "Step:  1000\tLoss: 0.248\tAcc: 93.60465%\n",
      "Step:  1100\tLoss: 0.227\tAcc: 94.76744%\n",
      "Step:  1200\tLoss: 0.209\tAcc: 95.05814%\n",
      "Step:  1300\tLoss: 0.195\tAcc: 95.63953%\n",
      "Step:  1400\tLoss: 0.183\tAcc: 95.93023%\n",
      "Step:  1500\tLoss: 0.172\tAcc: 96.51163%\n",
      "Step:  1600\tLoss: 0.162\tAcc: 96.80232%\n",
      "Step:  1700\tLoss: 0.154\tAcc: 97.38372%\n",
      "Step:  1800\tLoss: 0.146\tAcc: 97.67442%\n",
      "Step:  1900\tLoss: 0.139\tAcc: 97.96512%\n",
      "Step:  2000\tLoss: 0.133\tAcc: 98.25581%\n",
      "Step:  2100\tLoss: 0.127\tAcc: 97.96512%\n",
      "Step:  2200\tLoss: 0.121\tAcc: 98.25581%\n",
      "Step:  2300\tLoss: 0.116\tAcc: 98.25581%\n",
      "Step:  2400\tLoss: 0.111\tAcc: 98.25581%\n",
      "Step:  2500\tLoss: 0.107\tAcc: 98.54651%\n",
      "Step:  2600\tLoss: 0.103\tAcc: 98.54651%\n",
      "Step:  2700\tLoss: 0.099\tAcc: 98.54651%\n",
      "Step:  2800\tLoss: 0.095\tAcc: 98.54651%\n",
      "Step:  2900\tLoss: 0.092\tAcc: 98.83721%\n",
      "Step:  3000\tLoss: 0.089\tAcc: 98.83721%\n",
      "Step:  3100\tLoss: 0.087\tAcc: 98.83721%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9883721\n",
      "Test Prediction = 0.8608696\n",
      "=========== RUN 9=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 3.120\tAcc: 52.61628%\n",
      "Step:   100\tLoss: 1.026\tAcc: 71.80232%\n",
      "Step:   200\tLoss: 0.673\tAcc: 80.52326%\n",
      "Step:   300\tLoss: 0.518\tAcc: 84.01163%\n",
      "Step:   400\tLoss: 0.416\tAcc: 87.50000%\n",
      "Step:   500\tLoss: 0.345\tAcc: 89.24419%\n",
      "Step:   600\tLoss: 0.293\tAcc: 91.56977%\n",
      "Step:   700\tLoss: 0.253\tAcc: 92.44186%\n",
      "Step:   800\tLoss: 0.221\tAcc: 92.73256%\n",
      "Step:   900\tLoss: 0.196\tAcc: 93.89535%\n",
      "Step:  1000\tLoss: 0.177\tAcc: 95.93023%\n",
      "Step:  1100\tLoss: 0.161\tAcc: 96.51163%\n",
      "Step:  1200\tLoss: 0.148\tAcc: 96.51163%\n",
      "Step:  1300\tLoss: 0.137\tAcc: 96.51163%\n",
      "Step:  1400\tLoss: 0.127\tAcc: 96.80232%\n",
      "Step:  1500\tLoss: 0.119\tAcc: 97.09302%\n",
      "Step:  1600\tLoss: 0.112\tAcc: 97.38372%\n",
      "Step:  1700\tLoss: 0.106\tAcc: 97.96512%\n",
      "Step:  1800\tLoss: 0.100\tAcc: 97.96512%\n",
      "Step:  1900\tLoss: 0.096\tAcc: 97.96512%\n",
      "Step:  2000\tLoss: 0.092\tAcc: 98.54651%\n",
      "Step:  2100\tLoss: 0.088\tAcc: 98.54651%\n",
      "Step:  2200\tLoss: 0.084\tAcc: 98.83721%\n",
      "Step:  2300\tLoss: 0.081\tAcc: 98.83721%\n",
      "Step:  2400\tLoss: 0.078\tAcc: 98.83721%\n",
      "Step:  2500\tLoss: 0.076\tAcc: 99.12791%\n",
      "Step:  2600\tLoss: 0.073\tAcc: 99.12791%\n",
      "Step:  2700\tLoss: 0.071\tAcc: 99.12791%\n",
      "Step:  2800\tLoss: 0.069\tAcc: 99.12791%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.99127907\n",
      "Test Prediction = 0.87391305\n",
      "=========== RUN 10=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 12.835\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 6.110\tAcc: 47.67442%\n",
      "Step:   200\tLoss: 1.847\tAcc: 52.32558%\n",
      "Step:   300\tLoss: 0.939\tAcc: 69.76744%\n",
      "Step:   400\tLoss: 0.621\tAcc: 78.19768%\n",
      "Step:   500\tLoss: 0.472\tAcc: 85.75581%\n",
      "Step:   600\tLoss: 0.379\tAcc: 88.95349%\n",
      "Step:   700\tLoss: 0.324\tAcc: 91.27907%\n",
      "Step:   800\tLoss: 0.283\tAcc: 92.73256%\n",
      "Step:   900\tLoss: 0.251\tAcc: 93.60465%\n",
      "Step:  1000\tLoss: 0.226\tAcc: 94.18604%\n",
      "Step:  1100\tLoss: 0.205\tAcc: 94.76744%\n",
      "Step:  1200\tLoss: 0.188\tAcc: 95.34883%\n",
      "Step:  1300\tLoss: 0.173\tAcc: 95.93023%\n",
      "Step:  1400\tLoss: 0.160\tAcc: 96.80232%\n",
      "Step:  1500\tLoss: 0.148\tAcc: 96.80232%\n",
      "Step:  1600\tLoss: 0.138\tAcc: 97.67442%\n",
      "Step:  1700\tLoss: 0.129\tAcc: 98.25581%\n",
      "Step:  1800\tLoss: 0.121\tAcc: 98.25581%\n",
      "Step:  1900\tLoss: 0.114\tAcc: 98.25581%\n",
      "Step:  2000\tLoss: 0.108\tAcc: 98.54651%\n",
      "Step:  2100\tLoss: 0.103\tAcc: 98.54651%\n",
      "Step:  2200\tLoss: 0.098\tAcc: 98.83721%\n",
      "Step:  2300\tLoss: 0.093\tAcc: 98.83721%\n",
      "Step:  2400\tLoss: 0.089\tAcc: 98.83721%\n",
      "Step:  2500\tLoss: 0.086\tAcc: 98.83721%\n",
      "Step:  2600\tLoss: 0.083\tAcc: 99.41860%\n",
      "Step:  2700\tLoss: 0.080\tAcc: 99.41860%\n",
      "Step:  2800\tLoss: 0.077\tAcc: 99.70930%\n",
      "Step:  2900\tLoss: 0.075\tAcc: 99.70930%\n",
      "Step:  3000\tLoss: 0.073\tAcc: 99.70930%\n",
      "Step:  3100\tLoss: 0.071\tAcc: 99.70930%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.997093\n",
      "Test Prediction = 0.8695652\n",
      "=========== RUN 11=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 11.370\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 4.865\tAcc: 47.67442%\n",
      "Step:   200\tLoss: 1.879\tAcc: 56.97674%\n",
      "Step:   300\tLoss: 1.194\tAcc: 65.69768%\n",
      "Step:   400\tLoss: 0.843\tAcc: 71.51163%\n",
      "Step:   500\tLoss: 0.629\tAcc: 77.61628%\n",
      "Step:   600\tLoss: 0.504\tAcc: 84.30232%\n",
      "Step:   700\tLoss: 0.419\tAcc: 88.08140%\n",
      "Step:   800\tLoss: 0.364\tAcc: 90.98837%\n",
      "Step:   900\tLoss: 0.324\tAcc: 91.56977%\n",
      "Step:  1000\tLoss: 0.294\tAcc: 92.73256%\n",
      "Step:  1100\tLoss: 0.270\tAcc: 92.73256%\n",
      "Step:  1200\tLoss: 0.252\tAcc: 93.60465%\n",
      "Step:  1300\tLoss: 0.236\tAcc: 93.89535%\n",
      "Step:  1400\tLoss: 0.224\tAcc: 94.76744%\n",
      "Step:  1500\tLoss: 0.213\tAcc: 95.93023%\n",
      "Step:  1600\tLoss: 0.203\tAcc: 95.93023%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9593023\n",
      "Test Prediction = 0.8173913\n",
      "=========== RUN 12=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 12.258\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 4.536\tAcc: 47.09302%\n",
      "Step:   200\tLoss: 1.495\tAcc: 60.46512%\n",
      "Step:   300\tLoss: 0.903\tAcc: 73.54651%\n",
      "Step:   400\tLoss: 0.617\tAcc: 81.68604%\n",
      "Step:   500\tLoss: 0.472\tAcc: 86.33721%\n",
      "Step:   600\tLoss: 0.383\tAcc: 88.66279%\n",
      "Step:   700\tLoss: 0.324\tAcc: 91.86047%\n",
      "Step:   800\tLoss: 0.284\tAcc: 92.73256%\n",
      "Step:   900\tLoss: 0.256\tAcc: 93.60465%\n",
      "Step:  1000\tLoss: 0.234\tAcc: 94.18604%\n",
      "Step:  1100\tLoss: 0.216\tAcc: 95.05814%\n",
      "Step:  1200\tLoss: 0.202\tAcc: 95.05814%\n",
      "Step:  1300\tLoss: 0.189\tAcc: 96.51163%\n",
      "Step:  1400\tLoss: 0.177\tAcc: 96.51163%\n",
      "Step:  1500\tLoss: 0.167\tAcc: 97.09302%\n",
      "Step:  1600\tLoss: 0.159\tAcc: 97.38372%\n",
      "Step:  1700\tLoss: 0.151\tAcc: 97.67442%\n",
      "Step:  1800\tLoss: 0.145\tAcc: 97.67442%\n",
      "Step:  1900\tLoss: 0.139\tAcc: 97.67442%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9767442\n",
      "Test Prediction = 0.8565217\n",
      "=========== RUN 13=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 3.140\tAcc: 50.00000%\n",
      "Step:   100\tLoss: 0.918\tAcc: 70.34883%\n",
      "Step:   200\tLoss: 0.601\tAcc: 79.94186%\n",
      "Step:   300\tLoss: 0.478\tAcc: 85.17442%\n",
      "Step:   400\tLoss: 0.404\tAcc: 87.20930%\n",
      "Step:   500\tLoss: 0.349\tAcc: 90.11628%\n",
      "Step:   600\tLoss: 0.308\tAcc: 91.56977%\n",
      "Step:   700\tLoss: 0.277\tAcc: 92.73256%\n",
      "Step:   800\tLoss: 0.251\tAcc: 93.89535%\n",
      "Step:   900\tLoss: 0.230\tAcc: 94.18604%\n",
      "Step:  1000\tLoss: 0.213\tAcc: 94.47674%\n",
      "Step:  1100\tLoss: 0.199\tAcc: 94.47674%\n",
      "Step:  1200\tLoss: 0.187\tAcc: 94.47674%\n",
      "Step:  1300\tLoss: 0.176\tAcc: 95.93023%\n",
      "Step:  1400\tLoss: 0.166\tAcc: 96.51163%\n",
      "Step:  1500\tLoss: 0.157\tAcc: 96.80232%\n",
      "Step:  1600\tLoss: 0.150\tAcc: 96.80232%\n",
      "Step:  1700\tLoss: 0.143\tAcc: 97.09302%\n",
      "Step:  1800\tLoss: 0.136\tAcc: 97.38372%\n",
      "Step:  1900\tLoss: 0.129\tAcc: 97.38372%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9738372\n",
      "Test Prediction = 0.84782606\n",
      "=========== RUN 14=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 4.847\tAcc: 43.31395%\n",
      "Step:   100\tLoss: 0.676\tAcc: 74.70930%\n",
      "Step:   200\tLoss: 0.471\tAcc: 82.55814%\n",
      "Step:   300\tLoss: 0.373\tAcc: 85.17442%\n",
      "Step:   400\tLoss: 0.314\tAcc: 86.62791%\n",
      "Step:   500\tLoss: 0.272\tAcc: 89.53488%\n",
      "Step:   600\tLoss: 0.239\tAcc: 91.56977%\n",
      "Step:   700\tLoss: 0.213\tAcc: 92.15117%\n",
      "Step:   800\tLoss: 0.193\tAcc: 93.31396%\n",
      "Step:   900\tLoss: 0.176\tAcc: 94.18604%\n",
      "Step:  1000\tLoss: 0.163\tAcc: 95.34883%\n",
      "Step:  1100\tLoss: 0.151\tAcc: 96.22093%\n",
      "Step:  1200\tLoss: 0.142\tAcc: 96.22093%\n",
      "Step:  1300\tLoss: 0.134\tAcc: 96.80232%\n",
      "Step:  1400\tLoss: 0.126\tAcc: 96.80232%\n",
      "Step:  1500\tLoss: 0.120\tAcc: 97.96512%\n",
      "Step:  1600\tLoss: 0.114\tAcc: 98.25581%\n",
      "Step:  1700\tLoss: 0.109\tAcc: 99.12791%\n",
      "Step:  1800\tLoss: 0.105\tAcc: 99.12791%\n",
      "Step:  1900\tLoss: 0.101\tAcc: 99.12791%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.99127907\n",
      "Test Prediction = 0.8913044\n",
      "=========== RUN 15=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 16.824\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 5.462\tAcc: 48.25581%\n",
      "Step:   200\tLoss: 1.601\tAcc: 58.13953%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:   300\tLoss: 0.889\tAcc: 76.74419%\n",
      "Step:   400\tLoss: 0.636\tAcc: 83.43023%\n",
      "Step:   500\tLoss: 0.488\tAcc: 86.33721%\n",
      "Step:   600\tLoss: 0.390\tAcc: 89.24419%\n",
      "Step:   700\tLoss: 0.327\tAcc: 91.86047%\n",
      "Step:   800\tLoss: 0.282\tAcc: 93.02326%\n",
      "Step:   900\tLoss: 0.252\tAcc: 94.18604%\n",
      "Step:  1000\tLoss: 0.231\tAcc: 94.76744%\n",
      "Step:  1100\tLoss: 0.216\tAcc: 95.93023%\n",
      "Step:  1200\tLoss: 0.204\tAcc: 96.80232%\n",
      "Step:  1300\tLoss: 0.194\tAcc: 97.38372%\n",
      "Step:  1400\tLoss: 0.185\tAcc: 97.38372%\n",
      "Step:  1500\tLoss: 0.178\tAcc: 97.38372%\n",
      "Step:  1600\tLoss: 0.171\tAcc: 97.96512%\n",
      "Step:  1700\tLoss: 0.164\tAcc: 97.96512%\n",
      "Step:  1800\tLoss: 0.158\tAcc: 98.54651%\n",
      "Step:  1900\tLoss: 0.152\tAcc: 98.83721%\n",
      "Step:  2000\tLoss: 0.147\tAcc: 98.83721%\n",
      "Step:  2100\tLoss: 0.141\tAcc: 99.12791%\n",
      "Step:  2200\tLoss: 0.136\tAcc: 99.12791%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.99127907\n",
      "Test Prediction = 0.8652174\n",
      "=========== RUN 16=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 4.593\tAcc: 49.12791%\n",
      "Step:   100\tLoss: 1.337\tAcc: 68.60465%\n",
      "Step:   200\tLoss: 0.808\tAcc: 77.90698%\n",
      "Step:   300\tLoss: 0.596\tAcc: 83.72093%\n",
      "Step:   400\tLoss: 0.477\tAcc: 85.46512%\n",
      "Step:   500\tLoss: 0.397\tAcc: 87.79070%\n",
      "Step:   600\tLoss: 0.339\tAcc: 89.53488%\n",
      "Step:   700\tLoss: 0.294\tAcc: 90.69768%\n",
      "Step:   800\tLoss: 0.260\tAcc: 91.86047%\n",
      "Step:   900\tLoss: 0.233\tAcc: 93.89535%\n",
      "Step:  1000\tLoss: 0.211\tAcc: 94.18604%\n",
      "Step:  1100\tLoss: 0.193\tAcc: 94.47674%\n",
      "Step:  1200\tLoss: 0.178\tAcc: 95.05814%\n",
      "Step:  1300\tLoss: 0.165\tAcc: 95.63953%\n",
      "Step:  1400\tLoss: 0.154\tAcc: 96.51163%\n",
      "Step:  1500\tLoss: 0.145\tAcc: 96.51163%\n",
      "Step:  1600\tLoss: 0.137\tAcc: 96.51163%\n",
      "Step:  1700\tLoss: 0.130\tAcc: 97.09302%\n",
      "Step:  1800\tLoss: 0.124\tAcc: 97.09302%\n",
      "Step:  1900\tLoss: 0.118\tAcc: 97.09302%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9709302\n",
      "Test Prediction = 0.87826085\n",
      "=========== RUN 17=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 5.706\tAcc: 48.83721%\n",
      "Step:   100\tLoss: 1.334\tAcc: 72.09302%\n",
      "Step:   200\tLoss: 0.731\tAcc: 79.36047%\n",
      "Step:   300\tLoss: 0.513\tAcc: 83.72093%\n",
      "Step:   400\tLoss: 0.394\tAcc: 88.08140%\n",
      "Step:   500\tLoss: 0.323\tAcc: 92.73256%\n",
      "Step:   600\tLoss: 0.280\tAcc: 93.31396%\n",
      "Step:   700\tLoss: 0.247\tAcc: 94.18604%\n",
      "Step:   800\tLoss: 0.219\tAcc: 94.47674%\n",
      "Step:   900\tLoss: 0.195\tAcc: 94.76744%\n",
      "Step:  1000\tLoss: 0.176\tAcc: 95.34883%\n",
      "Step:  1100\tLoss: 0.161\tAcc: 95.93023%\n",
      "Step:  1200\tLoss: 0.149\tAcc: 96.51163%\n",
      "Step:  1300\tLoss: 0.137\tAcc: 96.80232%\n",
      "Step:  1400\tLoss: 0.127\tAcc: 97.09302%\n",
      "Step:  1500\tLoss: 0.119\tAcc: 97.38372%\n",
      "Step:  1600\tLoss: 0.112\tAcc: 97.67442%\n",
      "Step:  1700\tLoss: 0.106\tAcc: 97.67442%\n",
      "Step:  1800\tLoss: 0.100\tAcc: 97.67442%\n",
      "Step:  1900\tLoss: 0.096\tAcc: 97.67442%\n",
      "Step:  2000\tLoss: 0.092\tAcc: 98.25581%\n",
      "Step:  2100\tLoss: 0.089\tAcc: 98.25581%\n",
      "Step:  2200\tLoss: 0.086\tAcc: 98.25581%\n",
      "Step:  2300\tLoss: 0.084\tAcc: 98.54651%\n",
      "Step:  2400\tLoss: 0.082\tAcc: 98.54651%\n",
      "Step:  2500\tLoss: 0.079\tAcc: 98.54651%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9854651\n",
      "Test Prediction = 0.8652174\n",
      "=========== RUN 18=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 11.646\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 4.019\tAcc: 49.70930%\n",
      "Step:   200\tLoss: 2.005\tAcc: 59.59302%\n",
      "Step:   300\tLoss: 1.302\tAcc: 64.24419%\n",
      "Step:   400\tLoss: 0.915\tAcc: 73.54651%\n",
      "Step:   500\tLoss: 0.677\tAcc: 80.23256%\n",
      "Step:   600\tLoss: 0.523\tAcc: 84.01163%\n",
      "Step:   700\tLoss: 0.432\tAcc: 85.75581%\n",
      "Step:   800\tLoss: 0.370\tAcc: 87.50000%\n",
      "Step:   900\tLoss: 0.325\tAcc: 90.69768%\n",
      "Step:  1000\tLoss: 0.290\tAcc: 91.56977%\n",
      "Step:  1100\tLoss: 0.262\tAcc: 93.89535%\n",
      "Step:  1200\tLoss: 0.237\tAcc: 94.18604%\n",
      "Step:  1300\tLoss: 0.215\tAcc: 95.93023%\n",
      "Step:  1400\tLoss: 0.198\tAcc: 96.22093%\n",
      "Step:  1500\tLoss: 0.183\tAcc: 97.09302%\n",
      "Step:  1600\tLoss: 0.171\tAcc: 97.38372%\n",
      "Step:  1700\tLoss: 0.161\tAcc: 97.67442%\n",
      "Step:  1800\tLoss: 0.152\tAcc: 97.67442%\n",
      "Step:  1900\tLoss: 0.145\tAcc: 97.96512%\n",
      "Step:  2000\tLoss: 0.138\tAcc: 98.54651%\n",
      "Step:  2100\tLoss: 0.131\tAcc: 98.54651%\n",
      "Step:  2200\tLoss: 0.126\tAcc: 98.54651%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9854651\n",
      "Test Prediction = 0.87826085\n",
      "=========== RUN 19=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 6.807\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 1.937\tAcc: 53.19768%\n",
      "Step:   200\tLoss: 1.088\tAcc: 66.86047%\n",
      "Step:   300\tLoss: 0.770\tAcc: 72.09302%\n",
      "Step:   400\tLoss: 0.587\tAcc: 78.77907%\n",
      "Step:   500\tLoss: 0.480\tAcc: 82.26744%\n",
      "Step:   600\tLoss: 0.398\tAcc: 85.46512%\n",
      "Step:   700\tLoss: 0.339\tAcc: 87.79070%\n",
      "Step:   800\tLoss: 0.291\tAcc: 89.24419%\n",
      "Step:   900\tLoss: 0.252\tAcc: 92.44186%\n",
      "Step:  1000\tLoss: 0.224\tAcc: 93.31396%\n",
      "Step:  1100\tLoss: 0.204\tAcc: 94.18604%\n",
      "Step:  1200\tLoss: 0.189\tAcc: 94.76744%\n",
      "Step:  1300\tLoss: 0.178\tAcc: 94.76744%\n",
      "Step:  1400\tLoss: 0.169\tAcc: 95.63953%\n",
      "Step:  1500\tLoss: 0.161\tAcc: 95.63953%\n",
      "Step:  1600\tLoss: 0.154\tAcc: 96.22093%\n",
      "Step:  1700\tLoss: 0.147\tAcc: 96.22093%\n",
      "Step:  1800\tLoss: 0.141\tAcc: 96.22093%\n",
      "Step:  1900\tLoss: 0.136\tAcc: 95.93023%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9593023\n",
      "Test Prediction = 0.8695652\n",
      "=========== RUN 20=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 7.027\tAcc: 48.25581%\n",
      "Step:   100\tLoss: 1.667\tAcc: 63.66279%\n",
      "Step:   200\tLoss: 0.808\tAcc: 77.03488%\n",
      "Step:   300\tLoss: 0.545\tAcc: 82.84883%\n",
      "Step:   400\tLoss: 0.418\tAcc: 86.62791%\n",
      "Step:   500\tLoss: 0.347\tAcc: 89.53488%\n",
      "Step:   600\tLoss: 0.296\tAcc: 90.69768%\n",
      "Step:   700\tLoss: 0.258\tAcc: 93.31396%\n",
      "Step:   800\tLoss: 0.228\tAcc: 93.60465%\n",
      "Step:   900\tLoss: 0.203\tAcc: 94.18604%\n",
      "Step:  1000\tLoss: 0.183\tAcc: 94.76744%\n",
      "Step:  1100\tLoss: 0.168\tAcc: 95.63953%\n",
      "Step:  1200\tLoss: 0.154\tAcc: 95.63953%\n",
      "Step:  1300\tLoss: 0.142\tAcc: 96.22093%\n",
      "Step:  1400\tLoss: 0.133\tAcc: 97.38372%\n",
      "Step:  1500\tLoss: 0.125\tAcc: 97.67442%\n",
      "Step:  1600\tLoss: 0.117\tAcc: 97.67442%\n",
      "Step:  1700\tLoss: 0.111\tAcc: 97.96512%\n",
      "Step:  1800\tLoss: 0.105\tAcc: 97.96512%\n",
      "Step:  1900\tLoss: 0.100\tAcc: 97.96512%\n",
      "Step:  2000\tLoss: 0.096\tAcc: 98.25581%\n",
      "Step:  2100\tLoss: 0.091\tAcc: 98.54651%\n",
      "Step:  2200\tLoss: 0.087\tAcc: 98.54651%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9854651\n",
      "Test Prediction = 0.87391305\n",
      "=========== RUN 21=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 12.917\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 5.810\tAcc: 47.96512%\n",
      "Step:   200\tLoss: 2.106\tAcc: 54.65117%\n",
      "Step:   300\tLoss: 1.216\tAcc: 65.11628%\n",
      "Step:   400\tLoss: 0.776\tAcc: 72.96512%\n",
      "Step:   500\tLoss: 0.579\tAcc: 77.32558%\n",
      "Step:   600\tLoss: 0.478\tAcc: 81.39535%\n",
      "Step:   700\tLoss: 0.416\tAcc: 86.91860%\n",
      "Step:   800\tLoss: 0.374\tAcc: 88.66279%\n",
      "Step:   900\tLoss: 0.343\tAcc: 89.53488%\n",
      "Step:  1000\tLoss: 0.317\tAcc: 89.24419%\n",
      "Step:  1100\tLoss: 0.295\tAcc: 90.11628%\n",
      "Step:  1200\tLoss: 0.276\tAcc: 90.40698%\n",
      "Step:  1300\tLoss: 0.260\tAcc: 91.86047%\n",
      "Step:  1400\tLoss: 0.246\tAcc: 92.15117%\n",
      "Step:  1500\tLoss: 0.235\tAcc: 92.15117%\n",
      "Step:  1600\tLoss: 0.224\tAcc: 92.44186%\n",
      "Step:  1700\tLoss: 0.214\tAcc: 93.60465%\n",
      "Step:  1800\tLoss: 0.206\tAcc: 94.47674%\n",
      "Step:  1900\tLoss: 0.198\tAcc: 95.05814%\n",
      "Step:  2000\tLoss: 0.191\tAcc: 95.34883%\n",
      "Step:  2100\tLoss: 0.184\tAcc: 95.93023%\n",
      "Step:  2200\tLoss: 0.178\tAcc: 96.22093%\n",
      "Step:  2300\tLoss: 0.172\tAcc: 96.51163%\n",
      "Step:  2400\tLoss: 0.167\tAcc: 96.51163%\n",
      "Step:  2500\tLoss: 0.163\tAcc: 96.51163%\n",
      "Step:  2600\tLoss: 0.158\tAcc: 96.80232%\n",
      "Step:  2700\tLoss: 0.154\tAcc: 96.80232%\n",
      "Step:  2800\tLoss: 0.150\tAcc: 97.09302%\n",
      "Step:  2900\tLoss: 0.147\tAcc: 97.09302%\n",
      "Step:  3000\tLoss: 0.143\tAcc: 97.09302%\n",
      "Step:  3100\tLoss: 0.140\tAcc: 97.09302%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9709302\n",
      "Test Prediction = 0.84347826\n",
      "=========== RUN 22=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 2.369\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 1.063\tAcc: 65.40698%\n",
      "Step:   200\tLoss: 0.716\tAcc: 77.61628%\n",
      "Step:   300\tLoss: 0.547\tAcc: 82.26744%\n",
      "Step:   400\tLoss: 0.449\tAcc: 85.75581%\n",
      "Step:   500\tLoss: 0.388\tAcc: 86.91860%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:   600\tLoss: 0.342\tAcc: 88.08140%\n",
      "Step:   700\tLoss: 0.304\tAcc: 88.08140%\n",
      "Step:   800\tLoss: 0.274\tAcc: 89.53488%\n",
      "Step:   900\tLoss: 0.250\tAcc: 90.98837%\n",
      "Step:  1000\tLoss: 0.231\tAcc: 92.44186%\n",
      "Step:  1100\tLoss: 0.214\tAcc: 92.73256%\n",
      "Step:  1200\tLoss: 0.202\tAcc: 93.02326%\n",
      "Step:  1300\tLoss: 0.190\tAcc: 93.60465%\n",
      "Step:  1400\tLoss: 0.181\tAcc: 94.76744%\n",
      "Step:  1500\tLoss: 0.172\tAcc: 94.76744%\n",
      "Step:  1600\tLoss: 0.164\tAcc: 95.05814%\n",
      "Step:  1700\tLoss: 0.157\tAcc: 96.22093%\n",
      "Step:  1800\tLoss: 0.150\tAcc: 96.80232%\n",
      "Step:  1900\tLoss: 0.145\tAcc: 96.80232%\n",
      "Step:  2000\tLoss: 0.140\tAcc: 97.09302%\n",
      "Step:  2100\tLoss: 0.135\tAcc: 97.38372%\n",
      "Step:  2200\tLoss: 0.132\tAcc: 97.38372%\n",
      "Step:  2300\tLoss: 0.128\tAcc: 97.67442%\n",
      "Step:  2400\tLoss: 0.125\tAcc: 97.67442%\n",
      "Step:  2500\tLoss: 0.122\tAcc: 97.67442%\n",
      "Step:  2600\tLoss: 0.119\tAcc: 97.96512%\n",
      "Step:  2700\tLoss: 0.116\tAcc: 98.25581%\n",
      "Step:  2800\tLoss: 0.113\tAcc: 98.25581%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.98255813\n",
      "Test Prediction = 0.87826085\n",
      "=========== RUN 23=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 6.800\tAcc: 48.25581%\n",
      "Step:   100\tLoss: 1.467\tAcc: 59.88372%\n",
      "Step:   200\tLoss: 0.762\tAcc: 76.74419%\n",
      "Step:   300\tLoss: 0.537\tAcc: 82.55814%\n",
      "Step:   400\tLoss: 0.430\tAcc: 84.88372%\n",
      "Step:   500\tLoss: 0.367\tAcc: 88.08140%\n",
      "Step:   600\tLoss: 0.323\tAcc: 90.40698%\n",
      "Step:   700\tLoss: 0.290\tAcc: 92.44186%\n",
      "Step:   800\tLoss: 0.264\tAcc: 93.89535%\n",
      "Step:   900\tLoss: 0.243\tAcc: 94.47674%\n",
      "Step:  1000\tLoss: 0.226\tAcc: 95.05814%\n",
      "Step:  1100\tLoss: 0.211\tAcc: 95.63953%\n",
      "Step:  1200\tLoss: 0.197\tAcc: 95.63953%\n",
      "Step:  1300\tLoss: 0.185\tAcc: 95.93023%\n",
      "Step:  1400\tLoss: 0.174\tAcc: 95.93023%\n",
      "Step:  1500\tLoss: 0.164\tAcc: 96.22093%\n",
      "Step:  1600\tLoss: 0.155\tAcc: 96.22093%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9622093\n",
      "Test Prediction = 0.8304348\n",
      "=========== RUN 24=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 4.631\tAcc: 48.54651%\n",
      "Step:   100\tLoss: 1.544\tAcc: 56.68604%\n",
      "Step:   200\tLoss: 1.043\tAcc: 65.40698%\n",
      "Step:   300\tLoss: 0.794\tAcc: 77.61628%\n",
      "Step:   400\tLoss: 0.652\tAcc: 81.39535%\n",
      "Step:   500\tLoss: 0.553\tAcc: 86.04651%\n",
      "Step:   600\tLoss: 0.480\tAcc: 87.20930%\n",
      "Step:   700\tLoss: 0.424\tAcc: 89.24419%\n",
      "Step:   800\tLoss: 0.382\tAcc: 90.11628%\n",
      "Step:   900\tLoss: 0.345\tAcc: 90.69768%\n",
      "Step:  1000\tLoss: 0.315\tAcc: 92.73256%\n",
      "Step:  1100\tLoss: 0.291\tAcc: 93.02326%\n",
      "Step:  1200\tLoss: 0.270\tAcc: 94.18604%\n",
      "Step:  1300\tLoss: 0.251\tAcc: 94.76744%\n",
      "Step:  1400\tLoss: 0.234\tAcc: 94.76744%\n",
      "Step:  1500\tLoss: 0.219\tAcc: 95.34883%\n",
      "Step:  1600\tLoss: 0.204\tAcc: 95.93023%\n",
      "Step:  1700\tLoss: 0.191\tAcc: 96.51163%\n",
      "Step:  1800\tLoss: 0.180\tAcc: 96.51163%\n",
      "Step:  1900\tLoss: 0.170\tAcc: 96.51163%\n",
      "Step:  2000\tLoss: 0.161\tAcc: 97.38372%\n",
      "Step:  2100\tLoss: 0.153\tAcc: 97.38372%\n",
      "Step:  2200\tLoss: 0.146\tAcc: 97.67442%\n",
      "Step:  2300\tLoss: 0.140\tAcc: 97.67442%\n",
      "Step:  2400\tLoss: 0.133\tAcc: 97.67442%\n",
      "Step:  2500\tLoss: 0.128\tAcc: 97.96512%\n",
      "Step:  2600\tLoss: 0.123\tAcc: 97.96512%\n",
      "Step:  2700\tLoss: 0.119\tAcc: 97.96512%\n",
      "Step:  2800\tLoss: 0.115\tAcc: 98.25581%\n",
      "Step:  2900\tLoss: 0.111\tAcc: 98.54651%\n",
      "Step:  3000\tLoss: 0.108\tAcc: 98.54651%\n",
      "Step:  3100\tLoss: 0.105\tAcc: 98.54651%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9854651\n",
      "Test Prediction = 0.8565217\n",
      "=========== RUN 25=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 8.369\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 2.615\tAcc: 50.00000%\n",
      "Step:   200\tLoss: 1.395\tAcc: 61.04651%\n",
      "Step:   300\tLoss: 0.884\tAcc: 71.22093%\n",
      "Step:   400\tLoss: 0.637\tAcc: 77.90698%\n",
      "Step:   500\tLoss: 0.487\tAcc: 82.84883%\n",
      "Step:   600\tLoss: 0.390\tAcc: 86.33721%\n",
      "Step:   700\tLoss: 0.325\tAcc: 89.24419%\n",
      "Step:   800\tLoss: 0.280\tAcc: 90.69768%\n",
      "Step:   900\tLoss: 0.247\tAcc: 93.60465%\n",
      "Step:  1000\tLoss: 0.221\tAcc: 95.34883%\n",
      "Step:  1100\tLoss: 0.198\tAcc: 95.63953%\n",
      "Step:  1200\tLoss: 0.180\tAcc: 96.22093%\n",
      "Step:  1300\tLoss: 0.165\tAcc: 96.51163%\n",
      "Step:  1400\tLoss: 0.152\tAcc: 96.80232%\n",
      "Step:  1500\tLoss: 0.142\tAcc: 96.80232%\n",
      "Step:  1600\tLoss: 0.134\tAcc: 97.09302%\n",
      "Step:  1700\tLoss: 0.126\tAcc: 97.38372%\n",
      "Step:  1800\tLoss: 0.120\tAcc: 97.38372%\n",
      "Step:  1900\tLoss: 0.115\tAcc: 97.96512%\n",
      "Step:  2000\tLoss: 0.109\tAcc: 98.25581%\n",
      "Step:  2100\tLoss: 0.104\tAcc: 98.54651%\n",
      "Step:  2200\tLoss: 0.100\tAcc: 98.54651%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9854651\n",
      "Test Prediction = 0.8913044\n",
      "=========== RUN 26=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 8.999\tAcc: 43.60465%\n",
      "Step:   100\tLoss: 3.508\tAcc: 41.86046%\n",
      "Step:   200\tLoss: 2.114\tAcc: 51.45349%\n",
      "Step:   300\tLoss: 1.396\tAcc: 65.69768%\n",
      "Step:   400\tLoss: 1.016\tAcc: 71.22093%\n",
      "Step:   500\tLoss: 0.766\tAcc: 78.19768%\n",
      "Step:   600\tLoss: 0.598\tAcc: 78.48837%\n",
      "Step:   700\tLoss: 0.487\tAcc: 82.55814%\n",
      "Step:   800\tLoss: 0.416\tAcc: 86.62791%\n",
      "Step:   900\tLoss: 0.363\tAcc: 88.37209%\n",
      "Step:  1000\tLoss: 0.323\tAcc: 90.69768%\n",
      "Step:  1100\tLoss: 0.293\tAcc: 91.86047%\n",
      "Step:  1200\tLoss: 0.268\tAcc: 93.60465%\n",
      "Step:  1300\tLoss: 0.250\tAcc: 93.60465%\n",
      "Step:  1400\tLoss: 0.236\tAcc: 93.89535%\n",
      "Step:  1500\tLoss: 0.224\tAcc: 93.89535%\n",
      "Step:  1600\tLoss: 0.214\tAcc: 93.89535%\n",
      "Step:  1700\tLoss: 0.206\tAcc: 94.76744%\n",
      "Step:  1800\tLoss: 0.198\tAcc: 95.05814%\n",
      "Step:  1900\tLoss: 0.191\tAcc: 94.76744%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9476744\n",
      "Test Prediction = 0.8608696\n",
      "=========== RUN 27=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 19.594\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 12.946\tAcc: 47.67442%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.47674417\n",
      "Test Prediction = 0.5347826\n",
      "=========== RUN 28=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 3.789\tAcc: 53.19768%\n",
      "Step:   100\tLoss: 0.712\tAcc: 75.87209%\n",
      "Step:   200\tLoss: 0.470\tAcc: 85.75581%\n",
      "Step:   300\tLoss: 0.371\tAcc: 88.37209%\n",
      "Step:   400\tLoss: 0.323\tAcc: 90.98837%\n",
      "Step:   500\tLoss: 0.288\tAcc: 91.86047%\n",
      "Step:   600\tLoss: 0.260\tAcc: 92.44186%\n",
      "Step:   700\tLoss: 0.238\tAcc: 93.02326%\n",
      "Step:   800\tLoss: 0.219\tAcc: 93.02326%\n",
      "Step:   900\tLoss: 0.202\tAcc: 93.02326%\n",
      "Step:  1000\tLoss: 0.188\tAcc: 93.31396%\n",
      "Step:  1100\tLoss: 0.176\tAcc: 94.47674%\n",
      "Step:  1200\tLoss: 0.165\tAcc: 95.05814%\n",
      "Step:  1300\tLoss: 0.156\tAcc: 95.05814%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9505814\n",
      "Test Prediction = 0.84782606\n",
      "=========== RUN 29=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 9.272\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 2.015\tAcc: 55.52326%\n",
      "Step:   200\tLoss: 0.785\tAcc: 71.51163%\n",
      "Step:   300\tLoss: 0.513\tAcc: 84.59302%\n",
      "Step:   400\tLoss: 0.405\tAcc: 87.20930%\n",
      "Step:   500\tLoss: 0.336\tAcc: 89.82558%\n",
      "Step:   600\tLoss: 0.293\tAcc: 90.11628%\n",
      "Step:   700\tLoss: 0.259\tAcc: 90.98837%\n",
      "Step:   800\tLoss: 0.234\tAcc: 94.47674%\n",
      "Step:   900\tLoss: 0.216\tAcc: 94.76744%\n",
      "Step:  1000\tLoss: 0.202\tAcc: 95.34883%\n",
      "Step:  1100\tLoss: 0.191\tAcc: 95.93023%\n",
      "Step:  1200\tLoss: 0.182\tAcc: 96.22093%\n",
      "Step:  1300\tLoss: 0.174\tAcc: 96.80232%\n",
      "Step:  1400\tLoss: 0.167\tAcc: 96.80232%\n",
      "Step:  1500\tLoss: 0.161\tAcc: 97.67442%\n",
      "Step:  1600\tLoss: 0.155\tAcc: 97.67442%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9767442\n",
      "Test Prediction = 0.8652174\n",
      "=========== RUN 30=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 2.437\tAcc: 47.38372%\n",
      "Step:   100\tLoss: 0.823\tAcc: 77.90698%\n",
      "Step:   200\tLoss: 0.624\tAcc: 83.13953%\n",
      "Step:   300\tLoss: 0.512\tAcc: 85.17442%\n",
      "Step:   400\tLoss: 0.438\tAcc: 86.04651%\n",
      "Step:   500\tLoss: 0.381\tAcc: 88.37209%\n",
      "Step:   600\tLoss: 0.338\tAcc: 89.82558%\n",
      "Step:   700\tLoss: 0.303\tAcc: 90.98837%\n",
      "Step:   800\tLoss: 0.274\tAcc: 91.56977%\n",
      "Step:   900\tLoss: 0.246\tAcc: 93.31396%\n",
      "Step:  1000\tLoss: 0.225\tAcc: 94.18604%\n",
      "Step:  1100\tLoss: 0.207\tAcc: 94.18604%\n",
      "Step:  1200\tLoss: 0.192\tAcc: 94.47674%\n",
      "Step:  1300\tLoss: 0.179\tAcc: 95.05814%\n",
      "Step:  1400\tLoss: 0.168\tAcc: 95.93023%\n",
      "Step:  1500\tLoss: 0.158\tAcc: 96.22093%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  1600\tLoss: 0.150\tAcc: 96.51163%\n",
      "Step:  1700\tLoss: 0.142\tAcc: 96.51163%\n",
      "Step:  1800\tLoss: 0.135\tAcc: 97.09302%\n",
      "Step:  1900\tLoss: 0.129\tAcc: 97.38372%\n",
      "Step:  2000\tLoss: 0.123\tAcc: 97.38372%\n",
      "Step:  2100\tLoss: 0.117\tAcc: 97.38372%\n",
      "Step:  2200\tLoss: 0.111\tAcc: 97.96512%\n",
      "Step:  2300\tLoss: 0.103\tAcc: 98.25581%\n",
      "Step:  2400\tLoss: 0.099\tAcc: 98.25581%\n",
      "Step:  2500\tLoss: 0.095\tAcc: 98.54651%\n",
      "Step:  2600\tLoss: 0.091\tAcc: 98.83721%\n",
      "Step:  2700\tLoss: 0.088\tAcc: 98.83721%\n",
      "Step:  2800\tLoss: 0.085\tAcc: 98.83721%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9883721\n",
      "Test Prediction = 0.8826087\n",
      "=========== RUN 31=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 5.788\tAcc: 48.25581%\n",
      "Step:   100\tLoss: 1.582\tAcc: 59.88372%\n",
      "Step:   200\tLoss: 0.836\tAcc: 68.60465%\n",
      "Step:   300\tLoss: 0.567\tAcc: 81.97674%\n",
      "Step:   400\tLoss: 0.425\tAcc: 87.20930%\n",
      "Step:   500\tLoss: 0.336\tAcc: 88.95349%\n",
      "Step:   600\tLoss: 0.274\tAcc: 90.11628%\n",
      "Step:   700\tLoss: 0.227\tAcc: 91.56977%\n",
      "Step:   800\tLoss: 0.191\tAcc: 93.02326%\n",
      "Step:   900\tLoss: 0.168\tAcc: 94.76744%\n",
      "Step:  1000\tLoss: 0.151\tAcc: 95.63953%\n",
      "Step:  1100\tLoss: 0.139\tAcc: 96.22093%\n",
      "Step:  1200\tLoss: 0.129\tAcc: 96.80232%\n",
      "Step:  1300\tLoss: 0.120\tAcc: 97.38372%\n",
      "Step:  1400\tLoss: 0.113\tAcc: 98.25581%\n",
      "Step:  1500\tLoss: 0.106\tAcc: 98.25581%\n",
      "Step:  1600\tLoss: 0.101\tAcc: 98.54651%\n",
      "Step:  1700\tLoss: 0.096\tAcc: 98.54651%\n",
      "Step:  1800\tLoss: 0.092\tAcc: 99.41860%\n",
      "Step:  1900\tLoss: 0.089\tAcc: 99.41860%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.99418604\n",
      "Test Prediction = 0.8913044\n",
      "=========== RUN 32=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 3.586\tAcc: 50.00000%\n",
      "Step:   100\tLoss: 1.188\tAcc: 63.95349%\n",
      "Step:   200\tLoss: 0.774\tAcc: 73.83721%\n",
      "Step:   300\tLoss: 0.603\tAcc: 78.77907%\n",
      "Step:   400\tLoss: 0.506\tAcc: 83.13953%\n",
      "Step:   500\tLoss: 0.432\tAcc: 87.50000%\n",
      "Step:   600\tLoss: 0.375\tAcc: 90.69768%\n",
      "Step:   700\tLoss: 0.330\tAcc: 91.56977%\n",
      "Step:   800\tLoss: 0.299\tAcc: 92.44186%\n",
      "Step:   900\tLoss: 0.273\tAcc: 93.02326%\n",
      "Step:  1000\tLoss: 0.251\tAcc: 93.89535%\n",
      "Step:  1100\tLoss: 0.232\tAcc: 94.47674%\n",
      "Step:  1200\tLoss: 0.216\tAcc: 95.34883%\n",
      "Step:  1300\tLoss: 0.202\tAcc: 95.63953%\n",
      "Step:  1400\tLoss: 0.191\tAcc: 95.63953%\n",
      "Step:  1500\tLoss: 0.180\tAcc: 96.80232%\n",
      "Step:  1600\tLoss: 0.171\tAcc: 97.09302%\n",
      "Step:  1700\tLoss: 0.163\tAcc: 97.38372%\n",
      "Step:  1800\tLoss: 0.156\tAcc: 97.38372%\n",
      "Step:  1900\tLoss: 0.149\tAcc: 97.38372%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9738372\n",
      "Test Prediction = 0.84347826\n",
      "=========== RUN 33=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 14.201\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 7.300\tAcc: 47.67442%\n",
      "Step:   200\tLoss: 3.105\tAcc: 50.29070%\n",
      "Step:   300\tLoss: 1.861\tAcc: 52.61628%\n",
      "Step:   400\tLoss: 1.284\tAcc: 59.88372%\n",
      "Step:   500\tLoss: 0.930\tAcc: 69.76744%\n",
      "Step:   600\tLoss: 0.703\tAcc: 75.29070%\n",
      "Step:   700\tLoss: 0.561\tAcc: 79.65117%\n",
      "Step:   800\tLoss: 0.475\tAcc: 81.97674%\n",
      "Step:   900\tLoss: 0.414\tAcc: 83.43023%\n",
      "Step:  1000\tLoss: 0.366\tAcc: 86.04651%\n",
      "Step:  1100\tLoss: 0.328\tAcc: 88.66279%\n",
      "Step:  1200\tLoss: 0.295\tAcc: 90.69768%\n",
      "Step:  1300\tLoss: 0.269\tAcc: 92.73256%\n",
      "Step:  1400\tLoss: 0.249\tAcc: 93.60465%\n",
      "Step:  1500\tLoss: 0.233\tAcc: 93.89535%\n",
      "Step:  1600\tLoss: 0.219\tAcc: 93.60465%\n",
      "Step:  1700\tLoss: 0.205\tAcc: 94.18604%\n",
      "Step:  1800\tLoss: 0.194\tAcc: 95.34883%\n",
      "Step:  1900\tLoss: 0.184\tAcc: 95.63953%\n",
      "Step:  2000\tLoss: 0.176\tAcc: 95.63953%\n",
      "Step:  2100\tLoss: 0.169\tAcc: 95.93023%\n",
      "Step:  2200\tLoss: 0.162\tAcc: 96.22093%\n",
      "Step:  2300\tLoss: 0.156\tAcc: 96.51163%\n",
      "Step:  2400\tLoss: 0.151\tAcc: 96.80232%\n",
      "Step:  2500\tLoss: 0.145\tAcc: 97.09302%\n",
      "Step:  2600\tLoss: 0.141\tAcc: 97.09302%\n",
      "Step:  2700\tLoss: 0.137\tAcc: 97.38372%\n",
      "Step:  2800\tLoss: 0.133\tAcc: 97.96512%\n",
      "Step:  2900\tLoss: 0.129\tAcc: 97.96512%\n",
      "Step:  3000\tLoss: 0.126\tAcc: 98.25581%\n",
      "Step:  3100\tLoss: 0.123\tAcc: 98.25581%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.98255813\n",
      "Test Prediction = 0.82173914\n",
      "=========== RUN 34=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 2.913\tAcc: 56.10465%\n",
      "Step:   100\tLoss: 0.884\tAcc: 76.45349%\n",
      "Step:   200\tLoss: 0.594\tAcc: 85.75581%\n",
      "Step:   300\tLoss: 0.484\tAcc: 88.37209%\n",
      "Step:   400\tLoss: 0.421\tAcc: 90.11628%\n",
      "Step:   500\tLoss: 0.366\tAcc: 92.73256%\n",
      "Step:   600\tLoss: 0.333\tAcc: 93.60465%\n",
      "Step:   700\tLoss: 0.306\tAcc: 94.76744%\n",
      "Step:   800\tLoss: 0.283\tAcc: 95.63953%\n",
      "Step:   900\tLoss: 0.263\tAcc: 96.22093%\n",
      "Step:  1000\tLoss: 0.245\tAcc: 96.22093%\n",
      "Step:  1100\tLoss: 0.231\tAcc: 96.80232%\n",
      "Step:  1200\tLoss: 0.220\tAcc: 96.80232%\n",
      "Step:  1300\tLoss: 0.209\tAcc: 97.09302%\n",
      "Step:  1400\tLoss: 0.199\tAcc: 97.09302%\n",
      "Step:  1500\tLoss: 0.188\tAcc: 97.67442%\n",
      "Step:  1600\tLoss: 0.175\tAcc: 97.67442%\n",
      "Step:  1700\tLoss: 0.159\tAcc: 97.96512%\n",
      "Step:  1800\tLoss: 0.142\tAcc: 98.25581%\n",
      "Step:  1900\tLoss: 0.127\tAcc: 98.25581%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.98255813\n",
      "Test Prediction = 0.8608696\n",
      "=========== RUN 35=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 6.175\tAcc: 48.83721%\n",
      "Step:   100\tLoss: 1.987\tAcc: 58.43023%\n",
      "Step:   200\tLoss: 1.181\tAcc: 69.47674%\n",
      "Step:   300\tLoss: 0.867\tAcc: 71.80232%\n",
      "Step:   400\tLoss: 0.672\tAcc: 74.70930%\n",
      "Step:   500\tLoss: 0.529\tAcc: 79.36047%\n",
      "Step:   600\tLoss: 0.431\tAcc: 84.88372%\n",
      "Step:   700\tLoss: 0.355\tAcc: 87.50000%\n",
      "Step:   800\tLoss: 0.302\tAcc: 90.11628%\n",
      "Step:   900\tLoss: 0.262\tAcc: 90.98837%\n",
      "Step:  1000\tLoss: 0.226\tAcc: 92.44186%\n",
      "Step:  1100\tLoss: 0.194\tAcc: 94.18604%\n",
      "Step:  1200\tLoss: 0.173\tAcc: 95.05814%\n",
      "Step:  1300\tLoss: 0.157\tAcc: 95.93023%\n",
      "Step:  1400\tLoss: 0.143\tAcc: 96.51163%\n",
      "Step:  1500\tLoss: 0.132\tAcc: 96.51163%\n",
      "Step:  1600\tLoss: 0.122\tAcc: 97.67442%\n",
      "Step:  1700\tLoss: 0.114\tAcc: 97.67442%\n",
      "Step:  1800\tLoss: 0.106\tAcc: 97.67442%\n",
      "Step:  1900\tLoss: 0.100\tAcc: 97.96512%\n",
      "Step:  2000\tLoss: 0.095\tAcc: 97.96512%\n",
      "Step:  2100\tLoss: 0.090\tAcc: 97.96512%\n",
      "Step:  2200\tLoss: 0.085\tAcc: 97.96512%\n",
      "Step:  2300\tLoss: 0.081\tAcc: 98.25581%\n",
      "Step:  2400\tLoss: 0.077\tAcc: 98.83721%\n",
      "Step:  2500\tLoss: 0.073\tAcc: 99.12791%\n",
      "Step:  2600\tLoss: 0.069\tAcc: 99.41860%\n",
      "Step:  2700\tLoss: 0.066\tAcc: 99.41860%\n",
      "Step:  2800\tLoss: 0.064\tAcc: 99.41860%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.99418604\n",
      "Test Prediction = 0.87826085\n",
      "=========== RUN 36=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 2.525\tAcc: 37.20930%\n",
      "Step:   100\tLoss: 1.064\tAcc: 65.98837%\n",
      "Step:   200\tLoss: 0.738\tAcc: 73.54651%\n",
      "Step:   300\tLoss: 0.565\tAcc: 78.77907%\n",
      "Step:   400\tLoss: 0.456\tAcc: 84.01163%\n",
      "Step:   500\tLoss: 0.380\tAcc: 86.33721%\n",
      "Step:   600\tLoss: 0.327\tAcc: 90.11628%\n",
      "Step:   700\tLoss: 0.287\tAcc: 91.27907%\n",
      "Step:   800\tLoss: 0.257\tAcc: 92.15117%\n",
      "Step:   900\tLoss: 0.232\tAcc: 93.31396%\n",
      "Step:  1000\tLoss: 0.210\tAcc: 94.18604%\n",
      "Step:  1100\tLoss: 0.191\tAcc: 94.76744%\n",
      "Step:  1200\tLoss: 0.176\tAcc: 95.05814%\n",
      "Step:  1300\tLoss: 0.164\tAcc: 96.22093%\n",
      "Step:  1400\tLoss: 0.153\tAcc: 96.22093%\n",
      "Step:  1500\tLoss: 0.142\tAcc: 96.22093%\n",
      "Step:  1600\tLoss: 0.134\tAcc: 96.22093%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9622093\n",
      "Test Prediction = 0.8695652\n",
      "=========== RUN 37=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 20.820\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 12.338\tAcc: 47.67442%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.4651163\n",
      "Test Prediction = 0.47826087\n",
      "=========== RUN 38=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 3.504\tAcc: 52.90698%\n",
      "Step:   100\tLoss: 1.332\tAcc: 61.62791%\n",
      "Step:   200\tLoss: 0.942\tAcc: 69.76744%\n",
      "Step:   300\tLoss: 0.733\tAcc: 78.48837%\n",
      "Step:   400\tLoss: 0.595\tAcc: 82.84883%\n",
      "Step:   500\tLoss: 0.501\tAcc: 85.75581%\n",
      "Step:   600\tLoss: 0.433\tAcc: 88.08140%\n",
      "Step:   700\tLoss: 0.378\tAcc: 89.53488%\n",
      "Step:   800\tLoss: 0.332\tAcc: 90.69768%\n",
      "Step:   900\tLoss: 0.295\tAcc: 91.27907%\n",
      "Step:  1000\tLoss: 0.264\tAcc: 91.86047%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  1100\tLoss: 0.239\tAcc: 92.44186%\n",
      "Step:  1200\tLoss: 0.218\tAcc: 92.73256%\n",
      "Step:  1300\tLoss: 0.200\tAcc: 93.89535%\n",
      "Step:  1400\tLoss: 0.187\tAcc: 95.34883%\n",
      "Step:  1500\tLoss: 0.176\tAcc: 95.63953%\n",
      "Step:  1600\tLoss: 0.167\tAcc: 96.22093%\n",
      "Step:  1700\tLoss: 0.159\tAcc: 97.96512%\n",
      "Step:  1800\tLoss: 0.152\tAcc: 98.25581%\n",
      "Step:  1900\tLoss: 0.146\tAcc: 98.54651%\n",
      "Step:  2000\tLoss: 0.141\tAcc: 98.54651%\n",
      "Step:  2100\tLoss: 0.136\tAcc: 98.83721%\n",
      "Step:  2200\tLoss: 0.132\tAcc: 98.83721%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9883721\n",
      "Test Prediction = 0.84782606\n",
      "=========== RUN 39=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 14.095\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 6.342\tAcc: 47.67442%\n",
      "Step:   200\tLoss: 2.304\tAcc: 50.87209%\n",
      "Step:   300\tLoss: 1.278\tAcc: 63.08140%\n",
      "Step:   400\tLoss: 0.869\tAcc: 73.83721%\n",
      "Step:   500\tLoss: 0.680\tAcc: 78.19768%\n",
      "Step:   600\tLoss: 0.563\tAcc: 79.94186%\n",
      "Step:   700\tLoss: 0.481\tAcc: 83.43023%\n",
      "Step:   800\tLoss: 0.422\tAcc: 84.88372%\n",
      "Step:   900\tLoss: 0.378\tAcc: 85.46512%\n",
      "Step:  1000\tLoss: 0.346\tAcc: 88.37209%\n",
      "Step:  1100\tLoss: 0.319\tAcc: 89.24419%\n",
      "Step:  1200\tLoss: 0.295\tAcc: 89.82558%\n",
      "Step:  1300\tLoss: 0.273\tAcc: 90.98837%\n",
      "Step:  1400\tLoss: 0.253\tAcc: 91.56977%\n",
      "Step:  1500\tLoss: 0.236\tAcc: 91.56977%\n",
      "Step:  1600\tLoss: 0.221\tAcc: 92.15117%\n",
      "Step:  1700\tLoss: 0.208\tAcc: 92.44186%\n",
      "Step:  1800\tLoss: 0.195\tAcc: 92.44186%\n",
      "Step:  1900\tLoss: 0.184\tAcc: 93.60465%\n",
      "Step:  2000\tLoss: 0.174\tAcc: 93.89535%\n",
      "Step:  2100\tLoss: 0.166\tAcc: 94.47674%\n",
      "Step:  2200\tLoss: 0.158\tAcc: 95.05814%\n",
      "Step:  2300\tLoss: 0.152\tAcc: 95.34883%\n",
      "Step:  2400\tLoss: 0.144\tAcc: 95.63953%\n",
      "Step:  2500\tLoss: 0.138\tAcc: 96.51163%\n",
      "Step:  2600\tLoss: 0.133\tAcc: 96.80232%\n",
      "Step:  2700\tLoss: 0.128\tAcc: 96.80232%\n",
      "Step:  2800\tLoss: 0.124\tAcc: 96.80232%\n",
      "Step:  2900\tLoss: 0.120\tAcc: 97.09302%\n",
      "Step:  3000\tLoss: 0.117\tAcc: 97.09302%\n",
      "Step:  3100\tLoss: 0.113\tAcc: 97.09302%\n",
      "Step:  3200\tLoss: 0.110\tAcc: 97.38372%\n",
      "Step:  3300\tLoss: 0.108\tAcc: 97.38372%\n",
      "Step:  3400\tLoss: 0.105\tAcc: 97.38372%\n",
      "Step:  3500\tLoss: 0.103\tAcc: 97.67442%\n",
      "Step:  3600\tLoss: 0.100\tAcc: 97.67442%\n",
      "Step:  3700\tLoss: 0.098\tAcc: 97.67442%\n",
      "Step:  3800\tLoss: 0.096\tAcc: 97.96512%\n",
      "Step:  3900\tLoss: 0.095\tAcc: 98.25581%\n",
      "Step:  4000\tLoss: 0.093\tAcc: 98.25581%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.98255813\n",
      "Test Prediction = 0.83913046\n",
      "=========== RUN 40=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 11.050\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 3.510\tAcc: 43.89535%\n",
      "Step:   200\tLoss: 1.473\tAcc: 63.95349%\n",
      "Step:   300\tLoss: 0.896\tAcc: 74.41860%\n",
      "Step:   400\tLoss: 0.656\tAcc: 81.10465%\n",
      "Step:   500\tLoss: 0.521\tAcc: 85.46512%\n",
      "Step:   600\tLoss: 0.431\tAcc: 87.50000%\n",
      "Step:   700\tLoss: 0.370\tAcc: 88.95349%\n",
      "Step:   800\tLoss: 0.323\tAcc: 90.98837%\n",
      "Step:   900\tLoss: 0.284\tAcc: 92.15117%\n",
      "Step:  1000\tLoss: 0.248\tAcc: 93.02326%\n",
      "Step:  1100\tLoss: 0.222\tAcc: 93.02326%\n",
      "Step:  1200\tLoss: 0.201\tAcc: 93.60465%\n",
      "Step:  1300\tLoss: 0.183\tAcc: 93.31396%\n",
      "Step:  1400\tLoss: 0.167\tAcc: 94.76744%\n",
      "Step:  1500\tLoss: 0.154\tAcc: 95.34883%\n",
      "Step:  1600\tLoss: 0.143\tAcc: 95.93023%\n",
      "Step:  1700\tLoss: 0.134\tAcc: 96.22093%\n",
      "Step:  1800\tLoss: 0.126\tAcc: 96.51163%\n",
      "Step:  1900\tLoss: 0.119\tAcc: 97.38372%\n",
      "Step:  2000\tLoss: 0.113\tAcc: 97.38372%\n",
      "Step:  2100\tLoss: 0.108\tAcc: 97.96512%\n",
      "Step:  2200\tLoss: 0.103\tAcc: 98.54651%\n",
      "Step:  2300\tLoss: 0.099\tAcc: 98.54651%\n",
      "Step:  2400\tLoss: 0.095\tAcc: 98.54651%\n",
      "Step:  2500\tLoss: 0.092\tAcc: 98.54651%\n",
      "Step:  2600\tLoss: 0.089\tAcc: 98.83721%\n",
      "Step:  2700\tLoss: 0.086\tAcc: 98.83721%\n",
      "Step:  2800\tLoss: 0.083\tAcc: 99.12791%\n",
      "Step:  2900\tLoss: 0.081\tAcc: 99.12791%\n",
      "Step:  3000\tLoss: 0.079\tAcc: 99.12791%\n",
      "Step:  3100\tLoss: 0.076\tAcc: 99.12791%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.99127907\n",
      "Test Prediction = 0.84347826\n",
      "=========== RUN 41=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 2.396\tAcc: 40.98837%\n",
      "Step:   100\tLoss: 0.857\tAcc: 65.98837%\n",
      "Step:   200\tLoss: 0.532\tAcc: 79.06977%\n",
      "Step:   300\tLoss: 0.392\tAcc: 85.75581%\n",
      "Step:   400\tLoss: 0.314\tAcc: 90.98837%\n",
      "Step:   500\tLoss: 0.268\tAcc: 91.86047%\n",
      "Step:   600\tLoss: 0.236\tAcc: 93.02326%\n",
      "Step:   700\tLoss: 0.212\tAcc: 94.76744%\n",
      "Step:   800\tLoss: 0.194\tAcc: 96.22093%\n",
      "Step:   900\tLoss: 0.180\tAcc: 96.22093%\n",
      "Step:  1000\tLoss: 0.167\tAcc: 96.80232%\n",
      "Step:  1100\tLoss: 0.153\tAcc: 97.09302%\n",
      "Step:  1200\tLoss: 0.142\tAcc: 97.09302%\n",
      "Step:  1300\tLoss: 0.133\tAcc: 97.09302%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9709302\n",
      "Test Prediction = 0.84347826\n",
      "=========== RUN 42=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 3.375\tAcc: 52.32558%\n",
      "Step:   100\tLoss: 1.253\tAcc: 60.75581%\n",
      "Step:   200\tLoss: 0.750\tAcc: 70.93023%\n",
      "Step:   300\tLoss: 0.560\tAcc: 78.77907%\n",
      "Step:   400\tLoss: 0.454\tAcc: 85.17442%\n",
      "Step:   500\tLoss: 0.385\tAcc: 86.62791%\n",
      "Step:   600\tLoss: 0.336\tAcc: 89.82558%\n",
      "Step:   700\tLoss: 0.301\tAcc: 91.56977%\n",
      "Step:   800\tLoss: 0.274\tAcc: 92.15117%\n",
      "Step:   900\tLoss: 0.252\tAcc: 93.60465%\n",
      "Step:  1000\tLoss: 0.234\tAcc: 94.18604%\n",
      "Step:  1100\tLoss: 0.219\tAcc: 94.76744%\n",
      "Step:  1200\tLoss: 0.205\tAcc: 95.63953%\n",
      "Step:  1300\tLoss: 0.194\tAcc: 95.93023%\n",
      "Step:  1400\tLoss: 0.184\tAcc: 96.51163%\n",
      "Step:  1500\tLoss: 0.175\tAcc: 96.80232%\n",
      "Step:  1600\tLoss: 0.167\tAcc: 96.80232%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.96802324\n",
      "Test Prediction = 0.8521739\n",
      "=========== RUN 43=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 5.803\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 1.922\tAcc: 58.13953%\n",
      "Step:   200\tLoss: 1.152\tAcc: 66.27907%\n",
      "Step:   300\tLoss: 0.819\tAcc: 72.09302%\n",
      "Step:   400\tLoss: 0.630\tAcc: 81.10465%\n",
      "Step:   500\tLoss: 0.515\tAcc: 86.62791%\n",
      "Step:   600\tLoss: 0.445\tAcc: 89.53488%\n",
      "Step:   700\tLoss: 0.396\tAcc: 92.15117%\n",
      "Step:   800\tLoss: 0.359\tAcc: 92.44186%\n",
      "Step:   900\tLoss: 0.327\tAcc: 92.73256%\n",
      "Step:  1000\tLoss: 0.299\tAcc: 93.60465%\n",
      "Step:  1100\tLoss: 0.274\tAcc: 93.60465%\n",
      "Step:  1200\tLoss: 0.254\tAcc: 93.89535%\n",
      "Step:  1300\tLoss: 0.237\tAcc: 93.89535%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.93895346\n",
      "Test Prediction = 0.83913046\n",
      "=========== RUN 44=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 11.293\tAcc: 47.96512%\n",
      "Step:   100\tLoss: 3.606\tAcc: 48.25581%\n",
      "Step:   200\tLoss: 1.215\tAcc: 62.50000%\n",
      "Step:   300\tLoss: 0.714\tAcc: 77.03488%\n",
      "Step:   400\tLoss: 0.526\tAcc: 82.84883%\n",
      "Step:   500\tLoss: 0.427\tAcc: 85.17442%\n",
      "Step:   600\tLoss: 0.363\tAcc: 88.08140%\n",
      "Step:   700\tLoss: 0.319\tAcc: 90.11628%\n",
      "Step:   800\tLoss: 0.287\tAcc: 90.98837%\n",
      "Step:   900\tLoss: 0.262\tAcc: 91.56977%\n",
      "Step:  1000\tLoss: 0.242\tAcc: 92.15117%\n",
      "Step:  1100\tLoss: 0.225\tAcc: 93.02326%\n",
      "Step:  1200\tLoss: 0.211\tAcc: 93.31396%\n",
      "Step:  1300\tLoss: 0.200\tAcc: 93.89535%\n",
      "Step:  1400\tLoss: 0.190\tAcc: 94.76744%\n",
      "Step:  1500\tLoss: 0.182\tAcc: 95.34883%\n",
      "Step:  1600\tLoss: 0.174\tAcc: 95.93023%\n",
      "Step:  1700\tLoss: 0.167\tAcc: 95.93023%\n",
      "Step:  1800\tLoss: 0.160\tAcc: 96.22093%\n",
      "Step:  1900\tLoss: 0.154\tAcc: 96.22093%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9622093\n",
      "Test Prediction = 0.8043478\n",
      "=========== RUN 45=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 11.018\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 2.465\tAcc: 49.70930%\n",
      "Step:   200\tLoss: 0.936\tAcc: 70.05814%\n",
      "Step:   300\tLoss: 0.641\tAcc: 77.32558%\n",
      "Step:   400\tLoss: 0.508\tAcc: 81.68604%\n",
      "Step:   500\tLoss: 0.424\tAcc: 85.46512%\n",
      "Step:   600\tLoss: 0.360\tAcc: 86.33721%\n",
      "Step:   700\tLoss: 0.313\tAcc: 88.37209%\n",
      "Step:   800\tLoss: 0.275\tAcc: 89.82558%\n",
      "Step:   900\tLoss: 0.249\tAcc: 90.69768%\n",
      "Step:  1000\tLoss: 0.227\tAcc: 91.56977%\n",
      "Step:  1100\tLoss: 0.209\tAcc: 92.15117%\n",
      "Step:  1200\tLoss: 0.195\tAcc: 93.89535%\n",
      "Step:  1300\tLoss: 0.180\tAcc: 94.76744%\n",
      "Step:  1400\tLoss: 0.169\tAcc: 95.34883%\n",
      "Step:  1500\tLoss: 0.160\tAcc: 95.63953%\n",
      "Step:  1600\tLoss: 0.152\tAcc: 95.93023%\n",
      "Step:  1700\tLoss: 0.145\tAcc: 95.93023%\n",
      "Step:  1800\tLoss: 0.139\tAcc: 95.93023%\n",
      "Step:  1900\tLoss: 0.134\tAcc: 96.80232%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  2000\tLoss: 0.129\tAcc: 96.80232%\n",
      "Step:  2100\tLoss: 0.125\tAcc: 96.80232%\n",
      "Step:  2200\tLoss: 0.121\tAcc: 96.80232%\n",
      "Step:  2300\tLoss: 0.117\tAcc: 97.09302%\n",
      "Step:  2400\tLoss: 0.113\tAcc: 97.67442%\n",
      "Step:  2500\tLoss: 0.110\tAcc: 97.96512%\n",
      "Step:  2600\tLoss: 0.106\tAcc: 97.96512%\n",
      "Step:  2700\tLoss: 0.103\tAcc: 97.96512%\n",
      "Step:  2800\tLoss: 0.100\tAcc: 98.25581%\n",
      "Step:  2900\tLoss: 0.097\tAcc: 98.25581%\n",
      "Step:  3000\tLoss: 0.095\tAcc: 98.25581%\n",
      "Step:  3100\tLoss: 0.093\tAcc: 98.25581%\n",
      "Step:  3200\tLoss: 0.090\tAcc: 98.83721%\n",
      "Step:  3300\tLoss: 0.088\tAcc: 99.12791%\n",
      "Step:  3400\tLoss: 0.086\tAcc: 99.41860%\n",
      "Step:  3500\tLoss: 0.085\tAcc: 99.41860%\n",
      "Step:  3600\tLoss: 0.083\tAcc: 99.41860%\n",
      "Step:  3700\tLoss: 0.081\tAcc: 99.41860%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.99418604\n",
      "Test Prediction = 0.8695652\n",
      "=========== RUN 46=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 3.767\tAcc: 47.38372%\n",
      "Step:   100\tLoss: 1.250\tAcc: 67.44186%\n",
      "Step:   200\tLoss: 0.865\tAcc: 72.38372%\n",
      "Step:   300\tLoss: 0.668\tAcc: 79.06977%\n",
      "Step:   400\tLoss: 0.573\tAcc: 82.55814%\n",
      "Step:   500\tLoss: 0.506\tAcc: 86.62791%\n",
      "Step:   600\tLoss: 0.451\tAcc: 88.37209%\n",
      "Step:   700\tLoss: 0.397\tAcc: 88.37209%\n",
      "Step:   800\tLoss: 0.352\tAcc: 90.98837%\n",
      "Step:   900\tLoss: 0.312\tAcc: 90.98837%\n",
      "Step:  1000\tLoss: 0.278\tAcc: 92.15117%\n",
      "Step:  1100\tLoss: 0.249\tAcc: 92.44186%\n",
      "Step:  1200\tLoss: 0.225\tAcc: 92.73256%\n",
      "Step:  1300\tLoss: 0.204\tAcc: 93.89535%\n",
      "Step:  1400\tLoss: 0.187\tAcc: 94.18604%\n",
      "Step:  1500\tLoss: 0.173\tAcc: 94.76744%\n",
      "Step:  1600\tLoss: 0.161\tAcc: 95.34883%\n",
      "Step:  1700\tLoss: 0.152\tAcc: 95.63953%\n",
      "Step:  1800\tLoss: 0.142\tAcc: 96.22093%\n",
      "Step:  1900\tLoss: 0.134\tAcc: 96.80232%\n",
      "Step:  2000\tLoss: 0.127\tAcc: 97.67442%\n",
      "Step:  2100\tLoss: 0.121\tAcc: 98.54651%\n",
      "Step:  2200\tLoss: 0.115\tAcc: 98.54651%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9854651\n",
      "Test Prediction = 0.8652174\n",
      "=========== RUN 47=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 16.110\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 7.770\tAcc: 47.67442%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.4622093\n",
      "Test Prediction = 0.4478261\n",
      "=========== RUN 48=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 3.531\tAcc: 56.10465%\n",
      "Step:   100\tLoss: 1.310\tAcc: 72.38372%\n",
      "Step:   200\tLoss: 0.985\tAcc: 74.41860%\n",
      "Step:   300\tLoss: 0.798\tAcc: 77.32558%\n",
      "Step:   400\tLoss: 0.681\tAcc: 81.10465%\n",
      "Step:   500\tLoss: 0.566\tAcc: 83.72093%\n",
      "Step:   600\tLoss: 0.500\tAcc: 86.62791%\n",
      "Step:   700\tLoss: 0.448\tAcc: 87.79070%\n",
      "Step:   800\tLoss: 0.406\tAcc: 90.69768%\n",
      "Step:   900\tLoss: 0.371\tAcc: 90.98837%\n",
      "Step:  1000\tLoss: 0.342\tAcc: 91.56977%\n",
      "Step:  1100\tLoss: 0.316\tAcc: 92.44186%\n",
      "Step:  1200\tLoss: 0.294\tAcc: 92.44186%\n",
      "Step:  1300\tLoss: 0.274\tAcc: 93.02326%\n",
      "Step:  1400\tLoss: 0.257\tAcc: 93.60465%\n",
      "Step:  1500\tLoss: 0.241\tAcc: 93.89535%\n",
      "Step:  1600\tLoss: 0.227\tAcc: 94.76744%\n",
      "Step:  1700\tLoss: 0.214\tAcc: 95.05814%\n",
      "Step:  1800\tLoss: 0.202\tAcc: 95.05814%\n",
      "Step:  1900\tLoss: 0.191\tAcc: 95.34883%\n",
      "Step:  2000\tLoss: 0.182\tAcc: 95.93023%\n",
      "Step:  2100\tLoss: 0.174\tAcc: 95.93023%\n",
      "Step:  2200\tLoss: 0.166\tAcc: 96.51163%\n",
      "Step:  2300\tLoss: 0.160\tAcc: 96.80232%\n",
      "Step:  2400\tLoss: 0.154\tAcc: 97.09302%\n",
      "Step:  2500\tLoss: 0.148\tAcc: 97.38372%\n",
      "Step:  2600\tLoss: 0.143\tAcc: 97.96512%\n",
      "Step:  2700\tLoss: 0.139\tAcc: 97.96512%\n",
      "Step:  2800\tLoss: 0.134\tAcc: 97.96512%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.97965115\n",
      "Test Prediction = 0.8\n",
      "=========== RUN 49=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 15.236\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 7.523\tAcc: 47.67442%\n",
      "Step:   200\tLoss: 3.229\tAcc: 47.96512%\n",
      "Step:   300\tLoss: 1.977\tAcc: 50.58140%\n",
      "Step:   400\tLoss: 1.368\tAcc: 60.46512%\n",
      "Step:   500\tLoss: 1.005\tAcc: 70.05814%\n",
      "Step:   600\tLoss: 0.774\tAcc: 76.16279%\n",
      "Step:   700\tLoss: 0.646\tAcc: 79.36047%\n",
      "Step:   800\tLoss: 0.566\tAcc: 82.26744%\n",
      "Step:   900\tLoss: 0.503\tAcc: 84.59302%\n",
      "Step:  1000\tLoss: 0.451\tAcc: 85.17442%\n",
      "Step:  1100\tLoss: 0.407\tAcc: 85.75581%\n",
      "Step:  1200\tLoss: 0.366\tAcc: 86.33721%\n",
      "Step:  1300\tLoss: 0.331\tAcc: 89.24419%\n",
      "Step:  1400\tLoss: 0.300\tAcc: 90.69768%\n",
      "Step:  1500\tLoss: 0.273\tAcc: 91.56977%\n",
      "Step:  1600\tLoss: 0.252\tAcc: 91.86047%\n",
      "Step:  1700\tLoss: 0.234\tAcc: 92.44186%\n",
      "Step:  1800\tLoss: 0.219\tAcc: 93.31396%\n",
      "Step:  1900\tLoss: 0.206\tAcc: 94.47674%\n",
      "Step:  2000\tLoss: 0.194\tAcc: 94.47674%\n",
      "Step:  2100\tLoss: 0.184\tAcc: 95.05814%\n",
      "Step:  2200\tLoss: 0.176\tAcc: 95.34883%\n",
      "Step:  2300\tLoss: 0.169\tAcc: 95.63953%\n",
      "Step:  2400\tLoss: 0.162\tAcc: 95.63953%\n",
      "Step:  2500\tLoss: 0.156\tAcc: 96.51163%\n",
      "Step:  2600\tLoss: 0.150\tAcc: 96.80232%\n",
      "Step:  2700\tLoss: 0.145\tAcc: 96.80232%\n",
      "Step:  2800\tLoss: 0.140\tAcc: 96.80232%\n",
      "Step:  2900\tLoss: 0.136\tAcc: 97.09302%\n",
      "Step:  3000\tLoss: 0.132\tAcc: 97.09302%\n",
      "Step:  3100\tLoss: 0.128\tAcc: 97.96512%\n",
      "Step:  3200\tLoss: 0.125\tAcc: 98.25581%\n",
      "Step:  3300\tLoss: 0.121\tAcc: 98.25581%\n",
      "Step:  3400\tLoss: 0.118\tAcc: 98.25581%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.98255813\n",
      "Test Prediction = 0.8826087\n",
      "=========== RUN 50=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 9.810\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 2.750\tAcc: 53.48837%\n",
      "Step:   200\tLoss: 1.013\tAcc: 70.34883%\n",
      "Step:   300\tLoss: 0.631\tAcc: 78.77907%\n",
      "Step:   400\tLoss: 0.475\tAcc: 83.72093%\n",
      "Step:   500\tLoss: 0.383\tAcc: 87.50000%\n",
      "Step:   600\tLoss: 0.320\tAcc: 89.53488%\n",
      "Step:   700\tLoss: 0.276\tAcc: 90.69768%\n",
      "Step:   800\tLoss: 0.242\tAcc: 92.44186%\n",
      "Step:   900\tLoss: 0.216\tAcc: 92.73256%\n",
      "Step:  1000\tLoss: 0.195\tAcc: 93.60465%\n",
      "Step:  1100\tLoss: 0.179\tAcc: 94.47674%\n",
      "Step:  1200\tLoss: 0.167\tAcc: 95.34883%\n",
      "Step:  1300\tLoss: 0.158\tAcc: 96.51163%\n",
      "Step:  1400\tLoss: 0.150\tAcc: 96.51163%\n",
      "Step:  1500\tLoss: 0.143\tAcc: 96.51163%\n",
      "Step:  1600\tLoss: 0.137\tAcc: 97.38372%\n",
      "Step:  1700\tLoss: 0.132\tAcc: 97.67442%\n",
      "Step:  1800\tLoss: 0.128\tAcc: 97.96512%\n",
      "Step:  1900\tLoss: 0.123\tAcc: 97.96512%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.97965115\n",
      "Test Prediction = 0.82608694\n",
      "=========== RUN 51=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 3.158\tAcc: 54.65117%\n",
      "Step:   100\tLoss: 1.101\tAcc: 64.53488%\n",
      "Step:   200\tLoss: 0.757\tAcc: 73.54651%\n",
      "Step:   300\tLoss: 0.587\tAcc: 83.13953%\n",
      "Step:   400\tLoss: 0.488\tAcc: 85.46512%\n",
      "Step:   500\tLoss: 0.418\tAcc: 86.62791%\n",
      "Step:   600\tLoss: 0.362\tAcc: 89.24419%\n",
      "Step:   700\tLoss: 0.319\tAcc: 90.69768%\n",
      "Step:   800\tLoss: 0.285\tAcc: 91.27907%\n",
      "Step:   900\tLoss: 0.258\tAcc: 91.86047%\n",
      "Step:  1000\tLoss: 0.236\tAcc: 92.15117%\n",
      "Step:  1100\tLoss: 0.217\tAcc: 93.60465%\n",
      "Step:  1200\tLoss: 0.202\tAcc: 93.89535%\n",
      "Step:  1300\tLoss: 0.188\tAcc: 94.47674%\n",
      "Step:  1400\tLoss: 0.177\tAcc: 94.47674%\n",
      "Step:  1500\tLoss: 0.167\tAcc: 95.05814%\n",
      "Step:  1600\tLoss: 0.159\tAcc: 95.05814%\n",
      "Step:  1700\tLoss: 0.151\tAcc: 95.34883%\n",
      "Step:  1800\tLoss: 0.145\tAcc: 96.51163%\n",
      "Step:  1900\tLoss: 0.139\tAcc: 96.51163%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.96511626\n",
      "Test Prediction = 0.8347826\n",
      "=========== RUN 52=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 2.326\tAcc: 43.89535%\n",
      "Step:   100\tLoss: 0.836\tAcc: 72.67442%\n",
      "Step:   200\tLoss: 0.575\tAcc: 81.39535%\n",
      "Step:   300\tLoss: 0.452\tAcc: 84.01163%\n",
      "Step:   400\tLoss: 0.383\tAcc: 88.66279%\n",
      "Step:   500\tLoss: 0.336\tAcc: 88.95349%\n",
      "Step:   600\tLoss: 0.298\tAcc: 89.24419%\n",
      "Step:   700\tLoss: 0.269\tAcc: 91.56977%\n",
      "Step:   800\tLoss: 0.246\tAcc: 93.02326%\n",
      "Step:   900\tLoss: 0.225\tAcc: 93.89535%\n",
      "Step:  1000\tLoss: 0.210\tAcc: 94.47674%\n",
      "Step:  1100\tLoss: 0.197\tAcc: 94.47674%\n",
      "Step:  1200\tLoss: 0.186\tAcc: 94.47674%\n",
      "Step:  1300\tLoss: 0.176\tAcc: 94.76744%\n",
      "Step:  1400\tLoss: 0.167\tAcc: 94.76744%\n",
      "Step:  1500\tLoss: 0.160\tAcc: 94.76744%\n",
      "Step:  1600\tLoss: 0.153\tAcc: 95.05814%\n",
      "Step:  1700\tLoss: 0.146\tAcc: 95.34883%\n",
      "Step:  1800\tLoss: 0.141\tAcc: 95.63953%\n",
      "Step:  1900\tLoss: 0.135\tAcc: 95.63953%\n",
      "Step:  2000\tLoss: 0.130\tAcc: 95.93023%\n",
      "Step:  2100\tLoss: 0.126\tAcc: 95.93023%\n",
      "Step:  2200\tLoss: 0.121\tAcc: 96.22093%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  2300\tLoss: 0.117\tAcc: 96.51163%\n",
      "Step:  2400\tLoss: 0.112\tAcc: 96.80232%\n",
      "Step:  2500\tLoss: 0.108\tAcc: 96.80232%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.96802324\n",
      "Test Prediction = 0.8347826\n",
      "=========== RUN 53=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 1.965\tAcc: 50.29070%\n",
      "Step:   100\tLoss: 0.544\tAcc: 75.58140%\n",
      "Step:   200\tLoss: 0.405\tAcc: 85.46512%\n",
      "Step:   300\tLoss: 0.325\tAcc: 90.69768%\n",
      "Step:   400\tLoss: 0.284\tAcc: 92.15117%\n",
      "Step:   500\tLoss: 0.257\tAcc: 93.31396%\n",
      "Step:   600\tLoss: 0.237\tAcc: 94.18604%\n",
      "Step:   700\tLoss: 0.220\tAcc: 94.47674%\n",
      "Step:   800\tLoss: 0.206\tAcc: 94.76744%\n",
      "Step:   900\tLoss: 0.193\tAcc: 94.76744%\n",
      "Step:  1000\tLoss: 0.183\tAcc: 94.76744%\n",
      "Step:  1100\tLoss: 0.173\tAcc: 95.34883%\n",
      "Step:  1200\tLoss: 0.165\tAcc: 95.34883%\n",
      "Step:  1300\tLoss: 0.157\tAcc: 95.34883%\n",
      "Step:  1400\tLoss: 0.149\tAcc: 95.63953%\n",
      "Step:  1500\tLoss: 0.141\tAcc: 96.22093%\n",
      "Step:  1600\tLoss: 0.135\tAcc: 96.80232%\n",
      "Step:  1700\tLoss: 0.130\tAcc: 97.09302%\n",
      "Step:  1800\tLoss: 0.125\tAcc: 97.09302%\n",
      "Step:  1900\tLoss: 0.121\tAcc: 97.38372%\n",
      "Step:  2000\tLoss: 0.117\tAcc: 97.67442%\n",
      "Step:  2100\tLoss: 0.113\tAcc: 97.67442%\n",
      "Step:  2200\tLoss: 0.110\tAcc: 97.67442%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9767442\n",
      "Test Prediction = 0.8913044\n",
      "=========== RUN 54=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 12.537\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 3.430\tAcc: 53.77907%\n",
      "Step:   200\tLoss: 1.537\tAcc: 60.46512%\n",
      "Step:   300\tLoss: 0.929\tAcc: 70.05814%\n",
      "Step:   400\tLoss: 0.644\tAcc: 80.23256%\n",
      "Step:   500\tLoss: 0.506\tAcc: 82.84883%\n",
      "Step:   600\tLoss: 0.408\tAcc: 87.20930%\n",
      "Step:   700\tLoss: 0.350\tAcc: 90.40698%\n",
      "Step:   800\tLoss: 0.308\tAcc: 91.27907%\n",
      "Step:   900\tLoss: 0.278\tAcc: 92.44186%\n",
      "Step:  1000\tLoss: 0.253\tAcc: 93.02326%\n",
      "Step:  1100\tLoss: 0.234\tAcc: 93.31396%\n",
      "Step:  1200\tLoss: 0.218\tAcc: 93.89535%\n",
      "Step:  1300\tLoss: 0.205\tAcc: 94.47674%\n",
      "Step:  1400\tLoss: 0.193\tAcc: 94.76744%\n",
      "Step:  1500\tLoss: 0.183\tAcc: 95.05814%\n",
      "Step:  1600\tLoss: 0.174\tAcc: 95.63953%\n",
      "Step:  1700\tLoss: 0.166\tAcc: 95.63953%\n",
      "Step:  1800\tLoss: 0.159\tAcc: 95.63953%\n",
      "Step:  1900\tLoss: 0.153\tAcc: 95.93023%\n",
      "Step:  2000\tLoss: 0.148\tAcc: 96.22093%\n",
      "Step:  2100\tLoss: 0.143\tAcc: 96.51163%\n",
      "Step:  2200\tLoss: 0.138\tAcc: 97.09302%\n",
      "Step:  2300\tLoss: 0.134\tAcc: 97.09302%\n",
      "Step:  2400\tLoss: 0.130\tAcc: 97.09302%\n",
      "Step:  2500\tLoss: 0.127\tAcc: 97.09302%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9709302\n",
      "Test Prediction = 0.8347826\n",
      "=========== RUN 55=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 7.308\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 2.005\tAcc: 52.61628%\n",
      "Step:   200\tLoss: 0.848\tAcc: 66.56977%\n",
      "Step:   300\tLoss: 0.573\tAcc: 78.77907%\n",
      "Step:   400\tLoss: 0.440\tAcc: 85.46512%\n",
      "Step:   500\tLoss: 0.368\tAcc: 89.24419%\n",
      "Step:   600\tLoss: 0.320\tAcc: 90.69768%\n",
      "Step:   700\tLoss: 0.284\tAcc: 91.56977%\n",
      "Step:   800\tLoss: 0.255\tAcc: 91.56977%\n",
      "Step:   900\tLoss: 0.232\tAcc: 91.56977%\n",
      "Step:  1000\tLoss: 0.214\tAcc: 93.31396%\n",
      "Step:  1100\tLoss: 0.200\tAcc: 93.60465%\n",
      "Step:  1200\tLoss: 0.187\tAcc: 94.18604%\n",
      "Step:  1300\tLoss: 0.175\tAcc: 94.47674%\n",
      "Step:  1400\tLoss: 0.163\tAcc: 95.63953%\n",
      "Step:  1500\tLoss: 0.154\tAcc: 96.22093%\n",
      "Step:  1600\tLoss: 0.146\tAcc: 96.51163%\n",
      "Step:  1700\tLoss: 0.140\tAcc: 96.80232%\n",
      "Step:  1800\tLoss: 0.133\tAcc: 96.80232%\n",
      "Step:  1900\tLoss: 0.128\tAcc: 97.09302%\n",
      "Step:  2000\tLoss: 0.123\tAcc: 97.09302%\n",
      "Step:  2100\tLoss: 0.118\tAcc: 97.38372%\n",
      "Step:  2200\tLoss: 0.114\tAcc: 97.96512%\n",
      "Step:  2300\tLoss: 0.110\tAcc: 98.25581%\n",
      "Step:  2400\tLoss: 0.107\tAcc: 98.25581%\n",
      "Step:  2500\tLoss: 0.103\tAcc: 98.54651%\n",
      "Step:  2600\tLoss: 0.101\tAcc: 98.54651%\n",
      "Step:  2700\tLoss: 0.098\tAcc: 98.54651%\n",
      "Step:  2800\tLoss: 0.095\tAcc: 98.54651%\n",
      "Step:  2900\tLoss: 0.093\tAcc: 98.83721%\n",
      "Step:  3000\tLoss: 0.090\tAcc: 99.12791%\n",
      "Step:  3100\tLoss: 0.088\tAcc: 99.41860%\n",
      "Step:  3200\tLoss: 0.086\tAcc: 99.41860%\n",
      "Step:  3300\tLoss: 0.084\tAcc: 99.41860%\n",
      "Step:  3400\tLoss: 0.082\tAcc: 99.41860%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.99418604\n",
      "Test Prediction = 0.8565217\n",
      "=========== RUN 56=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 10.599\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 3.186\tAcc: 48.83721%\n",
      "Step:   200\tLoss: 1.449\tAcc: 57.55814%\n",
      "Step:   300\tLoss: 0.875\tAcc: 73.25581%\n",
      "Step:   400\tLoss: 0.602\tAcc: 77.61628%\n",
      "Step:   500\tLoss: 0.447\tAcc: 85.17442%\n",
      "Step:   600\tLoss: 0.358\tAcc: 86.91860%\n",
      "Step:   700\tLoss: 0.300\tAcc: 88.66279%\n",
      "Step:   800\tLoss: 0.260\tAcc: 89.82558%\n",
      "Step:   900\tLoss: 0.228\tAcc: 91.56977%\n",
      "Step:  1000\tLoss: 0.201\tAcc: 93.60465%\n",
      "Step:  1100\tLoss: 0.180\tAcc: 94.18604%\n",
      "Step:  1200\tLoss: 0.163\tAcc: 94.76744%\n",
      "Step:  1300\tLoss: 0.148\tAcc: 95.34883%\n",
      "Step:  1400\tLoss: 0.135\tAcc: 95.63953%\n",
      "Step:  1500\tLoss: 0.125\tAcc: 97.38372%\n",
      "Step:  1600\tLoss: 0.116\tAcc: 97.67442%\n",
      "Step:  1700\tLoss: 0.109\tAcc: 97.96512%\n",
      "Step:  1800\tLoss: 0.102\tAcc: 98.54651%\n",
      "Step:  1900\tLoss: 0.097\tAcc: 98.83721%\n",
      "Step:  2000\tLoss: 0.092\tAcc: 99.12791%\n",
      "Step:  2100\tLoss: 0.088\tAcc: 99.41860%\n",
      "Step:  2200\tLoss: 0.084\tAcc: 99.41860%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.99418604\n",
      "Test Prediction = 0.84782606\n",
      "=========== RUN 57=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 10.877\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 4.012\tAcc: 53.19768%\n",
      "Step:   200\tLoss: 1.736\tAcc: 59.88372%\n",
      "Step:   300\tLoss: 1.053\tAcc: 70.34883%\n",
      "Step:   400\tLoss: 0.775\tAcc: 79.65117%\n",
      "Step:   500\tLoss: 0.625\tAcc: 81.39535%\n",
      "Step:   600\tLoss: 0.532\tAcc: 86.04651%\n",
      "Step:   700\tLoss: 0.463\tAcc: 86.33721%\n",
      "Step:   800\tLoss: 0.407\tAcc: 88.37209%\n",
      "Step:   900\tLoss: 0.361\tAcc: 90.69768%\n",
      "Step:  1000\tLoss: 0.323\tAcc: 91.27907%\n",
      "Step:  1100\tLoss: 0.292\tAcc: 91.86047%\n",
      "Step:  1200\tLoss: 0.267\tAcc: 93.31396%\n",
      "Step:  1300\tLoss: 0.245\tAcc: 93.31396%\n",
      "Step:  1400\tLoss: 0.226\tAcc: 93.89535%\n",
      "Step:  1500\tLoss: 0.210\tAcc: 94.18604%\n",
      "Step:  1600\tLoss: 0.196\tAcc: 95.63953%\n",
      "Step:  1700\tLoss: 0.184\tAcc: 95.93023%\n",
      "Step:  1800\tLoss: 0.173\tAcc: 96.22093%\n",
      "Step:  1900\tLoss: 0.165\tAcc: 96.80232%\n",
      "Step:  2000\tLoss: 0.157\tAcc: 96.80232%\n",
      "Step:  2100\tLoss: 0.150\tAcc: 96.80232%\n",
      "Step:  2200\tLoss: 0.143\tAcc: 97.09302%\n",
      "Step:  2300\tLoss: 0.138\tAcc: 97.09302%\n",
      "Step:  2400\tLoss: 0.132\tAcc: 97.09302%\n",
      "Step:  2500\tLoss: 0.128\tAcc: 97.38372%\n",
      "Step:  2600\tLoss: 0.123\tAcc: 98.25581%\n",
      "Step:  2700\tLoss: 0.119\tAcc: 98.25581%\n",
      "Step:  2800\tLoss: 0.116\tAcc: 98.25581%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.98255813\n",
      "Test Prediction = 0.87826085\n",
      "=========== RUN 58=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 19.457\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 12.775\tAcc: 47.67442%\n",
      "Step:   200\tLoss: 6.913\tAcc: 49.70930%\n",
      "Step:   300\tLoss: 3.002\tAcc: 53.77907%\n",
      "Step:   400\tLoss: 1.793\tAcc: 53.77907%\n",
      "Step:   500\tLoss: 1.298\tAcc: 65.11628%\n",
      "Step:   600\tLoss: 0.946\tAcc: 70.93023%\n",
      "Step:   700\tLoss: 0.741\tAcc: 75.58140%\n",
      "Step:   800\tLoss: 0.619\tAcc: 80.52326%\n",
      "Step:   900\tLoss: 0.534\tAcc: 82.55814%\n",
      "Step:  1000\tLoss: 0.467\tAcc: 84.59302%\n",
      "Step:  1100\tLoss: 0.417\tAcc: 86.33721%\n",
      "Step:  1200\tLoss: 0.373\tAcc: 87.79070%\n",
      "Step:  1300\tLoss: 0.335\tAcc: 88.95349%\n",
      "Step:  1400\tLoss: 0.304\tAcc: 89.53488%\n",
      "Step:  1500\tLoss: 0.277\tAcc: 90.40698%\n",
      "Step:  1600\tLoss: 0.255\tAcc: 90.69768%\n",
      "Step:  1700\tLoss: 0.236\tAcc: 92.15117%\n",
      "Step:  1800\tLoss: 0.220\tAcc: 93.89535%\n",
      "Step:  1900\tLoss: 0.206\tAcc: 94.18604%\n",
      "Step:  2000\tLoss: 0.193\tAcc: 95.05814%\n",
      "Step:  2100\tLoss: 0.183\tAcc: 96.22093%\n",
      "Step:  2200\tLoss: 0.174\tAcc: 96.51163%\n",
      "Step:  2300\tLoss: 0.166\tAcc: 96.80232%\n",
      "Step:  2400\tLoss: 0.159\tAcc: 96.80232%\n",
      "Step:  2500\tLoss: 0.153\tAcc: 97.38372%\n",
      "Step:  2600\tLoss: 0.148\tAcc: 97.38372%\n",
      "Step:  2700\tLoss: 0.142\tAcc: 97.38372%\n",
      "Step:  2800\tLoss: 0.138\tAcc: 97.38372%\n",
      "Step:  2900\tLoss: 0.133\tAcc: 97.67442%\n",
      "Step:  3000\tLoss: 0.129\tAcc: 97.67442%\n",
      "Step:  3100\tLoss: 0.125\tAcc: 97.67442%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9767442\n",
      "Test Prediction = 0.84347826\n",
      "=========== RUN 59=================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 1.910\tAcc: 51.74419%\n",
      "Step:   100\tLoss: 0.973\tAcc: 68.60465%\n",
      "Step:   200\tLoss: 0.674\tAcc: 76.74419%\n",
      "Step:   300\tLoss: 0.525\tAcc: 82.84883%\n",
      "Step:   400\tLoss: 0.443\tAcc: 85.17442%\n",
      "Step:   500\tLoss: 0.385\tAcc: 86.62791%\n",
      "Step:   600\tLoss: 0.341\tAcc: 88.37209%\n",
      "Step:   700\tLoss: 0.306\tAcc: 88.66279%\n",
      "Step:   800\tLoss: 0.277\tAcc: 89.53488%\n",
      "Step:   900\tLoss: 0.252\tAcc: 90.11628%\n",
      "Step:  1000\tLoss: 0.231\tAcc: 91.56977%\n",
      "Step:  1100\tLoss: 0.213\tAcc: 93.02326%\n",
      "Step:  1200\tLoss: 0.198\tAcc: 93.02326%\n",
      "Step:  1300\tLoss: 0.185\tAcc: 93.89535%\n",
      "Step:  1400\tLoss: 0.174\tAcc: 94.18604%\n",
      "Step:  1500\tLoss: 0.165\tAcc: 94.76744%\n",
      "Step:  1600\tLoss: 0.156\tAcc: 95.93023%\n",
      "Step:  1700\tLoss: 0.148\tAcc: 96.22093%\n",
      "Step:  1800\tLoss: 0.141\tAcc: 96.80232%\n",
      "Step:  1900\tLoss: 0.134\tAcc: 97.09302%\n",
      "Step:  2000\tLoss: 0.128\tAcc: 97.38372%\n",
      "Step:  2100\tLoss: 0.123\tAcc: 97.67442%\n",
      "Step:  2200\tLoss: 0.119\tAcc: 97.96512%\n",
      "Step:  2300\tLoss: 0.114\tAcc: 97.96512%\n",
      "Step:  2400\tLoss: 0.111\tAcc: 97.96512%\n",
      "Step:  2500\tLoss: 0.107\tAcc: 98.25581%\n",
      "Step:  2600\tLoss: 0.104\tAcc: 98.54651%\n",
      "Step:  2700\tLoss: 0.101\tAcc: 98.54651%\n",
      "Step:  2800\tLoss: 0.098\tAcc: 98.54651%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9854651\n",
      "Test Prediction = 0.8826087\n",
      "=========== RUN 60=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 2.213\tAcc: 59.01163%\n",
      "Step:   100\tLoss: 0.929\tAcc: 74.12791%\n",
      "Step:   200\tLoss: 0.671\tAcc: 79.94186%\n",
      "Step:   300\tLoss: 0.521\tAcc: 84.01163%\n",
      "Step:   400\tLoss: 0.425\tAcc: 88.08140%\n",
      "Step:   500\tLoss: 0.360\tAcc: 90.11628%\n",
      "Step:   600\tLoss: 0.314\tAcc: 92.15117%\n",
      "Step:   700\tLoss: 0.284\tAcc: 93.31396%\n",
      "Step:   800\tLoss: 0.261\tAcc: 93.89535%\n",
      "Step:   900\tLoss: 0.243\tAcc: 94.18604%\n",
      "Step:  1000\tLoss: 0.228\tAcc: 94.76744%\n",
      "Step:  1100\tLoss: 0.214\tAcc: 95.05814%\n",
      "Step:  1200\tLoss: 0.202\tAcc: 95.34883%\n",
      "Step:  1300\tLoss: 0.191\tAcc: 95.93023%\n",
      "Step:  1400\tLoss: 0.181\tAcc: 96.22093%\n",
      "Step:  1500\tLoss: 0.172\tAcc: 96.22093%\n",
      "Step:  1600\tLoss: 0.164\tAcc: 96.22093%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9622093\n",
      "Test Prediction = 0.8521739\n",
      "=========== RUN 61=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 9.897\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 2.636\tAcc: 54.65117%\n",
      "Step:   200\tLoss: 1.107\tAcc: 70.93023%\n",
      "Step:   300\tLoss: 0.784\tAcc: 79.65117%\n",
      "Step:   400\tLoss: 0.611\tAcc: 84.59302%\n",
      "Step:   500\tLoss: 0.508\tAcc: 88.66279%\n",
      "Step:   600\tLoss: 0.434\tAcc: 90.98837%\n",
      "Step:   700\tLoss: 0.363\tAcc: 91.56977%\n",
      "Step:   800\tLoss: 0.305\tAcc: 93.02326%\n",
      "Step:   900\tLoss: 0.264\tAcc: 93.89535%\n",
      "Step:  1000\tLoss: 0.232\tAcc: 94.18604%\n",
      "Step:  1100\tLoss: 0.206\tAcc: 95.05814%\n",
      "Step:  1200\tLoss: 0.186\tAcc: 95.63953%\n",
      "Step:  1300\tLoss: 0.169\tAcc: 96.22093%\n",
      "Step:  1400\tLoss: 0.156\tAcc: 96.22093%\n",
      "Step:  1500\tLoss: 0.146\tAcc: 96.80232%\n",
      "Step:  1600\tLoss: 0.137\tAcc: 97.09302%\n",
      "Step:  1700\tLoss: 0.130\tAcc: 97.09302%\n",
      "Step:  1800\tLoss: 0.124\tAcc: 97.09302%\n",
      "Step:  1900\tLoss: 0.119\tAcc: 97.38372%\n",
      "Step:  2000\tLoss: 0.114\tAcc: 97.67442%\n",
      "Step:  2100\tLoss: 0.110\tAcc: 97.67442%\n",
      "Step:  2200\tLoss: 0.106\tAcc: 97.67442%\n",
      "Step:  2300\tLoss: 0.102\tAcc: 97.96512%\n",
      "Step:  2400\tLoss: 0.099\tAcc: 98.25581%\n",
      "Step:  2500\tLoss: 0.095\tAcc: 98.25581%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.98255813\n",
      "Test Prediction = 0.9\n",
      "=========== RUN 62=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 17.502\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 9.398\tAcc: 48.54651%\n",
      "Step:   200\tLoss: 4.417\tAcc: 53.19768%\n",
      "Step:   300\tLoss: 1.756\tAcc: 59.01163%\n",
      "Step:   400\tLoss: 1.051\tAcc: 67.73256%\n",
      "Step:   500\tLoss: 0.783\tAcc: 72.96512%\n",
      "Step:   600\tLoss: 0.631\tAcc: 77.61628%\n",
      "Step:   700\tLoss: 0.519\tAcc: 81.97674%\n",
      "Step:   800\tLoss: 0.441\tAcc: 84.59302%\n",
      "Step:   900\tLoss: 0.382\tAcc: 85.46512%\n",
      "Step:  1000\tLoss: 0.338\tAcc: 86.91860%\n",
      "Step:  1100\tLoss: 0.303\tAcc: 87.79070%\n",
      "Step:  1200\tLoss: 0.276\tAcc: 89.82558%\n",
      "Step:  1300\tLoss: 0.254\tAcc: 90.98837%\n",
      "Step:  1400\tLoss: 0.235\tAcc: 92.73256%\n",
      "Step:  1500\tLoss: 0.219\tAcc: 93.60465%\n",
      "Step:  1600\tLoss: 0.205\tAcc: 94.47674%\n",
      "Step:  1700\tLoss: 0.192\tAcc: 95.34883%\n",
      "Step:  1800\tLoss: 0.183\tAcc: 95.93023%\n",
      "Step:  1900\tLoss: 0.174\tAcc: 96.22093%\n",
      "Step:  2000\tLoss: 0.166\tAcc: 96.80232%\n",
      "Step:  2100\tLoss: 0.159\tAcc: 97.09302%\n",
      "Step:  2200\tLoss: 0.153\tAcc: 97.09302%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9709302\n",
      "Test Prediction = 0.8608696\n",
      "=========== RUN 63=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 1.837\tAcc: 48.25581%\n",
      "Step:   100\tLoss: 0.859\tAcc: 75.58140%\n",
      "Step:   200\tLoss: 0.634\tAcc: 80.81396%\n",
      "Step:   300\tLoss: 0.502\tAcc: 84.01163%\n",
      "Step:   400\tLoss: 0.419\tAcc: 86.04651%\n",
      "Step:   500\tLoss: 0.365\tAcc: 88.37209%\n",
      "Step:   600\tLoss: 0.326\tAcc: 90.40698%\n",
      "Step:   700\tLoss: 0.298\tAcc: 91.86047%\n",
      "Step:   800\tLoss: 0.274\tAcc: 92.73256%\n",
      "Step:   900\tLoss: 0.255\tAcc: 93.89535%\n",
      "Step:  1000\tLoss: 0.238\tAcc: 94.47674%\n",
      "Step:  1100\tLoss: 0.223\tAcc: 94.47674%\n",
      "Step:  1200\tLoss: 0.209\tAcc: 94.76744%\n",
      "Step:  1300\tLoss: 0.196\tAcc: 94.76744%\n",
      "Step:  1400\tLoss: 0.184\tAcc: 95.34883%\n",
      "Step:  1500\tLoss: 0.173\tAcc: 95.63953%\n",
      "Step:  1600\tLoss: 0.162\tAcc: 95.93023%\n",
      "Step:  1700\tLoss: 0.152\tAcc: 96.51163%\n",
      "Step:  1800\tLoss: 0.143\tAcc: 97.09302%\n",
      "Step:  1900\tLoss: 0.135\tAcc: 97.09302%\n",
      "Step:  2000\tLoss: 0.128\tAcc: 97.38372%\n",
      "Step:  2100\tLoss: 0.121\tAcc: 97.38372%\n",
      "Step:  2200\tLoss: 0.115\tAcc: 97.67442%\n",
      "Step:  2300\tLoss: 0.109\tAcc: 97.67442%\n",
      "Step:  2400\tLoss: 0.104\tAcc: 97.67442%\n",
      "Step:  2500\tLoss: 0.098\tAcc: 97.96512%\n",
      "Step:  2600\tLoss: 0.093\tAcc: 97.96512%\n",
      "Step:  2700\tLoss: 0.089\tAcc: 97.96512%\n",
      "Step:  2800\tLoss: 0.086\tAcc: 98.25581%\n",
      "Step:  2900\tLoss: 0.083\tAcc: 99.12791%\n",
      "Step:  3000\tLoss: 0.080\tAcc: 99.12791%\n",
      "Step:  3100\tLoss: 0.078\tAcc: 99.12791%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.99127907\n",
      "Test Prediction = 0.8695652\n",
      "=========== RUN 64=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 3.498\tAcc: 52.03488%\n",
      "Step:   100\tLoss: 0.775\tAcc: 77.32558%\n",
      "Step:   200\tLoss: 0.631\tAcc: 82.55814%\n",
      "Step:   300\tLoss: 0.553\tAcc: 84.88372%\n",
      "Step:   400\tLoss: 0.494\tAcc: 88.37209%\n",
      "Step:   500\tLoss: 0.447\tAcc: 90.11628%\n",
      "Step:   600\tLoss: 0.415\tAcc: 90.98837%\n",
      "Step:   700\tLoss: 0.388\tAcc: 91.27907%\n",
      "Step:   800\tLoss: 0.366\tAcc: 92.44186%\n",
      "Step:   900\tLoss: 0.346\tAcc: 92.44186%\n",
      "Step:  1000\tLoss: 0.327\tAcc: 93.31396%\n",
      "Step:  1100\tLoss: 0.310\tAcc: 94.18604%\n",
      "Step:  1200\tLoss: 0.293\tAcc: 94.47674%\n",
      "Step:  1300\tLoss: 0.277\tAcc: 95.63953%\n",
      "Step:  1400\tLoss: 0.261\tAcc: 95.93023%\n",
      "Step:  1500\tLoss: 0.247\tAcc: 96.22093%\n",
      "Step:  1600\tLoss: 0.235\tAcc: 95.93023%\n",
      "Step:  1700\tLoss: 0.223\tAcc: 96.22093%\n",
      "Step:  1800\tLoss: 0.213\tAcc: 96.80232%\n",
      "Step:  1900\tLoss: 0.204\tAcc: 96.80232%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.96802324\n",
      "Test Prediction = 0.84347826\n",
      "=========== RUN 65=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 2.890\tAcc: 48.25581%\n",
      "Step:   100\tLoss: 1.059\tAcc: 63.95349%\n",
      "Step:   200\tLoss: 0.670\tAcc: 73.83721%\n",
      "Step:   300\tLoss: 0.514\tAcc: 82.84883%\n",
      "Step:   400\tLoss: 0.429\tAcc: 86.33721%\n",
      "Step:   500\tLoss: 0.371\tAcc: 87.79070%\n",
      "Step:   600\tLoss: 0.328\tAcc: 88.95349%\n",
      "Step:   700\tLoss: 0.296\tAcc: 90.98837%\n",
      "Step:   800\tLoss: 0.271\tAcc: 92.15117%\n",
      "Step:   900\tLoss: 0.251\tAcc: 92.73256%\n",
      "Step:  1000\tLoss: 0.235\tAcc: 93.60465%\n",
      "Step:  1100\tLoss: 0.221\tAcc: 94.47674%\n",
      "Step:  1200\tLoss: 0.210\tAcc: 94.76744%\n",
      "Step:  1300\tLoss: 0.199\tAcc: 94.76744%\n",
      "Step:  1400\tLoss: 0.190\tAcc: 95.34883%\n",
      "Step:  1500\tLoss: 0.182\tAcc: 95.63953%\n",
      "Step:  1600\tLoss: 0.175\tAcc: 96.80232%\n",
      "Step:  1700\tLoss: 0.169\tAcc: 97.09302%\n",
      "Step:  1800\tLoss: 0.163\tAcc: 97.38372%\n",
      "Step:  1900\tLoss: 0.157\tAcc: 97.38372%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9738372\n",
      "Test Prediction = 0.87391305\n",
      "=========== RUN 66=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 4.331\tAcc: 50.29070%\n",
      "Step:   100\tLoss: 1.429\tAcc: 63.66279%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:   200\tLoss: 0.910\tAcc: 69.47674%\n",
      "Step:   300\tLoss: 0.672\tAcc: 72.96512%\n",
      "Step:   400\tLoss: 0.523\tAcc: 79.65117%\n",
      "Step:   500\tLoss: 0.436\tAcc: 83.13953%\n",
      "Step:   600\tLoss: 0.374\tAcc: 87.50000%\n",
      "Step:   700\tLoss: 0.327\tAcc: 90.11628%\n",
      "Step:   800\tLoss: 0.291\tAcc: 92.44186%\n",
      "Step:   900\tLoss: 0.263\tAcc: 92.73256%\n",
      "Step:  1000\tLoss: 0.240\tAcc: 93.02326%\n",
      "Step:  1100\tLoss: 0.221\tAcc: 93.31396%\n",
      "Step:  1200\tLoss: 0.205\tAcc: 93.60465%\n",
      "Step:  1300\tLoss: 0.189\tAcc: 95.05814%\n",
      "Step:  1400\tLoss: 0.171\tAcc: 95.63953%\n",
      "Step:  1500\tLoss: 0.159\tAcc: 95.63953%\n",
      "Step:  1600\tLoss: 0.150\tAcc: 95.93023%\n",
      "Step:  1700\tLoss: 0.143\tAcc: 96.22093%\n",
      "Step:  1800\tLoss: 0.136\tAcc: 96.22093%\n",
      "Step:  1900\tLoss: 0.130\tAcc: 96.22093%\n",
      "Step:  2000\tLoss: 0.125\tAcc: 96.80232%\n",
      "Step:  2100\tLoss: 0.120\tAcc: 97.38372%\n",
      "Step:  2200\tLoss: 0.115\tAcc: 97.96512%\n",
      "Step:  2300\tLoss: 0.112\tAcc: 97.96512%\n",
      "Step:  2400\tLoss: 0.108\tAcc: 98.25581%\n",
      "Step:  2500\tLoss: 0.105\tAcc: 98.25581%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.98255813\n",
      "Test Prediction = 0.87391305\n",
      "=========== RUN 67=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 10.103\tAcc: 48.25581%\n",
      "Step:   100\tLoss: 3.228\tAcc: 54.65117%\n",
      "Step:   200\tLoss: 0.892\tAcc: 75.29070%\n",
      "Step:   300\tLoss: 0.605\tAcc: 78.19768%\n",
      "Step:   400\tLoss: 0.472\tAcc: 80.52326%\n",
      "Step:   500\tLoss: 0.400\tAcc: 84.01163%\n",
      "Step:   600\tLoss: 0.351\tAcc: 83.72093%\n",
      "Step:   700\tLoss: 0.313\tAcc: 86.33721%\n",
      "Step:   800\tLoss: 0.284\tAcc: 88.37209%\n",
      "Step:   900\tLoss: 0.259\tAcc: 90.69768%\n",
      "Step:  1000\tLoss: 0.239\tAcc: 90.98837%\n",
      "Step:  1100\tLoss: 0.219\tAcc: 92.73256%\n",
      "Step:  1200\tLoss: 0.206\tAcc: 93.02326%\n",
      "Step:  1300\tLoss: 0.195\tAcc: 94.76744%\n",
      "Step:  1400\tLoss: 0.185\tAcc: 95.34883%\n",
      "Step:  1500\tLoss: 0.175\tAcc: 95.93023%\n",
      "Step:  1600\tLoss: 0.167\tAcc: 96.80232%\n",
      "Step:  1700\tLoss: 0.160\tAcc: 96.80232%\n",
      "Step:  1800\tLoss: 0.154\tAcc: 96.80232%\n",
      "Step:  1900\tLoss: 0.149\tAcc: 96.80232%\n",
      "Step:  2000\tLoss: 0.144\tAcc: 97.38372%\n",
      "Step:  2100\tLoss: 0.140\tAcc: 97.96512%\n",
      "Step:  2200\tLoss: 0.137\tAcc: 97.96512%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.97965115\n",
      "Test Prediction = 0.84347826\n",
      "=========== RUN 68=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 9.782\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 3.113\tAcc: 48.25581%\n",
      "Step:   200\tLoss: 1.276\tAcc: 62.50000%\n",
      "Step:   300\tLoss: 0.725\tAcc: 78.19768%\n",
      "Step:   400\tLoss: 0.541\tAcc: 84.30232%\n",
      "Step:   500\tLoss: 0.442\tAcc: 86.91860%\n",
      "Step:   600\tLoss: 0.378\tAcc: 88.08140%\n",
      "Step:   700\tLoss: 0.333\tAcc: 89.82558%\n",
      "Step:   800\tLoss: 0.297\tAcc: 90.98837%\n",
      "Step:   900\tLoss: 0.267\tAcc: 92.73256%\n",
      "Step:  1000\tLoss: 0.242\tAcc: 93.31396%\n",
      "Step:  1100\tLoss: 0.221\tAcc: 93.60465%\n",
      "Step:  1200\tLoss: 0.202\tAcc: 93.60465%\n",
      "Step:  1300\tLoss: 0.186\tAcc: 93.89535%\n",
      "Step:  1400\tLoss: 0.172\tAcc: 94.76744%\n",
      "Step:  1500\tLoss: 0.160\tAcc: 95.63953%\n",
      "Step:  1600\tLoss: 0.150\tAcc: 96.22093%\n",
      "Step:  1700\tLoss: 0.141\tAcc: 96.22093%\n",
      "Step:  1800\tLoss: 0.133\tAcc: 96.22093%\n",
      "Step:  1900\tLoss: 0.126\tAcc: 96.22093%\n",
      "Step:  2000\tLoss: 0.120\tAcc: 97.09302%\n",
      "Step:  2100\tLoss: 0.114\tAcc: 97.38372%\n",
      "Step:  2200\tLoss: 0.108\tAcc: 98.25581%\n",
      "Step:  2300\tLoss: 0.103\tAcc: 98.25581%\n",
      "Step:  2400\tLoss: 0.099\tAcc: 98.54651%\n",
      "Step:  2500\tLoss: 0.094\tAcc: 98.54651%\n",
      "Step:  2600\tLoss: 0.090\tAcc: 98.83721%\n",
      "Step:  2700\tLoss: 0.085\tAcc: 98.83721%\n",
      "Step:  2800\tLoss: 0.082\tAcc: 98.83721%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9883721\n",
      "Test Prediction = 0.8608696\n",
      "=========== RUN 69=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 19.581\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 9.731\tAcc: 49.12791%\n",
      "Step:   200\tLoss: 3.945\tAcc: 50.87209%\n",
      "Step:   300\tLoss: 2.133\tAcc: 61.04651%\n",
      "Step:   400\tLoss: 1.365\tAcc: 63.37209%\n",
      "Step:   500\tLoss: 0.973\tAcc: 70.34883%\n",
      "Step:   600\tLoss: 0.756\tAcc: 76.74419%\n",
      "Step:   700\tLoss: 0.618\tAcc: 79.06977%\n",
      "Step:   800\tLoss: 0.518\tAcc: 80.23256%\n",
      "Step:   900\tLoss: 0.439\tAcc: 83.43023%\n",
      "Step:  1000\tLoss: 0.379\tAcc: 86.91860%\n",
      "Step:  1100\tLoss: 0.333\tAcc: 87.79070%\n",
      "Step:  1200\tLoss: 0.295\tAcc: 90.40698%\n",
      "Step:  1300\tLoss: 0.264\tAcc: 91.56977%\n",
      "Step:  1400\tLoss: 0.236\tAcc: 92.15117%\n",
      "Step:  1500\tLoss: 0.213\tAcc: 93.60465%\n",
      "Step:  1600\tLoss: 0.196\tAcc: 95.34883%\n",
      "Step:  1700\tLoss: 0.181\tAcc: 95.34883%\n",
      "Step:  1800\tLoss: 0.169\tAcc: 95.63953%\n",
      "Step:  1900\tLoss: 0.158\tAcc: 95.93023%\n",
      "Step:  2000\tLoss: 0.149\tAcc: 96.51163%\n",
      "Step:  2100\tLoss: 0.142\tAcc: 96.51163%\n",
      "Step:  2200\tLoss: 0.134\tAcc: 96.51163%\n",
      "Step:  2300\tLoss: 0.128\tAcc: 96.80232%\n",
      "Step:  2400\tLoss: 0.123\tAcc: 97.38372%\n",
      "Step:  2500\tLoss: 0.118\tAcc: 97.67442%\n",
      "Step:  2600\tLoss: 0.113\tAcc: 97.67442%\n",
      "Step:  2700\tLoss: 0.109\tAcc: 97.96512%\n",
      "Step:  2800\tLoss: 0.105\tAcc: 97.96512%\n",
      "Step:  2900\tLoss: 0.102\tAcc: 98.25581%\n",
      "Step:  3000\tLoss: 0.098\tAcc: 98.54651%\n",
      "Step:  3100\tLoss: 0.096\tAcc: 98.54651%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9854651\n",
      "Test Prediction = 0.8521739\n",
      "=========== RUN 70=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 8.886\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 2.361\tAcc: 49.12791%\n",
      "Step:   200\tLoss: 1.106\tAcc: 65.40698%\n",
      "Step:   300\tLoss: 0.759\tAcc: 76.16279%\n",
      "Step:   400\tLoss: 0.590\tAcc: 79.36047%\n",
      "Step:   500\tLoss: 0.494\tAcc: 82.55814%\n",
      "Step:   600\tLoss: 0.429\tAcc: 85.17442%\n",
      "Step:   700\tLoss: 0.383\tAcc: 87.50000%\n",
      "Step:   800\tLoss: 0.349\tAcc: 88.95349%\n",
      "Step:   900\tLoss: 0.322\tAcc: 90.69768%\n",
      "Step:  1000\tLoss: 0.299\tAcc: 91.27907%\n",
      "Step:  1100\tLoss: 0.278\tAcc: 92.15117%\n",
      "Step:  1200\tLoss: 0.260\tAcc: 92.73256%\n",
      "Step:  1300\tLoss: 0.246\tAcc: 93.60465%\n",
      "Step:  1400\tLoss: 0.234\tAcc: 93.89535%\n",
      "Step:  1500\tLoss: 0.223\tAcc: 93.89535%\n",
      "Step:  1600\tLoss: 0.214\tAcc: 94.18604%\n",
      "Step:  1700\tLoss: 0.206\tAcc: 94.47674%\n",
      "Step:  1800\tLoss: 0.199\tAcc: 94.47674%\n",
      "Step:  1900\tLoss: 0.192\tAcc: 94.76744%\n",
      "Step:  2000\tLoss: 0.186\tAcc: 95.34883%\n",
      "Step:  2100\tLoss: 0.181\tAcc: 95.63953%\n",
      "Step:  2200\tLoss: 0.176\tAcc: 95.63953%\n",
      "Step:  2300\tLoss: 0.171\tAcc: 95.93023%\n",
      "Step:  2400\tLoss: 0.166\tAcc: 96.22093%\n",
      "Step:  2500\tLoss: 0.161\tAcc: 96.51163%\n",
      "Step:  2600\tLoss: 0.157\tAcc: 96.51163%\n",
      "Step:  2700\tLoss: 0.153\tAcc: 96.51163%\n",
      "Step:  2800\tLoss: 0.149\tAcc: 96.51163%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.96511626\n",
      "Test Prediction = 0.8565217\n",
      "=========== RUN 71=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 12.593\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 4.057\tAcc: 48.54651%\n",
      "Step:   200\tLoss: 2.019\tAcc: 59.88372%\n",
      "Step:   300\tLoss: 1.319\tAcc: 69.76744%\n",
      "Step:   400\tLoss: 0.920\tAcc: 72.67442%\n",
      "Step:   500\tLoss: 0.718\tAcc: 75.58140%\n",
      "Step:   600\tLoss: 0.604\tAcc: 79.06977%\n",
      "Step:   700\tLoss: 0.520\tAcc: 80.52326%\n",
      "Step:   800\tLoss: 0.451\tAcc: 81.68604%\n",
      "Step:   900\tLoss: 0.395\tAcc: 88.37209%\n",
      "Step:  1000\tLoss: 0.349\tAcc: 89.82558%\n",
      "Step:  1100\tLoss: 0.313\tAcc: 90.40698%\n",
      "Step:  1200\tLoss: 0.283\tAcc: 90.98837%\n",
      "Step:  1300\tLoss: 0.258\tAcc: 91.86047%\n",
      "Step:  1400\tLoss: 0.236\tAcc: 93.02326%\n",
      "Step:  1500\tLoss: 0.216\tAcc: 93.60465%\n",
      "Step:  1600\tLoss: 0.199\tAcc: 94.18604%\n",
      "Step:  1700\tLoss: 0.185\tAcc: 94.76744%\n",
      "Step:  1800\tLoss: 0.173\tAcc: 95.34883%\n",
      "Step:  1900\tLoss: 0.162\tAcc: 96.22093%\n",
      "Step:  2000\tLoss: 0.153\tAcc: 95.93023%\n",
      "Step:  2100\tLoss: 0.145\tAcc: 96.22093%\n",
      "Step:  2200\tLoss: 0.137\tAcc: 96.22093%\n",
      "Step:  2300\tLoss: 0.131\tAcc: 96.51163%\n",
      "Step:  2400\tLoss: 0.124\tAcc: 97.09302%\n",
      "Step:  2500\tLoss: 0.119\tAcc: 97.38372%\n",
      "Step:  2600\tLoss: 0.114\tAcc: 97.67442%\n",
      "Step:  2700\tLoss: 0.109\tAcc: 97.67442%\n",
      "Step:  2800\tLoss: 0.105\tAcc: 97.67442%\n",
      "Step:  2900\tLoss: 0.101\tAcc: 97.96512%\n",
      "Step:  3000\tLoss: 0.097\tAcc: 98.54651%\n",
      "Step:  3100\tLoss: 0.093\tAcc: 98.83721%\n",
      "Step:  3200\tLoss: 0.090\tAcc: 98.83721%\n",
      "Step:  3300\tLoss: 0.087\tAcc: 98.83721%\n",
      "Step:  3400\tLoss: 0.084\tAcc: 98.83721%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9883721\n",
      "Test Prediction = 0.8652174\n",
      "=========== RUN 72=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 3.725\tAcc: 51.16279%\n",
      "Step:   100\tLoss: 1.353\tAcc: 61.91860%\n",
      "Step:   200\tLoss: 0.912\tAcc: 71.22093%\n",
      "Step:   300\tLoss: 0.672\tAcc: 79.65117%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:   400\tLoss: 0.530\tAcc: 83.43023%\n",
      "Step:   500\tLoss: 0.441\tAcc: 84.88372%\n",
      "Step:   600\tLoss: 0.371\tAcc: 87.79070%\n",
      "Step:   700\tLoss: 0.320\tAcc: 89.82558%\n",
      "Step:   800\tLoss: 0.280\tAcc: 90.69768%\n",
      "Step:   900\tLoss: 0.245\tAcc: 92.15117%\n",
      "Step:  1000\tLoss: 0.216\tAcc: 95.05814%\n",
      "Step:  1100\tLoss: 0.193\tAcc: 95.05814%\n",
      "Step:  1200\tLoss: 0.174\tAcc: 95.63953%\n",
      "Step:  1300\tLoss: 0.158\tAcc: 96.22093%\n",
      "Step:  1400\tLoss: 0.144\tAcc: 97.09302%\n",
      "Step:  1500\tLoss: 0.133\tAcc: 97.67442%\n",
      "Step:  1600\tLoss: 0.123\tAcc: 97.96512%\n",
      "Step:  1700\tLoss: 0.114\tAcc: 97.96512%\n",
      "Step:  1800\tLoss: 0.107\tAcc: 98.25581%\n",
      "Step:  1900\tLoss: 0.101\tAcc: 98.25581%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.98255813\n",
      "Test Prediction = 0.87826085\n",
      "=========== RUN 73=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 6.271\tAcc: 47.96512%\n",
      "Step:   100\tLoss: 1.236\tAcc: 62.50000%\n",
      "Step:   200\tLoss: 0.665\tAcc: 76.74419%\n",
      "Step:   300\tLoss: 0.501\tAcc: 82.55814%\n",
      "Step:   400\tLoss: 0.396\tAcc: 88.08140%\n",
      "Step:   500\tLoss: 0.339\tAcc: 89.53488%\n",
      "Step:   600\tLoss: 0.301\tAcc: 91.56977%\n",
      "Step:   700\tLoss: 0.270\tAcc: 92.44186%\n",
      "Step:   800\tLoss: 0.244\tAcc: 92.73256%\n",
      "Step:   900\tLoss: 0.224\tAcc: 93.02326%\n",
      "Step:  1000\tLoss: 0.208\tAcc: 94.18604%\n",
      "Step:  1100\tLoss: 0.193\tAcc: 94.18604%\n",
      "Step:  1200\tLoss: 0.181\tAcc: 94.47674%\n",
      "Step:  1300\tLoss: 0.170\tAcc: 95.34883%\n",
      "Step:  1400\tLoss: 0.160\tAcc: 95.63953%\n",
      "Step:  1500\tLoss: 0.150\tAcc: 96.51163%\n",
      "Step:  1600\tLoss: 0.143\tAcc: 97.09302%\n",
      "Step:  1700\tLoss: 0.136\tAcc: 97.96512%\n",
      "Step:  1800\tLoss: 0.131\tAcc: 98.25581%\n",
      "Step:  1900\tLoss: 0.126\tAcc: 98.25581%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.98255813\n",
      "Test Prediction = 0.87391305\n",
      "=========== RUN 74=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 2.202\tAcc: 49.70930%\n",
      "Step:   100\tLoss: 0.623\tAcc: 79.65117%\n",
      "Step:   200\tLoss: 0.469\tAcc: 82.84883%\n",
      "Step:   300\tLoss: 0.381\tAcc: 88.37209%\n",
      "Step:   400\tLoss: 0.320\tAcc: 90.40698%\n",
      "Step:   500\tLoss: 0.280\tAcc: 90.40698%\n",
      "Step:   600\tLoss: 0.252\tAcc: 90.69768%\n",
      "Step:   700\tLoss: 0.228\tAcc: 92.44186%\n",
      "Step:   800\tLoss: 0.208\tAcc: 93.60465%\n",
      "Step:   900\tLoss: 0.193\tAcc: 94.47674%\n",
      "Step:  1000\tLoss: 0.180\tAcc: 94.76744%\n",
      "Step:  1100\tLoss: 0.170\tAcc: 95.34883%\n",
      "Step:  1200\tLoss: 0.160\tAcc: 95.63953%\n",
      "Step:  1300\tLoss: 0.152\tAcc: 95.63953%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9563953\n",
      "Test Prediction = 0.8608696\n",
      "=========== RUN 75=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 4.478\tAcc: 47.96512%\n",
      "Step:   100\tLoss: 1.516\tAcc: 67.73256%\n",
      "Step:   200\tLoss: 0.938\tAcc: 74.70930%\n",
      "Step:   300\tLoss: 0.684\tAcc: 82.26744%\n",
      "Step:   400\tLoss: 0.538\tAcc: 84.88372%\n",
      "Step:   500\tLoss: 0.445\tAcc: 87.79070%\n",
      "Step:   600\tLoss: 0.372\tAcc: 90.69768%\n",
      "Step:   700\tLoss: 0.313\tAcc: 93.02326%\n",
      "Step:   800\tLoss: 0.263\tAcc: 93.31396%\n",
      "Step:   900\tLoss: 0.228\tAcc: 93.89535%\n",
      "Step:  1000\tLoss: 0.203\tAcc: 94.47674%\n",
      "Step:  1100\tLoss: 0.185\tAcc: 94.47674%\n",
      "Step:  1200\tLoss: 0.171\tAcc: 95.05814%\n",
      "Step:  1300\tLoss: 0.158\tAcc: 96.80232%\n",
      "Step:  1400\tLoss: 0.148\tAcc: 96.80232%\n",
      "Step:  1500\tLoss: 0.140\tAcc: 97.38372%\n",
      "Step:  1600\tLoss: 0.132\tAcc: 97.67442%\n",
      "Step:  1700\tLoss: 0.125\tAcc: 97.67442%\n",
      "Step:  1800\tLoss: 0.119\tAcc: 98.25581%\n",
      "Step:  1900\tLoss: 0.114\tAcc: 98.54651%\n",
      "Step:  2000\tLoss: 0.109\tAcc: 98.54651%\n",
      "Step:  2100\tLoss: 0.105\tAcc: 98.54651%\n",
      "Step:  2200\tLoss: 0.100\tAcc: 98.54651%\n",
      "Step:  2300\tLoss: 0.096\tAcc: 98.83721%\n",
      "Step:  2400\tLoss: 0.093\tAcc: 98.83721%\n",
      "Step:  2500\tLoss: 0.089\tAcc: 98.83721%\n",
      "Step:  2600\tLoss: 0.086\tAcc: 99.12791%\n",
      "Step:  2700\tLoss: 0.083\tAcc: 99.12791%\n",
      "Step:  2800\tLoss: 0.080\tAcc: 99.12791%\n",
      "Step:  2900\tLoss: 0.078\tAcc: 99.41860%\n",
      "Step:  3000\tLoss: 0.075\tAcc: 99.41860%\n",
      "Step:  3100\tLoss: 0.073\tAcc: 99.41860%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.99418604\n",
      "Test Prediction = 0.87391305\n",
      "=========== RUN 76=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 11.539\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 3.464\tAcc: 43.89535%\n",
      "Step:   200\tLoss: 1.587\tAcc: 57.55814%\n",
      "Step:   300\tLoss: 1.009\tAcc: 72.67442%\n",
      "Step:   400\tLoss: 0.740\tAcc: 77.32558%\n",
      "Step:   500\tLoss: 0.558\tAcc: 80.81396%\n",
      "Step:   600\tLoss: 0.458\tAcc: 85.46512%\n",
      "Step:   700\tLoss: 0.391\tAcc: 87.50000%\n",
      "Step:   800\tLoss: 0.343\tAcc: 90.40698%\n",
      "Step:   900\tLoss: 0.308\tAcc: 91.86047%\n",
      "Step:  1000\tLoss: 0.280\tAcc: 92.44186%\n",
      "Step:  1100\tLoss: 0.257\tAcc: 93.02326%\n",
      "Step:  1200\tLoss: 0.238\tAcc: 94.18604%\n",
      "Step:  1300\tLoss: 0.221\tAcc: 94.76744%\n",
      "Step:  1400\tLoss: 0.207\tAcc: 95.34883%\n",
      "Step:  1500\tLoss: 0.195\tAcc: 95.34883%\n",
      "Step:  1600\tLoss: 0.185\tAcc: 95.93023%\n",
      "Step:  1700\tLoss: 0.176\tAcc: 95.93023%\n",
      "Step:  1800\tLoss: 0.167\tAcc: 95.93023%\n",
      "Step:  1900\tLoss: 0.160\tAcc: 96.51163%\n",
      "Step:  2000\tLoss: 0.153\tAcc: 96.80232%\n",
      "Step:  2100\tLoss: 0.147\tAcc: 97.09302%\n",
      "Step:  2200\tLoss: 0.141\tAcc: 97.09302%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9709302\n",
      "Test Prediction = 0.8869565\n",
      "=========== RUN 77=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 9.404\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 3.214\tAcc: 50.29070%\n",
      "Step:   200\tLoss: 1.462\tAcc: 52.90698%\n",
      "Step:   300\tLoss: 0.939\tAcc: 67.15117%\n",
      "Step:   400\tLoss: 0.714\tAcc: 79.36047%\n",
      "Step:   500\tLoss: 0.575\tAcc: 82.26744%\n",
      "Step:   600\tLoss: 0.486\tAcc: 82.55814%\n",
      "Step:   700\tLoss: 0.419\tAcc: 84.01163%\n",
      "Step:   800\tLoss: 0.367\tAcc: 85.46512%\n",
      "Step:   900\tLoss: 0.324\tAcc: 87.20930%\n",
      "Step:  1000\tLoss: 0.284\tAcc: 89.24419%\n",
      "Step:  1100\tLoss: 0.249\tAcc: 90.98837%\n",
      "Step:  1200\tLoss: 0.225\tAcc: 91.27907%\n",
      "Step:  1300\tLoss: 0.206\tAcc: 91.86047%\n",
      "Step:  1400\tLoss: 0.190\tAcc: 92.73256%\n",
      "Step:  1500\tLoss: 0.177\tAcc: 95.05814%\n",
      "Step:  1600\tLoss: 0.166\tAcc: 96.51163%\n",
      "Step:  1700\tLoss: 0.157\tAcc: 96.80232%\n",
      "Step:  1800\tLoss: 0.148\tAcc: 97.38372%\n",
      "Step:  1900\tLoss: 0.140\tAcc: 97.96512%\n",
      "Step:  2000\tLoss: 0.134\tAcc: 97.96512%\n",
      "Step:  2100\tLoss: 0.129\tAcc: 98.25581%\n",
      "Step:  2200\tLoss: 0.124\tAcc: 98.54651%\n",
      "Step:  2300\tLoss: 0.120\tAcc: 98.54651%\n",
      "Step:  2400\tLoss: 0.116\tAcc: 98.54651%\n",
      "Step:  2500\tLoss: 0.112\tAcc: 98.83721%\n",
      "Step:  2600\tLoss: 0.108\tAcc: 98.83721%\n",
      "Step:  2700\tLoss: 0.105\tAcc: 98.83721%\n",
      "Step:  2800\tLoss: 0.102\tAcc: 98.83721%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9883721\n",
      "Test Prediction = 0.8826087\n",
      "=========== RUN 78=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 24.918\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 16.462\tAcc: 47.67442%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.47674417\n",
      "Test Prediction = 0.5347826\n",
      "=========== RUN 79=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 1.831\tAcc: 48.83721%\n",
      "Step:   100\tLoss: 0.762\tAcc: 70.63953%\n",
      "Step:   200\tLoss: 0.502\tAcc: 81.39535%\n",
      "Step:   300\tLoss: 0.387\tAcc: 86.33721%\n",
      "Step:   400\tLoss: 0.326\tAcc: 88.66279%\n",
      "Step:   500\tLoss: 0.283\tAcc: 91.27907%\n",
      "Step:   600\tLoss: 0.249\tAcc: 91.27907%\n",
      "Step:   700\tLoss: 0.221\tAcc: 93.31396%\n",
      "Step:   800\tLoss: 0.196\tAcc: 94.18604%\n",
      "Step:   900\tLoss: 0.173\tAcc: 94.76744%\n",
      "Step:  1000\tLoss: 0.158\tAcc: 95.93023%\n",
      "Step:  1100\tLoss: 0.146\tAcc: 96.80232%\n",
      "Step:  1200\tLoss: 0.136\tAcc: 96.80232%\n",
      "Step:  1300\tLoss: 0.128\tAcc: 96.80232%\n",
      "Step:  1400\tLoss: 0.121\tAcc: 97.09302%\n",
      "Step:  1500\tLoss: 0.114\tAcc: 97.38372%\n",
      "Step:  1600\tLoss: 0.109\tAcc: 98.25581%\n",
      "Step:  1700\tLoss: 0.104\tAcc: 98.25581%\n",
      "Step:  1800\tLoss: 0.100\tAcc: 98.25581%\n",
      "Step:  1900\tLoss: 0.096\tAcc: 98.25581%\n",
      "Step:  2000\tLoss: 0.092\tAcc: 98.54651%\n",
      "Step:  2100\tLoss: 0.089\tAcc: 98.54651%\n",
      "Step:  2200\tLoss: 0.086\tAcc: 98.83721%\n",
      "Step:  2300\tLoss: 0.084\tAcc: 98.83721%\n",
      "Step:  2400\tLoss: 0.081\tAcc: 98.83721%\n",
      "Step:  2500\tLoss: 0.079\tAcc: 98.83721%\n",
      "Step:  2600\tLoss: 0.077\tAcc: 99.12791%\n",
      "Step:  2700\tLoss: 0.075\tAcc: 99.12791%\n",
      "Step:  2800\tLoss: 0.073\tAcc: 99.41860%\n",
      "Step:  2900\tLoss: 0.072\tAcc: 99.41860%\n",
      "Step:  3000\tLoss: 0.070\tAcc: 99.41860%\n",
      "Step:  3100\tLoss: 0.069\tAcc: 99.41860%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.99418604\n",
      "Test Prediction = 0.8913044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== RUN 80=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 4.465\tAcc: 49.41860%\n",
      "Step:   100\tLoss: 1.452\tAcc: 59.01163%\n",
      "Step:   200\tLoss: 0.878\tAcc: 67.73256%\n",
      "Step:   300\tLoss: 0.602\tAcc: 77.03488%\n",
      "Step:   400\tLoss: 0.462\tAcc: 82.26744%\n",
      "Step:   500\tLoss: 0.380\tAcc: 86.62791%\n",
      "Step:   600\tLoss: 0.321\tAcc: 88.08140%\n",
      "Step:   700\tLoss: 0.281\tAcc: 89.82558%\n",
      "Step:   800\tLoss: 0.248\tAcc: 90.98837%\n",
      "Step:   900\tLoss: 0.221\tAcc: 92.15117%\n",
      "Step:  1000\tLoss: 0.197\tAcc: 93.31396%\n",
      "Step:  1100\tLoss: 0.179\tAcc: 95.63953%\n",
      "Step:  1200\tLoss: 0.163\tAcc: 96.22093%\n",
      "Step:  1300\tLoss: 0.151\tAcc: 96.22093%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9622093\n",
      "Test Prediction = 0.8347826\n",
      "=========== RUN 81=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 1.634\tAcc: 51.45349%\n",
      "Step:   100\tLoss: 0.835\tAcc: 71.22093%\n",
      "Step:   200\tLoss: 0.642\tAcc: 78.19768%\n",
      "Step:   300\tLoss: 0.524\tAcc: 84.59302%\n",
      "Step:   400\tLoss: 0.440\tAcc: 87.50000%\n",
      "Step:   500\tLoss: 0.383\tAcc: 89.24419%\n",
      "Step:   600\tLoss: 0.341\tAcc: 90.11628%\n",
      "Step:   700\tLoss: 0.309\tAcc: 91.27907%\n",
      "Step:   800\tLoss: 0.282\tAcc: 92.44186%\n",
      "Step:   900\tLoss: 0.260\tAcc: 93.31396%\n",
      "Step:  1000\tLoss: 0.243\tAcc: 93.31396%\n",
      "Step:  1100\tLoss: 0.228\tAcc: 93.89535%\n",
      "Step:  1200\tLoss: 0.215\tAcc: 93.89535%\n",
      "Step:  1300\tLoss: 0.201\tAcc: 93.89535%\n",
      "Step:  1400\tLoss: 0.189\tAcc: 95.05814%\n",
      "Step:  1500\tLoss: 0.180\tAcc: 95.34883%\n",
      "Step:  1600\tLoss: 0.171\tAcc: 95.63953%\n",
      "Step:  1700\tLoss: 0.162\tAcc: 95.63953%\n",
      "Step:  1800\tLoss: 0.155\tAcc: 95.93023%\n",
      "Step:  1900\tLoss: 0.148\tAcc: 96.22093%\n",
      "Step:  2000\tLoss: 0.142\tAcc: 96.22093%\n",
      "Step:  2100\tLoss: 0.137\tAcc: 96.80232%\n",
      "Step:  2200\tLoss: 0.132\tAcc: 97.38372%\n",
      "Step:  2300\tLoss: 0.127\tAcc: 97.67442%\n",
      "Step:  2400\tLoss: 0.122\tAcc: 97.67442%\n",
      "Step:  2500\tLoss: 0.118\tAcc: 97.96512%\n",
      "Step:  2600\tLoss: 0.114\tAcc: 97.96512%\n",
      "Step:  2700\tLoss: 0.111\tAcc: 98.25581%\n",
      "Step:  2800\tLoss: 0.108\tAcc: 98.25581%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.98255813\n",
      "Test Prediction = 0.8695652\n",
      "=========== RUN 82=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 29.121\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 19.790\tAcc: 47.67442%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.47674417\n",
      "Test Prediction = 0.5347826\n",
      "=========== RUN 83=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 3.922\tAcc: 55.23256%\n",
      "Step:   100\tLoss: 0.975\tAcc: 69.76744%\n",
      "Step:   200\tLoss: 0.614\tAcc: 81.10465%\n",
      "Step:   300\tLoss: 0.459\tAcc: 86.33721%\n",
      "Step:   400\tLoss: 0.381\tAcc: 87.79070%\n",
      "Step:   500\tLoss: 0.327\tAcc: 90.11628%\n",
      "Step:   600\tLoss: 0.290\tAcc: 91.86047%\n",
      "Step:   700\tLoss: 0.264\tAcc: 93.31396%\n",
      "Step:   800\tLoss: 0.244\tAcc: 94.47674%\n",
      "Step:   900\tLoss: 0.227\tAcc: 94.76744%\n",
      "Step:  1000\tLoss: 0.213\tAcc: 95.05814%\n",
      "Step:  1100\tLoss: 0.200\tAcc: 95.63953%\n",
      "Step:  1200\tLoss: 0.188\tAcc: 95.93023%\n",
      "Step:  1300\tLoss: 0.178\tAcc: 96.51163%\n",
      "Step:  1400\tLoss: 0.169\tAcc: 96.51163%\n",
      "Step:  1500\tLoss: 0.160\tAcc: 96.22093%\n",
      "Step:  1600\tLoss: 0.153\tAcc: 96.22093%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9622093\n",
      "Test Prediction = 0.8521739\n",
      "=========== RUN 84=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 1.691\tAcc: 55.81396%\n",
      "Step:   100\tLoss: 0.715\tAcc: 75.00000%\n",
      "Step:   200\tLoss: 0.511\tAcc: 80.81396%\n",
      "Step:   300\tLoss: 0.410\tAcc: 85.46512%\n",
      "Step:   400\tLoss: 0.344\tAcc: 89.24419%\n",
      "Step:   500\tLoss: 0.294\tAcc: 91.86047%\n",
      "Step:   600\tLoss: 0.255\tAcc: 93.02326%\n",
      "Step:   700\tLoss: 0.228\tAcc: 94.47674%\n",
      "Step:   800\tLoss: 0.207\tAcc: 94.47674%\n",
      "Step:   900\tLoss: 0.190\tAcc: 94.76744%\n",
      "Step:  1000\tLoss: 0.176\tAcc: 95.05814%\n",
      "Step:  1100\tLoss: 0.164\tAcc: 95.34883%\n",
      "Step:  1200\tLoss: 0.153\tAcc: 95.63953%\n",
      "Step:  1300\tLoss: 0.143\tAcc: 96.51163%\n",
      "Step:  1400\tLoss: 0.135\tAcc: 97.09302%\n",
      "Step:  1500\tLoss: 0.127\tAcc: 97.38372%\n",
      "Step:  1600\tLoss: 0.121\tAcc: 97.38372%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9738372\n",
      "Test Prediction = 0.83913046\n",
      "=========== RUN 85=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 1.685\tAcc: 55.81396%\n",
      "Step:   100\tLoss: 0.773\tAcc: 74.41860%\n",
      "Step:   200\tLoss: 0.584\tAcc: 81.10465%\n",
      "Step:   300\tLoss: 0.462\tAcc: 83.72093%\n",
      "Step:   400\tLoss: 0.391\tAcc: 89.24419%\n",
      "Step:   500\tLoss: 0.338\tAcc: 90.40698%\n",
      "Step:   600\tLoss: 0.297\tAcc: 91.56977%\n",
      "Step:   700\tLoss: 0.265\tAcc: 92.15117%\n",
      "Step:   800\tLoss: 0.238\tAcc: 92.44186%\n",
      "Step:   900\tLoss: 0.215\tAcc: 94.18604%\n",
      "Step:  1000\tLoss: 0.194\tAcc: 94.76744%\n",
      "Step:  1100\tLoss: 0.177\tAcc: 96.51163%\n",
      "Step:  1200\tLoss: 0.162\tAcc: 97.09302%\n",
      "Step:  1300\tLoss: 0.149\tAcc: 97.38372%\n",
      "Step:  1400\tLoss: 0.138\tAcc: 97.67442%\n",
      "Step:  1500\tLoss: 0.129\tAcc: 97.96512%\n",
      "Step:  1600\tLoss: 0.121\tAcc: 98.25581%\n",
      "Step:  1700\tLoss: 0.115\tAcc: 98.25581%\n",
      "Step:  1800\tLoss: 0.108\tAcc: 98.25581%\n",
      "Step:  1900\tLoss: 0.102\tAcc: 98.54651%\n",
      "Step:  2000\tLoss: 0.097\tAcc: 98.54651%\n",
      "Step:  2100\tLoss: 0.092\tAcc: 98.54651%\n",
      "Step:  2200\tLoss: 0.087\tAcc: 98.54651%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9854651\n",
      "Test Prediction = 0.9173913\n",
      "=========== RUN 86=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 4.207\tAcc: 47.09302%\n",
      "Step:   100\tLoss: 0.574\tAcc: 77.32558%\n",
      "Step:   200\tLoss: 0.419\tAcc: 86.33721%\n",
      "Step:   300\tLoss: 0.348\tAcc: 88.66279%\n",
      "Step:   400\tLoss: 0.298\tAcc: 89.24419%\n",
      "Step:   500\tLoss: 0.262\tAcc: 90.69768%\n",
      "Step:   600\tLoss: 0.232\tAcc: 92.44186%\n",
      "Step:   700\tLoss: 0.208\tAcc: 93.60465%\n",
      "Step:   800\tLoss: 0.188\tAcc: 95.05814%\n",
      "Step:   900\tLoss: 0.172\tAcc: 96.51163%\n",
      "Step:  1000\tLoss: 0.159\tAcc: 96.80232%\n",
      "Step:  1100\tLoss: 0.149\tAcc: 97.09302%\n",
      "Step:  1200\tLoss: 0.141\tAcc: 97.38372%\n",
      "Step:  1300\tLoss: 0.133\tAcc: 97.38372%\n",
      "Step:  1400\tLoss: 0.127\tAcc: 98.25581%\n",
      "Step:  1500\tLoss: 0.121\tAcc: 98.25581%\n",
      "Step:  1600\tLoss: 0.116\tAcc: 98.25581%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.98255813\n",
      "Test Prediction = 0.8565217\n",
      "=========== RUN 87=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 14.048\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 6.317\tAcc: 47.67442%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.4622093\n",
      "Test Prediction = 0.49565217\n",
      "=========== RUN 88=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 1.143\tAcc: 68.31396%\n",
      "Step:   100\tLoss: 0.613\tAcc: 79.65117%\n",
      "Step:   200\tLoss: 0.483\tAcc: 84.59302%\n",
      "Step:   300\tLoss: 0.417\tAcc: 88.95349%\n",
      "Step:   400\tLoss: 0.372\tAcc: 90.11628%\n",
      "Step:   500\tLoss: 0.338\tAcc: 90.98837%\n",
      "Step:   600\tLoss: 0.309\tAcc: 91.86047%\n",
      "Step:   700\tLoss: 0.282\tAcc: 92.44186%\n",
      "Step:   800\tLoss: 0.260\tAcc: 93.89535%\n",
      "Step:   900\tLoss: 0.242\tAcc: 94.18604%\n",
      "Step:  1000\tLoss: 0.227\tAcc: 94.18604%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.94186044\n",
      "Test Prediction = 0.84782606\n",
      "=========== RUN 89=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 6.326\tAcc: 52.32558%\n",
      "Step:   100\tLoss: 0.973\tAcc: 66.86047%\n",
      "Step:   200\tLoss: 0.550\tAcc: 85.17442%\n",
      "Step:   300\tLoss: 0.431\tAcc: 88.08140%\n",
      "Step:   400\tLoss: 0.370\tAcc: 91.86047%\n",
      "Step:   500\tLoss: 0.333\tAcc: 92.15117%\n",
      "Step:   600\tLoss: 0.308\tAcc: 93.02326%\n",
      "Step:   700\tLoss: 0.287\tAcc: 93.02326%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9302326\n",
      "Test Prediction = 0.79565215\n",
      "=========== RUN 90=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 2.317\tAcc: 50.58140%\n",
      "Step:   100\tLoss: 1.069\tAcc: 65.98837%\n",
      "Step:   200\tLoss: 0.724\tAcc: 75.29070%\n",
      "Step:   300\tLoss: 0.569\tAcc: 79.65117%\n",
      "Step:   400\tLoss: 0.465\tAcc: 81.39535%\n",
      "Step:   500\tLoss: 0.396\tAcc: 83.72093%\n",
      "Step:   600\tLoss: 0.351\tAcc: 87.50000%\n",
      "Step:   700\tLoss: 0.314\tAcc: 89.53488%\n",
      "Step:   800\tLoss: 0.288\tAcc: 89.82558%\n",
      "Step:   900\tLoss: 0.267\tAcc: 92.15117%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  1000\tLoss: 0.250\tAcc: 92.73256%\n",
      "Step:  1100\tLoss: 0.235\tAcc: 93.02326%\n",
      "Step:  1200\tLoss: 0.223\tAcc: 93.02326%\n",
      "Step:  1300\tLoss: 0.212\tAcc: 93.31396%\n",
      "Step:  1400\tLoss: 0.203\tAcc: 93.31396%\n",
      "Step:  1500\tLoss: 0.194\tAcc: 93.60465%\n",
      "Step:  1600\tLoss: 0.186\tAcc: 93.89535%\n",
      "Step:  1700\tLoss: 0.178\tAcc: 94.18604%\n",
      "Step:  1800\tLoss: 0.171\tAcc: 94.18604%\n",
      "Step:  1900\tLoss: 0.165\tAcc: 94.47674%\n",
      "Step:  2000\tLoss: 0.159\tAcc: 94.76744%\n",
      "Step:  2100\tLoss: 0.153\tAcc: 94.76744%\n",
      "Step:  2200\tLoss: 0.147\tAcc: 94.76744%\n",
      "Step:  2300\tLoss: 0.142\tAcc: 95.05814%\n",
      "Step:  2400\tLoss: 0.137\tAcc: 95.34883%\n",
      "Step:  2500\tLoss: 0.133\tAcc: 95.93023%\n",
      "Step:  2600\tLoss: 0.129\tAcc: 95.93023%\n",
      "Step:  2700\tLoss: 0.126\tAcc: 96.22093%\n",
      "Step:  2800\tLoss: 0.122\tAcc: 96.80232%\n",
      "Step:  2900\tLoss: 0.119\tAcc: 96.80232%\n",
      "Step:  3000\tLoss: 0.116\tAcc: 96.80232%\n",
      "Step:  3100\tLoss: 0.114\tAcc: 97.67442%\n",
      "Step:  3200\tLoss: 0.111\tAcc: 97.96512%\n",
      "Step:  3300\tLoss: 0.109\tAcc: 97.96512%\n",
      "Step:  3400\tLoss: 0.107\tAcc: 97.96512%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.97965115\n",
      "Test Prediction = 0.84782606\n",
      "=========== RUN 91=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 3.909\tAcc: 51.16279%\n",
      "Step:   100\tLoss: 0.673\tAcc: 78.19768%\n",
      "Step:   200\tLoss: 0.512\tAcc: 84.01163%\n",
      "Step:   300\tLoss: 0.421\tAcc: 89.53488%\n",
      "Step:   400\tLoss: 0.354\tAcc: 92.73256%\n",
      "Step:   500\tLoss: 0.312\tAcc: 93.02326%\n",
      "Step:   600\tLoss: 0.280\tAcc: 94.47674%\n",
      "Step:   700\tLoss: 0.253\tAcc: 95.05814%\n",
      "Step:   800\tLoss: 0.230\tAcc: 95.05814%\n",
      "Step:   900\tLoss: 0.211\tAcc: 95.34883%\n",
      "Step:  1000\tLoss: 0.195\tAcc: 95.93023%\n",
      "Step:  1100\tLoss: 0.180\tAcc: 96.22093%\n",
      "Step:  1200\tLoss: 0.167\tAcc: 97.09302%\n",
      "Step:  1300\tLoss: 0.156\tAcc: 97.09302%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9709302\n",
      "Test Prediction = 0.87826085\n",
      "=========== RUN 92=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 14.360\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 5.760\tAcc: 48.25581%\n",
      "Step:   200\tLoss: 1.717\tAcc: 57.84883%\n",
      "Step:   300\tLoss: 0.988\tAcc: 71.51163%\n",
      "Step:   400\tLoss: 0.715\tAcc: 76.74419%\n",
      "Step:   500\tLoss: 0.540\tAcc: 83.13953%\n",
      "Step:   600\tLoss: 0.428\tAcc: 85.17442%\n",
      "Step:   700\tLoss: 0.365\tAcc: 88.95349%\n",
      "Step:   800\tLoss: 0.323\tAcc: 90.69768%\n",
      "Step:   900\tLoss: 0.291\tAcc: 92.73256%\n",
      "Step:  1000\tLoss: 0.266\tAcc: 92.73256%\n",
      "Step:  1100\tLoss: 0.244\tAcc: 93.60465%\n",
      "Step:  1200\tLoss: 0.226\tAcc: 94.47674%\n",
      "Step:  1300\tLoss: 0.210\tAcc: 95.05814%\n",
      "Step:  1400\tLoss: 0.197\tAcc: 95.63953%\n",
      "Step:  1500\tLoss: 0.184\tAcc: 96.51163%\n",
      "Step:  1600\tLoss: 0.174\tAcc: 96.51163%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.96511626\n",
      "Test Prediction = 0.84347826\n",
      "=========== RUN 93=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 14.510\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 7.088\tAcc: 47.67442%\n",
      "Step:   200\tLoss: 2.548\tAcc: 50.58140%\n",
      "Step:   300\tLoss: 1.453\tAcc: 66.27907%\n",
      "Step:   400\tLoss: 0.963\tAcc: 70.93023%\n",
      "Step:   500\tLoss: 0.737\tAcc: 77.61628%\n",
      "Step:   600\tLoss: 0.598\tAcc: 80.23256%\n",
      "Step:   700\tLoss: 0.497\tAcc: 81.68604%\n",
      "Step:   800\tLoss: 0.429\tAcc: 84.30232%\n",
      "Step:   900\tLoss: 0.374\tAcc: 85.46512%\n",
      "Step:  1000\tLoss: 0.328\tAcc: 86.91860%\n",
      "Step:  1100\tLoss: 0.288\tAcc: 91.56977%\n",
      "Step:  1200\tLoss: 0.257\tAcc: 92.44186%\n",
      "Step:  1300\tLoss: 0.234\tAcc: 93.02326%\n",
      "Step:  1400\tLoss: 0.215\tAcc: 94.76744%\n",
      "Step:  1500\tLoss: 0.199\tAcc: 95.05814%\n",
      "Step:  1600\tLoss: 0.186\tAcc: 95.63953%\n",
      "Step:  1700\tLoss: 0.175\tAcc: 95.93023%\n",
      "Step:  1800\tLoss: 0.166\tAcc: 96.22093%\n",
      "Step:  1900\tLoss: 0.158\tAcc: 96.80232%\n",
      "Step:  2000\tLoss: 0.150\tAcc: 97.09302%\n",
      "Step:  2100\tLoss: 0.143\tAcc: 97.38372%\n",
      "Step:  2200\tLoss: 0.138\tAcc: 97.67442%\n",
      "Step:  2300\tLoss: 0.132\tAcc: 97.67442%\n",
      "Step:  2400\tLoss: 0.127\tAcc: 97.96512%\n",
      "Step:  2500\tLoss: 0.123\tAcc: 97.96512%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.97965115\n",
      "Test Prediction = 0.82173914\n",
      "=========== RUN 94=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 10.579\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 3.846\tAcc: 53.48837%\n",
      "Step:   200\tLoss: 1.707\tAcc: 56.68604%\n",
      "Step:   300\tLoss: 1.041\tAcc: 65.98837%\n",
      "Step:   400\tLoss: 0.754\tAcc: 72.96512%\n",
      "Step:   500\tLoss: 0.597\tAcc: 77.61628%\n",
      "Step:   600\tLoss: 0.488\tAcc: 85.75581%\n",
      "Step:   700\tLoss: 0.410\tAcc: 89.24419%\n",
      "Step:   800\tLoss: 0.360\tAcc: 90.11628%\n",
      "Step:   900\tLoss: 0.325\tAcc: 90.11628%\n",
      "Step:  1000\tLoss: 0.297\tAcc: 92.44186%\n",
      "Step:  1100\tLoss: 0.275\tAcc: 92.15117%\n",
      "Step:  1200\tLoss: 0.256\tAcc: 93.89535%\n",
      "Step:  1300\tLoss: 0.239\tAcc: 94.47674%\n",
      "Step:  1400\tLoss: 0.225\tAcc: 95.34883%\n",
      "Step:  1500\tLoss: 0.212\tAcc: 96.22093%\n",
      "Step:  1600\tLoss: 0.201\tAcc: 96.51163%\n",
      "Step:  1700\tLoss: 0.191\tAcc: 96.80232%\n",
      "Step:  1800\tLoss: 0.181\tAcc: 97.38372%\n",
      "Step:  1900\tLoss: 0.173\tAcc: 97.38372%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9738372\n",
      "Test Prediction = 0.82608694\n",
      "=========== RUN 95=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 2.036\tAcc: 52.03488%\n",
      "Step:   100\tLoss: 0.498\tAcc: 83.13953%\n",
      "Step:   200\tLoss: 0.368\tAcc: 88.37209%\n",
      "Step:   300\tLoss: 0.306\tAcc: 91.27907%\n",
      "Step:   400\tLoss: 0.266\tAcc: 92.44186%\n",
      "Step:   500\tLoss: 0.234\tAcc: 94.18604%\n",
      "Step:   600\tLoss: 0.209\tAcc: 95.34883%\n",
      "Step:   700\tLoss: 0.189\tAcc: 95.63953%\n",
      "Step:   800\tLoss: 0.173\tAcc: 95.63953%\n",
      "Step:   900\tLoss: 0.159\tAcc: 95.63953%\n",
      "Step:  1000\tLoss: 0.146\tAcc: 95.63953%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9563953\n",
      "Test Prediction = 0.83913046\n",
      "=========== RUN 96=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 3.818\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 1.481\tAcc: 68.60465%\n",
      "Step:   200\tLoss: 0.942\tAcc: 74.70930%\n",
      "Step:   300\tLoss: 0.691\tAcc: 79.65117%\n",
      "Step:   400\tLoss: 0.552\tAcc: 85.17442%\n",
      "Step:   500\tLoss: 0.462\tAcc: 89.24419%\n",
      "Step:   600\tLoss: 0.399\tAcc: 89.82558%\n",
      "Step:   700\tLoss: 0.357\tAcc: 92.15117%\n",
      "Step:   800\tLoss: 0.326\tAcc: 92.44186%\n",
      "Step:   900\tLoss: 0.300\tAcc: 94.47674%\n",
      "Step:  1000\tLoss: 0.278\tAcc: 94.76744%\n",
      "Step:  1100\tLoss: 0.259\tAcc: 95.05814%\n",
      "Step:  1200\tLoss: 0.240\tAcc: 95.05814%\n",
      "Step:  1300\tLoss: 0.224\tAcc: 95.34883%\n",
      "Step:  1400\tLoss: 0.209\tAcc: 95.34883%\n",
      "Step:  1500\tLoss: 0.196\tAcc: 95.34883%\n",
      "Step:  1600\tLoss: 0.184\tAcc: 95.63953%\n",
      "Step:  1700\tLoss: 0.173\tAcc: 96.22093%\n",
      "Step:  1800\tLoss: 0.162\tAcc: 96.22093%\n",
      "Step:  1900\tLoss: 0.152\tAcc: 96.22093%\n",
      "Step:  2000\tLoss: 0.143\tAcc: 96.51163%\n",
      "Step:  2100\tLoss: 0.134\tAcc: 96.51163%\n",
      "Step:  2200\tLoss: 0.126\tAcc: 96.51163%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.96511626\n",
      "Test Prediction = 0.84347826\n",
      "=========== RUN 97=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 2.844\tAcc: 49.41860%\n",
      "Step:   100\tLoss: 0.608\tAcc: 78.77907%\n",
      "Step:   200\tLoss: 0.458\tAcc: 82.84883%\n",
      "Step:   300\tLoss: 0.379\tAcc: 87.79070%\n",
      "Step:   400\tLoss: 0.325\tAcc: 89.24419%\n",
      "Step:   500\tLoss: 0.288\tAcc: 90.11628%\n",
      "Step:   600\tLoss: 0.259\tAcc: 91.27907%\n",
      "Step:   700\tLoss: 0.236\tAcc: 94.47674%\n",
      "Step:   800\tLoss: 0.219\tAcc: 95.34883%\n",
      "Step:   900\tLoss: 0.204\tAcc: 95.63953%\n",
      "Step:  1000\tLoss: 0.190\tAcc: 96.51163%\n",
      "Step:  1100\tLoss: 0.179\tAcc: 96.80232%\n",
      "Step:  1200\tLoss: 0.168\tAcc: 96.80232%\n",
      "Step:  1300\tLoss: 0.160\tAcc: 96.80232%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.96802324\n",
      "Test Prediction = 0.8652174\n",
      "=========== RUN 98=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 3.046\tAcc: 46.22093%\n",
      "Step:   100\tLoss: 1.153\tAcc: 61.33721%\n",
      "Step:   200\tLoss: 0.720\tAcc: 72.67442%\n",
      "Step:   300\tLoss: 0.526\tAcc: 80.23256%\n",
      "Step:   400\tLoss: 0.415\tAcc: 84.59302%\n",
      "Step:   500\tLoss: 0.350\tAcc: 87.20930%\n",
      "Step:   600\tLoss: 0.304\tAcc: 87.79070%\n",
      "Step:   700\tLoss: 0.269\tAcc: 90.98837%\n",
      "Step:   800\tLoss: 0.243\tAcc: 91.86047%\n",
      "Step:   900\tLoss: 0.222\tAcc: 92.44186%\n",
      "Step:  1000\tLoss: 0.205\tAcc: 93.89535%\n",
      "Step:  1100\tLoss: 0.191\tAcc: 94.47674%\n",
      "Step:  1200\tLoss: 0.179\tAcc: 95.34883%\n",
      "Step:  1300\tLoss: 0.168\tAcc: 96.22093%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  1400\tLoss: 0.159\tAcc: 96.51163%\n",
      "Step:  1500\tLoss: 0.151\tAcc: 97.38372%\n",
      "Step:  1600\tLoss: 0.145\tAcc: 97.38372%\n",
      "Step:  1700\tLoss: 0.138\tAcc: 97.96512%\n",
      "Step:  1800\tLoss: 0.133\tAcc: 98.54651%\n",
      "Step:  1900\tLoss: 0.128\tAcc: 98.83721%\n",
      "Step:  2000\tLoss: 0.123\tAcc: 98.83721%\n",
      "Step:  2100\tLoss: 0.120\tAcc: 98.83721%\n",
      "Step:  2200\tLoss: 0.116\tAcc: 98.83721%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9883721\n",
      "Test Prediction = 0.84782606\n",
      "=========== RUN 99=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 3.851\tAcc: 52.03488%\n",
      "Step:   100\tLoss: 0.634\tAcc: 81.68604%\n",
      "Step:   200\tLoss: 0.350\tAcc: 88.95349%\n",
      "Step:   300\tLoss: 0.265\tAcc: 93.02326%\n",
      "Step:   400\tLoss: 0.221\tAcc: 94.47674%\n",
      "Step:   500\tLoss: 0.195\tAcc: 95.63953%\n",
      "Step:   600\tLoss: 0.178\tAcc: 97.38372%\n",
      "Step:   700\tLoss: 0.163\tAcc: 97.38372%\n",
      "Step:   800\tLoss: 0.151\tAcc: 97.67442%\n",
      "Step:   900\tLoss: 0.141\tAcc: 97.67442%\n",
      "Step:  1000\tLoss: 0.131\tAcc: 97.67442%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9767442\n",
      "Test Prediction = 0.9\n",
      "=========== RUN 100=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 19.991\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 11.859\tAcc: 47.67442%\n",
      "Step:   200\tLoss: 5.124\tAcc: 48.25581%\n",
      "Step:   300\tLoss: 2.344\tAcc: 44.76744%\n",
      "Step:   400\tLoss: 1.480\tAcc: 54.06977%\n",
      "Step:   500\tLoss: 0.993\tAcc: 68.60465%\n",
      "Step:   600\tLoss: 0.756\tAcc: 74.41860%\n",
      "Step:   700\tLoss: 0.614\tAcc: 78.48837%\n",
      "Step:   800\tLoss: 0.524\tAcc: 81.39535%\n",
      "Step:   900\tLoss: 0.452\tAcc: 82.55814%\n",
      "Step:  1000\tLoss: 0.397\tAcc: 84.88372%\n",
      "Step:  1100\tLoss: 0.354\tAcc: 86.91860%\n",
      "Step:  1200\tLoss: 0.318\tAcc: 88.08140%\n",
      "Step:  1300\tLoss: 0.288\tAcc: 89.53488%\n",
      "Step:  1400\tLoss: 0.265\tAcc: 90.40698%\n",
      "Step:  1500\tLoss: 0.245\tAcc: 92.15117%\n",
      "Step:  1600\tLoss: 0.229\tAcc: 92.73256%\n",
      "Step:  1700\tLoss: 0.215\tAcc: 93.31396%\n",
      "Step:  1800\tLoss: 0.204\tAcc: 94.47674%\n",
      "Step:  1900\tLoss: 0.194\tAcc: 94.47674%\n",
      "Step:  2000\tLoss: 0.185\tAcc: 95.05814%\n",
      "Step:  2100\tLoss: 0.177\tAcc: 95.05814%\n",
      "Step:  2200\tLoss: 0.169\tAcc: 95.34883%\n",
      "Step:  2300\tLoss: 0.162\tAcc: 95.93023%\n",
      "Step:  2400\tLoss: 0.155\tAcc: 96.22093%\n",
      "Step:  2500\tLoss: 0.149\tAcc: 97.09302%\n",
      "Step:  2600\tLoss: 0.144\tAcc: 97.38372%\n",
      "Step:  2700\tLoss: 0.140\tAcc: 97.38372%\n",
      "Step:  2800\tLoss: 0.136\tAcc: 97.38372%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9738372\n",
      "Test Prediction = 0.82608694\n",
      "=========== RUN 101=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 8.366\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 2.171\tAcc: 54.36047%\n",
      "Step:   200\tLoss: 1.206\tAcc: 67.73256%\n",
      "Step:   300\tLoss: 0.827\tAcc: 76.74419%\n",
      "Step:   400\tLoss: 0.636\tAcc: 80.23256%\n",
      "Step:   500\tLoss: 0.511\tAcc: 83.72093%\n",
      "Step:   600\tLoss: 0.425\tAcc: 85.75581%\n",
      "Step:   700\tLoss: 0.360\tAcc: 89.82558%\n",
      "Step:   800\tLoss: 0.307\tAcc: 91.27907%\n",
      "Step:   900\tLoss: 0.263\tAcc: 92.15117%\n",
      "Step:  1000\tLoss: 0.231\tAcc: 93.60465%\n",
      "Step:  1100\tLoss: 0.209\tAcc: 94.76744%\n",
      "Step:  1200\tLoss: 0.193\tAcc: 95.34883%\n",
      "Step:  1300\tLoss: 0.180\tAcc: 95.63953%\n",
      "Step:  1400\tLoss: 0.169\tAcc: 95.93023%\n",
      "Step:  1500\tLoss: 0.160\tAcc: 96.22093%\n",
      "Step:  1600\tLoss: 0.152\tAcc: 97.09302%\n",
      "Step:  1700\tLoss: 0.144\tAcc: 97.38372%\n",
      "Step:  1800\tLoss: 0.138\tAcc: 97.38372%\n",
      "Step:  1900\tLoss: 0.132\tAcc: 97.38372%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9738372\n",
      "Test Prediction = 0.87826085\n",
      "=========== RUN 102=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 2.103\tAcc: 57.84883%\n",
      "Step:   100\tLoss: 0.808\tAcc: 72.38372%\n",
      "Step:   200\tLoss: 0.525\tAcc: 80.23256%\n",
      "Step:   300\tLoss: 0.399\tAcc: 84.59302%\n",
      "Step:   400\tLoss: 0.334\tAcc: 87.50000%\n",
      "Step:   500\tLoss: 0.293\tAcc: 89.24419%\n",
      "Step:   600\tLoss: 0.265\tAcc: 89.82558%\n",
      "Step:   700\tLoss: 0.244\tAcc: 90.69768%\n",
      "Step:   800\tLoss: 0.226\tAcc: 90.98837%\n",
      "Step:   900\tLoss: 0.212\tAcc: 92.15117%\n",
      "Step:  1000\tLoss: 0.200\tAcc: 92.73256%\n",
      "Step:  1100\tLoss: 0.190\tAcc: 93.02326%\n",
      "Step:  1200\tLoss: 0.182\tAcc: 93.60465%\n",
      "Step:  1300\tLoss: 0.174\tAcc: 93.89535%\n",
      "Step:  1400\tLoss: 0.166\tAcc: 94.18604%\n",
      "Step:  1500\tLoss: 0.160\tAcc: 94.76744%\n",
      "Step:  1600\tLoss: 0.154\tAcc: 94.76744%\n",
      "Step:  1700\tLoss: 0.148\tAcc: 95.63953%\n",
      "Step:  1800\tLoss: 0.142\tAcc: 95.63953%\n",
      "Step:  1900\tLoss: 0.137\tAcc: 95.93023%\n",
      "Step:  2000\tLoss: 0.133\tAcc: 95.93023%\n",
      "Step:  2100\tLoss: 0.128\tAcc: 95.93023%\n",
      "Step:  2200\tLoss: 0.124\tAcc: 96.22093%\n",
      "Step:  2300\tLoss: 0.121\tAcc: 96.51163%\n",
      "Step:  2400\tLoss: 0.118\tAcc: 96.51163%\n",
      "Step:  2500\tLoss: 0.115\tAcc: 96.51163%\n",
      "Step:  2600\tLoss: 0.112\tAcc: 96.80232%\n",
      "Step:  2700\tLoss: 0.109\tAcc: 97.38372%\n",
      "Step:  2800\tLoss: 0.107\tAcc: 97.38372%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9738372\n",
      "Test Prediction = 0.90434784\n",
      "=========== RUN 103=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 2.359\tAcc: 44.18605%\n",
      "Step:   100\tLoss: 1.070\tAcc: 71.22093%\n",
      "Step:   200\tLoss: 0.777\tAcc: 77.03488%\n",
      "Step:   300\tLoss: 0.634\tAcc: 79.36047%\n",
      "Step:   400\tLoss: 0.542\tAcc: 80.52326%\n",
      "Step:   500\tLoss: 0.475\tAcc: 83.43023%\n",
      "Step:   600\tLoss: 0.423\tAcc: 86.33721%\n",
      "Step:   700\tLoss: 0.380\tAcc: 88.08140%\n",
      "Step:   800\tLoss: 0.345\tAcc: 88.66279%\n",
      "Step:   900\tLoss: 0.316\tAcc: 89.53488%\n",
      "Step:  1000\tLoss: 0.291\tAcc: 90.11628%\n",
      "Step:  1100\tLoss: 0.268\tAcc: 91.56977%\n",
      "Step:  1200\tLoss: 0.249\tAcc: 92.15117%\n",
      "Step:  1300\tLoss: 0.231\tAcc: 92.44186%\n",
      "Step:  1400\tLoss: 0.216\tAcc: 92.44186%\n",
      "Step:  1500\tLoss: 0.203\tAcc: 93.02326%\n",
      "Step:  1600\tLoss: 0.192\tAcc: 93.89535%\n",
      "Step:  1700\tLoss: 0.183\tAcc: 94.47674%\n",
      "Step:  1800\tLoss: 0.174\tAcc: 94.47674%\n",
      "Step:  1900\tLoss: 0.167\tAcc: 94.76744%\n",
      "Step:  2000\tLoss: 0.161\tAcc: 94.76744%\n",
      "Step:  2100\tLoss: 0.155\tAcc: 95.34883%\n",
      "Step:  2200\tLoss: 0.150\tAcc: 95.93023%\n",
      "Step:  2300\tLoss: 0.144\tAcc: 95.93023%\n",
      "Step:  2400\tLoss: 0.140\tAcc: 95.93023%\n",
      "Step:  2500\tLoss: 0.135\tAcc: 96.51163%\n",
      "Step:  2600\tLoss: 0.131\tAcc: 97.38372%\n",
      "Step:  2700\tLoss: 0.127\tAcc: 97.38372%\n",
      "Step:  2800\tLoss: 0.123\tAcc: 97.67442%\n",
      "Step:  2900\tLoss: 0.120\tAcc: 97.67442%\n",
      "Step:  3000\tLoss: 0.117\tAcc: 97.67442%\n",
      "Step:  3100\tLoss: 0.114\tAcc: 98.25581%\n",
      "Step:  3200\tLoss: 0.111\tAcc: 98.25581%\n",
      "Step:  3300\tLoss: 0.109\tAcc: 98.25581%\n",
      "Step:  3400\tLoss: 0.106\tAcc: 98.54651%\n",
      "Step:  3500\tLoss: 0.104\tAcc: 98.54651%\n",
      "Step:  3600\tLoss: 0.102\tAcc: 98.54651%\n",
      "Step:  3700\tLoss: 0.100\tAcc: 98.54651%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9854651\n",
      "Test Prediction = 0.8826087\n",
      "=========== RUN 104=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 3.221\tAcc: 51.45349%\n",
      "Step:   100\tLoss: 1.094\tAcc: 65.69768%\n",
      "Step:   200\tLoss: 0.712\tAcc: 74.41860%\n",
      "Step:   300\tLoss: 0.528\tAcc: 80.81396%\n",
      "Step:   400\tLoss: 0.439\tAcc: 86.04651%\n",
      "Step:   500\tLoss: 0.384\tAcc: 88.37209%\n",
      "Step:   600\tLoss: 0.342\tAcc: 90.11628%\n",
      "Step:   700\tLoss: 0.310\tAcc: 90.11628%\n",
      "Step:   800\tLoss: 0.286\tAcc: 92.44186%\n",
      "Step:   900\tLoss: 0.265\tAcc: 92.44186%\n",
      "Step:  1000\tLoss: 0.248\tAcc: 93.02326%\n",
      "Step:  1100\tLoss: 0.234\tAcc: 93.89535%\n",
      "Step:  1200\tLoss: 0.222\tAcc: 94.18604%\n",
      "Step:  1300\tLoss: 0.212\tAcc: 95.05814%\n",
      "Step:  1400\tLoss: 0.203\tAcc: 95.34883%\n",
      "Step:  1500\tLoss: 0.195\tAcc: 95.63953%\n",
      "Step:  1600\tLoss: 0.188\tAcc: 95.93023%\n",
      "Step:  1700\tLoss: 0.182\tAcc: 96.22093%\n",
      "Step:  1800\tLoss: 0.176\tAcc: 96.51163%\n",
      "Step:  1900\tLoss: 0.171\tAcc: 96.80232%\n",
      "Step:  2000\tLoss: 0.166\tAcc: 97.09302%\n",
      "Step:  2100\tLoss: 0.162\tAcc: 97.09302%\n",
      "Step:  2200\tLoss: 0.157\tAcc: 97.09302%\n",
      "Step:  2300\tLoss: 0.153\tAcc: 97.38372%\n",
      "Step:  2400\tLoss: 0.149\tAcc: 97.38372%\n",
      "Step:  2500\tLoss: 0.145\tAcc: 97.38372%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9738372\n",
      "Test Prediction = 0.8521739\n",
      "=========== RUN 105=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 13.757\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 5.456\tAcc: 46.80233%\n",
      "Step:   200\tLoss: 2.236\tAcc: 48.54651%\n",
      "Step:   300\tLoss: 1.337\tAcc: 56.10465%\n",
      "Step:   400\tLoss: 0.975\tAcc: 66.27907%\n",
      "Step:   500\tLoss: 0.760\tAcc: 75.29070%\n",
      "Step:   600\tLoss: 0.619\tAcc: 80.81396%\n",
      "Step:   700\tLoss: 0.528\tAcc: 82.55814%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:   800\tLoss: 0.462\tAcc: 86.04651%\n",
      "Step:   900\tLoss: 0.410\tAcc: 86.91860%\n",
      "Step:  1000\tLoss: 0.369\tAcc: 88.66279%\n",
      "Step:  1100\tLoss: 0.334\tAcc: 88.37209%\n",
      "Step:  1200\tLoss: 0.305\tAcc: 90.11628%\n",
      "Step:  1300\tLoss: 0.283\tAcc: 90.69768%\n",
      "Step:  1400\tLoss: 0.266\tAcc: 91.56977%\n",
      "Step:  1500\tLoss: 0.252\tAcc: 92.73256%\n",
      "Step:  1600\tLoss: 0.238\tAcc: 94.18604%\n",
      "Step:  1700\tLoss: 0.228\tAcc: 94.18604%\n",
      "Step:  1800\tLoss: 0.217\tAcc: 94.47674%\n",
      "Step:  1900\tLoss: 0.209\tAcc: 94.47674%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9447674\n",
      "Test Prediction = 0.8304348\n",
      "=========== RUN 106=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 3.008\tAcc: 46.80233%\n",
      "Step:   100\tLoss: 1.195\tAcc: 67.15117%\n",
      "Step:   200\tLoss: 0.824\tAcc: 72.96512%\n",
      "Step:   300\tLoss: 0.623\tAcc: 79.94186%\n",
      "Step:   400\tLoss: 0.489\tAcc: 83.72093%\n",
      "Step:   500\tLoss: 0.398\tAcc: 86.91860%\n",
      "Step:   600\tLoss: 0.339\tAcc: 90.11628%\n",
      "Step:   700\tLoss: 0.301\tAcc: 90.98837%\n",
      "Step:   800\tLoss: 0.272\tAcc: 91.56977%\n",
      "Step:   900\tLoss: 0.247\tAcc: 92.44186%\n",
      "Step:  1000\tLoss: 0.226\tAcc: 93.60465%\n",
      "Step:  1100\tLoss: 0.208\tAcc: 93.60465%\n",
      "Step:  1200\tLoss: 0.193\tAcc: 94.18604%\n",
      "Step:  1300\tLoss: 0.180\tAcc: 94.47674%\n",
      "Step:  1400\tLoss: 0.168\tAcc: 94.76744%\n",
      "Step:  1500\tLoss: 0.158\tAcc: 96.22093%\n",
      "Step:  1600\tLoss: 0.149\tAcc: 96.80232%\n",
      "Step:  1700\tLoss: 0.141\tAcc: 96.80232%\n",
      "Step:  1800\tLoss: 0.134\tAcc: 97.38372%\n",
      "Step:  1900\tLoss: 0.127\tAcc: 97.38372%\n",
      "Step:  2000\tLoss: 0.121\tAcc: 97.67442%\n",
      "Step:  2100\tLoss: 0.116\tAcc: 97.67442%\n",
      "Step:  2200\tLoss: 0.111\tAcc: 97.67442%\n",
      "Step:  2300\tLoss: 0.107\tAcc: 97.96512%\n",
      "Step:  2400\tLoss: 0.104\tAcc: 97.96512%\n",
      "Step:  2500\tLoss: 0.100\tAcc: 97.96512%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.97965115\n",
      "Test Prediction = 0.8565217\n",
      "=========== RUN 107=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 1.859\tAcc: 57.84883%\n",
      "Step:   100\tLoss: 0.793\tAcc: 73.83721%\n",
      "Step:   200\tLoss: 0.573\tAcc: 80.52326%\n",
      "Step:   300\tLoss: 0.460\tAcc: 86.33721%\n",
      "Step:   400\tLoss: 0.389\tAcc: 88.66279%\n",
      "Step:   500\tLoss: 0.338\tAcc: 91.56977%\n",
      "Step:   600\tLoss: 0.302\tAcc: 92.15117%\n",
      "Step:   700\tLoss: 0.275\tAcc: 92.73256%\n",
      "Step:   800\tLoss: 0.254\tAcc: 92.73256%\n",
      "Step:   900\tLoss: 0.235\tAcc: 93.02326%\n",
      "Step:  1000\tLoss: 0.219\tAcc: 93.60465%\n",
      "Step:  1100\tLoss: 0.205\tAcc: 95.05814%\n",
      "Step:  1200\tLoss: 0.192\tAcc: 95.34883%\n",
      "Step:  1300\tLoss: 0.180\tAcc: 95.34883%\n",
      "Step:  1400\tLoss: 0.169\tAcc: 95.93023%\n",
      "Step:  1500\tLoss: 0.159\tAcc: 96.22093%\n",
      "Step:  1600\tLoss: 0.150\tAcc: 96.51163%\n",
      "Step:  1700\tLoss: 0.141\tAcc: 96.80232%\n",
      "Step:  1800\tLoss: 0.133\tAcc: 97.09302%\n",
      "Step:  1900\tLoss: 0.127\tAcc: 97.09302%\n",
      "Step:  2000\tLoss: 0.121\tAcc: 97.38372%\n",
      "Step:  2100\tLoss: 0.115\tAcc: 97.38372%\n",
      "Step:  2200\tLoss: 0.111\tAcc: 97.38372%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9738372\n",
      "Test Prediction = 0.87826085\n",
      "=========== RUN 108=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 13.846\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 5.511\tAcc: 47.96512%\n",
      "Step:   200\tLoss: 2.421\tAcc: 51.74419%\n",
      "Step:   300\tLoss: 1.403\tAcc: 63.08140%\n",
      "Step:   400\tLoss: 0.909\tAcc: 75.58140%\n",
      "Step:   500\tLoss: 0.638\tAcc: 78.77907%\n",
      "Step:   600\tLoss: 0.485\tAcc: 84.88372%\n",
      "Step:   700\tLoss: 0.390\tAcc: 89.82558%\n",
      "Step:   800\tLoss: 0.328\tAcc: 91.27907%\n",
      "Step:   900\tLoss: 0.287\tAcc: 92.73256%\n",
      "Step:  1000\tLoss: 0.256\tAcc: 94.47674%\n",
      "Step:  1100\tLoss: 0.230\tAcc: 96.22093%\n",
      "Step:  1200\tLoss: 0.210\tAcc: 96.51163%\n",
      "Step:  1300\tLoss: 0.193\tAcc: 97.67442%\n",
      "Step:  1400\tLoss: 0.178\tAcc: 97.67442%\n",
      "Step:  1500\tLoss: 0.165\tAcc: 97.67442%\n",
      "Step:  1600\tLoss: 0.153\tAcc: 97.67442%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9767442\n",
      "Test Prediction = 0.8086957\n",
      "=========== RUN 109=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 10.146\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 3.100\tAcc: 50.87209%\n",
      "Step:   200\tLoss: 1.177\tAcc: 64.24419%\n",
      "Step:   300\tLoss: 0.692\tAcc: 77.03488%\n",
      "Step:   400\tLoss: 0.505\tAcc: 81.39535%\n",
      "Step:   500\tLoss: 0.397\tAcc: 84.01163%\n",
      "Step:   600\tLoss: 0.328\tAcc: 87.20930%\n",
      "Step:   700\tLoss: 0.282\tAcc: 89.24419%\n",
      "Step:   800\tLoss: 0.249\tAcc: 90.98837%\n",
      "Step:   900\tLoss: 0.222\tAcc: 92.44186%\n",
      "Step:  1000\tLoss: 0.204\tAcc: 93.31396%\n",
      "Step:  1100\tLoss: 0.189\tAcc: 93.89535%\n",
      "Step:  1200\tLoss: 0.177\tAcc: 94.18604%\n",
      "Step:  1300\tLoss: 0.167\tAcc: 94.47674%\n",
      "Step:  1400\tLoss: 0.159\tAcc: 95.05814%\n",
      "Step:  1500\tLoss: 0.152\tAcc: 95.63953%\n",
      "Step:  1600\tLoss: 0.145\tAcc: 95.93023%\n",
      "Step:  1700\tLoss: 0.140\tAcc: 96.51163%\n",
      "Step:  1800\tLoss: 0.135\tAcc: 96.51163%\n",
      "Step:  1900\tLoss: 0.131\tAcc: 96.51163%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.96511626\n",
      "Test Prediction = 0.8652174\n",
      "=========== RUN 110=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 11.706\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 3.287\tAcc: 51.45349%\n",
      "Step:   200\tLoss: 1.421\tAcc: 66.56977%\n",
      "Step:   300\tLoss: 0.957\tAcc: 74.70930%\n",
      "Step:   400\tLoss: 0.680\tAcc: 81.10465%\n",
      "Step:   500\tLoss: 0.519\tAcc: 84.30232%\n",
      "Step:   600\tLoss: 0.421\tAcc: 86.91860%\n",
      "Step:   700\tLoss: 0.358\tAcc: 88.66279%\n",
      "Step:   800\tLoss: 0.315\tAcc: 90.98837%\n",
      "Step:   900\tLoss: 0.282\tAcc: 90.98837%\n",
      "Step:  1000\tLoss: 0.256\tAcc: 91.27907%\n",
      "Step:  1100\tLoss: 0.236\tAcc: 93.02326%\n",
      "Step:  1200\tLoss: 0.220\tAcc: 93.89535%\n",
      "Step:  1300\tLoss: 0.206\tAcc: 94.18604%\n",
      "Step:  1400\tLoss: 0.194\tAcc: 94.47674%\n",
      "Step:  1500\tLoss: 0.184\tAcc: 94.47674%\n",
      "Step:  1600\tLoss: 0.174\tAcc: 95.05814%\n",
      "Step:  1700\tLoss: 0.166\tAcc: 95.05814%\n",
      "Step:  1800\tLoss: 0.157\tAcc: 95.05814%\n",
      "Step:  1900\tLoss: 0.150\tAcc: 95.05814%\n",
      "Step:  2000\tLoss: 0.144\tAcc: 95.34883%\n",
      "Step:  2100\tLoss: 0.137\tAcc: 95.34883%\n",
      "Step:  2200\tLoss: 0.131\tAcc: 95.34883%\n",
      "Step:  2300\tLoss: 0.126\tAcc: 95.63953%\n",
      "Step:  2400\tLoss: 0.121\tAcc: 95.93023%\n",
      "Step:  2500\tLoss: 0.117\tAcc: 96.22093%\n",
      "Step:  2600\tLoss: 0.112\tAcc: 96.51163%\n",
      "Step:  2700\tLoss: 0.109\tAcc: 96.80232%\n",
      "Step:  2800\tLoss: 0.105\tAcc: 97.09302%\n",
      "Step:  2900\tLoss: 0.102\tAcc: 97.38372%\n",
      "Step:  3000\tLoss: 0.099\tAcc: 97.67442%\n",
      "Step:  3100\tLoss: 0.096\tAcc: 98.54651%\n",
      "Step:  3200\tLoss: 0.093\tAcc: 98.54651%\n",
      "Step:  3300\tLoss: 0.090\tAcc: 98.54651%\n",
      "Step:  3400\tLoss: 0.088\tAcc: 98.54651%\n",
      "Step:  3500\tLoss: 0.085\tAcc: 98.83721%\n",
      "Step:  3600\tLoss: 0.082\tAcc: 99.41860%\n",
      "Step:  3700\tLoss: 0.080\tAcc: 99.41860%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.99418604\n",
      "Test Prediction = 0.8521739\n",
      "=========== RUN 111=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 10.101\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 3.547\tAcc: 45.34884%\n",
      "Step:   200\tLoss: 1.466\tAcc: 52.90698%\n",
      "Step:   300\tLoss: 0.957\tAcc: 70.34883%\n",
      "Step:   400\tLoss: 0.752\tAcc: 78.19768%\n",
      "Step:   500\tLoss: 0.618\tAcc: 81.68604%\n",
      "Step:   600\tLoss: 0.522\tAcc: 83.72093%\n",
      "Step:   700\tLoss: 0.449\tAcc: 86.04651%\n",
      "Step:   800\tLoss: 0.396\tAcc: 86.04651%\n",
      "Step:   900\tLoss: 0.353\tAcc: 87.50000%\n",
      "Step:  1000\tLoss: 0.320\tAcc: 89.53488%\n",
      "Step:  1100\tLoss: 0.295\tAcc: 89.82558%\n",
      "Step:  1200\tLoss: 0.270\tAcc: 91.27907%\n",
      "Step:  1300\tLoss: 0.252\tAcc: 93.31396%\n",
      "Step:  1400\tLoss: 0.236\tAcc: 93.60465%\n",
      "Step:  1500\tLoss: 0.223\tAcc: 93.60465%\n",
      "Step:  1600\tLoss: 0.212\tAcc: 93.89535%\n",
      "Step:  1700\tLoss: 0.201\tAcc: 93.89535%\n",
      "Step:  1800\tLoss: 0.192\tAcc: 94.18604%\n",
      "Step:  1900\tLoss: 0.184\tAcc: 94.76744%\n",
      "Step:  2000\tLoss: 0.176\tAcc: 95.05814%\n",
      "Step:  2100\tLoss: 0.169\tAcc: 95.05814%\n",
      "Step:  2200\tLoss: 0.162\tAcc: 95.63953%\n",
      "Step:  2300\tLoss: 0.155\tAcc: 96.22093%\n",
      "Step:  2400\tLoss: 0.150\tAcc: 96.22093%\n",
      "Step:  2500\tLoss: 0.144\tAcc: 96.22093%\n",
      "Step:  2600\tLoss: 0.139\tAcc: 96.80232%\n",
      "Step:  2700\tLoss: 0.134\tAcc: 96.80232%\n",
      "Step:  2800\tLoss: 0.130\tAcc: 96.80232%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.96802324\n",
      "Test Prediction = 0.87826085\n",
      "=========== RUN 112=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 4.588\tAcc: 48.83721%\n",
      "Step:   100\tLoss: 1.426\tAcc: 59.01163%\n",
      "Step:   200\tLoss: 0.859\tAcc: 68.60465%\n",
      "Step:   300\tLoss: 0.622\tAcc: 75.29070%\n",
      "Step:   400\tLoss: 0.500\tAcc: 80.81396%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:   500\tLoss: 0.423\tAcc: 83.72093%\n",
      "Step:   600\tLoss: 0.369\tAcc: 85.46512%\n",
      "Step:   700\tLoss: 0.329\tAcc: 89.53488%\n",
      "Step:   800\tLoss: 0.297\tAcc: 90.69768%\n",
      "Step:   900\tLoss: 0.271\tAcc: 93.31396%\n",
      "Step:  1000\tLoss: 0.248\tAcc: 93.89535%\n",
      "Step:  1100\tLoss: 0.229\tAcc: 95.05814%\n",
      "Step:  1200\tLoss: 0.213\tAcc: 95.93023%\n",
      "Step:  1300\tLoss: 0.200\tAcc: 96.51163%\n",
      "Step:  1400\tLoss: 0.187\tAcc: 96.51163%\n",
      "Step:  1500\tLoss: 0.176\tAcc: 96.51163%\n",
      "Step:  1600\tLoss: 0.166\tAcc: 96.51163%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.96511626\n",
      "Test Prediction = 0.8173913\n",
      "=========== RUN 113=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 13.018\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 6.295\tAcc: 47.67442%\n",
      "Step:   200\tLoss: 2.405\tAcc: 54.06977%\n",
      "Step:   300\tLoss: 1.347\tAcc: 60.46512%\n",
      "Step:   400\tLoss: 1.005\tAcc: 69.18604%\n",
      "Step:   500\tLoss: 0.825\tAcc: 74.41860%\n",
      "Step:   600\tLoss: 0.702\tAcc: 80.52326%\n",
      "Step:   700\tLoss: 0.606\tAcc: 83.13953%\n",
      "Step:   800\tLoss: 0.529\tAcc: 86.62791%\n",
      "Step:   900\tLoss: 0.466\tAcc: 87.50000%\n",
      "Step:  1000\tLoss: 0.416\tAcc: 88.95349%\n",
      "Step:  1100\tLoss: 0.376\tAcc: 90.69768%\n",
      "Step:  1200\tLoss: 0.345\tAcc: 91.27907%\n",
      "Step:  1300\tLoss: 0.319\tAcc: 93.60465%\n",
      "Step:  1400\tLoss: 0.296\tAcc: 93.60465%\n",
      "Step:  1500\tLoss: 0.277\tAcc: 94.18604%\n",
      "Step:  1600\tLoss: 0.261\tAcc: 94.47674%\n",
      "Step:  1700\tLoss: 0.247\tAcc: 94.76744%\n",
      "Step:  1800\tLoss: 0.234\tAcc: 95.05814%\n",
      "Step:  1900\tLoss: 0.222\tAcc: 95.63953%\n",
      "Step:  2000\tLoss: 0.212\tAcc: 95.93023%\n",
      "Step:  2100\tLoss: 0.202\tAcc: 95.93023%\n",
      "Step:  2200\tLoss: 0.193\tAcc: 95.93023%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9593023\n",
      "Test Prediction = 0.84782606\n",
      "=========== RUN 114=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 4.661\tAcc: 50.29070%\n",
      "Step:   100\tLoss: 1.541\tAcc: 63.37209%\n",
      "Step:   200\tLoss: 1.006\tAcc: 71.80232%\n",
      "Step:   300\tLoss: 0.758\tAcc: 78.19768%\n",
      "Step:   400\tLoss: 0.615\tAcc: 80.23256%\n",
      "Step:   500\tLoss: 0.517\tAcc: 80.81396%\n",
      "Step:   600\tLoss: 0.448\tAcc: 84.59302%\n",
      "Step:   700\tLoss: 0.396\tAcc: 86.62791%\n",
      "Step:   800\tLoss: 0.357\tAcc: 87.20930%\n",
      "Step:   900\tLoss: 0.324\tAcc: 87.79070%\n",
      "Step:  1000\tLoss: 0.297\tAcc: 89.53488%\n",
      "Step:  1100\tLoss: 0.273\tAcc: 90.11628%\n",
      "Step:  1200\tLoss: 0.252\tAcc: 90.98837%\n",
      "Step:  1300\tLoss: 0.233\tAcc: 92.15117%\n",
      "Step:  1400\tLoss: 0.217\tAcc: 93.02326%\n",
      "Step:  1500\tLoss: 0.203\tAcc: 93.60465%\n",
      "Step:  1600\tLoss: 0.191\tAcc: 93.89535%\n",
      "Step:  1700\tLoss: 0.180\tAcc: 94.47674%\n",
      "Step:  1800\tLoss: 0.171\tAcc: 94.76744%\n",
      "Step:  1900\tLoss: 0.162\tAcc: 95.34883%\n",
      "Step:  2000\tLoss: 0.155\tAcc: 95.93023%\n",
      "Step:  2100\tLoss: 0.147\tAcc: 96.51163%\n",
      "Step:  2200\tLoss: 0.141\tAcc: 96.80232%\n",
      "Step:  2300\tLoss: 0.135\tAcc: 96.80232%\n",
      "Step:  2400\tLoss: 0.129\tAcc: 97.09302%\n",
      "Step:  2500\tLoss: 0.124\tAcc: 97.38372%\n",
      "Step:  2600\tLoss: 0.120\tAcc: 97.38372%\n",
      "Step:  2700\tLoss: 0.116\tAcc: 97.67442%\n",
      "Step:  2800\tLoss: 0.112\tAcc: 97.67442%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9767442\n",
      "Test Prediction = 0.8695652\n",
      "=========== RUN 115=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 16.978\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 9.948\tAcc: 47.67442%\n",
      "Step:   200\tLoss: 3.735\tAcc: 53.19768%\n",
      "Step:   300\tLoss: 1.422\tAcc: 61.62791%\n",
      "Step:   400\tLoss: 0.907\tAcc: 72.96512%\n",
      "Step:   500\tLoss: 0.674\tAcc: 81.10465%\n",
      "Step:   600\tLoss: 0.534\tAcc: 84.30232%\n",
      "Step:   700\tLoss: 0.438\tAcc: 85.75581%\n",
      "Step:   800\tLoss: 0.378\tAcc: 88.08140%\n",
      "Step:   900\tLoss: 0.334\tAcc: 89.53488%\n",
      "Step:  1000\tLoss: 0.301\tAcc: 90.40698%\n",
      "Step:  1100\tLoss: 0.275\tAcc: 91.56977%\n",
      "Step:  1200\tLoss: 0.254\tAcc: 92.15117%\n",
      "Step:  1300\tLoss: 0.236\tAcc: 92.73256%\n",
      "Step:  1400\tLoss: 0.220\tAcc: 93.60465%\n",
      "Step:  1500\tLoss: 0.206\tAcc: 93.89535%\n",
      "Step:  1600\tLoss: 0.194\tAcc: 95.63953%\n",
      "Step:  1700\tLoss: 0.184\tAcc: 95.63953%\n",
      "Step:  1800\tLoss: 0.174\tAcc: 95.63953%\n",
      "Step:  1900\tLoss: 0.166\tAcc: 95.93023%\n",
      "Step:  2000\tLoss: 0.158\tAcc: 96.51163%\n",
      "Step:  2100\tLoss: 0.150\tAcc: 97.09302%\n",
      "Step:  2200\tLoss: 0.143\tAcc: 97.09302%\n",
      "Step:  2300\tLoss: 0.137\tAcc: 97.38372%\n",
      "Step:  2400\tLoss: 0.131\tAcc: 97.96512%\n",
      "Step:  2500\tLoss: 0.126\tAcc: 97.96512%\n",
      "Step:  2600\tLoss: 0.121\tAcc: 98.25581%\n",
      "Step:  2700\tLoss: 0.117\tAcc: 98.25581%\n",
      "Step:  2800\tLoss: 0.113\tAcc: 98.25581%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.98255813\n",
      "Test Prediction = 0.84347826\n",
      "=========== RUN 116=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 3.703\tAcc: 49.12791%\n",
      "Step:   100\tLoss: 1.056\tAcc: 61.04651%\n",
      "Step:   200\tLoss: 0.655\tAcc: 75.29070%\n",
      "Step:   300\tLoss: 0.473\tAcc: 83.72093%\n",
      "Step:   400\tLoss: 0.375\tAcc: 87.50000%\n",
      "Step:   500\tLoss: 0.318\tAcc: 88.66279%\n",
      "Step:   600\tLoss: 0.277\tAcc: 90.40698%\n",
      "Step:   700\tLoss: 0.246\tAcc: 92.15117%\n",
      "Step:   800\tLoss: 0.219\tAcc: 93.02326%\n",
      "Step:   900\tLoss: 0.198\tAcc: 93.31396%\n",
      "Step:  1000\tLoss: 0.180\tAcc: 94.47674%\n",
      "Step:  1100\tLoss: 0.164\tAcc: 95.63953%\n",
      "Step:  1200\tLoss: 0.153\tAcc: 96.51163%\n",
      "Step:  1300\tLoss: 0.144\tAcc: 96.51163%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.96511626\n",
      "Test Prediction = 0.8347826\n",
      "=========== RUN 117=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 4.948\tAcc: 48.54651%\n",
      "Step:   100\tLoss: 1.188\tAcc: 63.08140%\n",
      "Step:   200\tLoss: 0.692\tAcc: 75.58140%\n",
      "Step:   300\tLoss: 0.534\tAcc: 81.39535%\n",
      "Step:   400\tLoss: 0.437\tAcc: 83.13953%\n",
      "Step:   500\tLoss: 0.366\tAcc: 85.75581%\n",
      "Step:   600\tLoss: 0.309\tAcc: 88.37209%\n",
      "Step:   700\tLoss: 0.266\tAcc: 90.11628%\n",
      "Step:   800\tLoss: 0.237\tAcc: 91.56977%\n",
      "Step:   900\tLoss: 0.213\tAcc: 94.47674%\n",
      "Step:  1000\tLoss: 0.193\tAcc: 94.76744%\n",
      "Step:  1100\tLoss: 0.178\tAcc: 96.22093%\n",
      "Step:  1200\tLoss: 0.165\tAcc: 97.09302%\n",
      "Step:  1300\tLoss: 0.154\tAcc: 97.09302%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9709302\n",
      "Test Prediction = 0.87391305\n",
      "=========== RUN 118=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 7.825\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 1.902\tAcc: 57.84883%\n",
      "Step:   200\tLoss: 0.984\tAcc: 68.60465%\n",
      "Step:   300\tLoss: 0.717\tAcc: 76.45349%\n",
      "Step:   400\tLoss: 0.573\tAcc: 80.23256%\n",
      "Step:   500\tLoss: 0.475\tAcc: 83.13953%\n",
      "Step:   600\tLoss: 0.403\tAcc: 84.88372%\n",
      "Step:   700\tLoss: 0.347\tAcc: 87.50000%\n",
      "Step:   800\tLoss: 0.306\tAcc: 89.82558%\n",
      "Step:   900\tLoss: 0.273\tAcc: 90.11628%\n",
      "Step:  1000\tLoss: 0.248\tAcc: 91.27907%\n",
      "Step:  1100\tLoss: 0.227\tAcc: 92.44186%\n",
      "Step:  1200\tLoss: 0.210\tAcc: 92.73256%\n",
      "Step:  1300\tLoss: 0.196\tAcc: 93.31396%\n",
      "Step:  1400\tLoss: 0.185\tAcc: 93.89535%\n",
      "Step:  1500\tLoss: 0.175\tAcc: 94.47674%\n",
      "Step:  1600\tLoss: 0.167\tAcc: 95.05814%\n",
      "Step:  1700\tLoss: 0.159\tAcc: 95.63953%\n",
      "Step:  1800\tLoss: 0.153\tAcc: 95.93023%\n",
      "Step:  1900\tLoss: 0.147\tAcc: 96.22093%\n",
      "Step:  2000\tLoss: 0.141\tAcc: 96.80232%\n",
      "Step:  2100\tLoss: 0.137\tAcc: 96.80232%\n",
      "Step:  2200\tLoss: 0.132\tAcc: 97.67442%\n",
      "Step:  2300\tLoss: 0.128\tAcc: 98.25581%\n",
      "Step:  2400\tLoss: 0.124\tAcc: 98.25581%\n",
      "Step:  2500\tLoss: 0.120\tAcc: 98.25581%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.98255813\n",
      "Test Prediction = 0.8913044\n",
      "=========== RUN 119=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 16.930\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 8.779\tAcc: 47.67442%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.4127907\n",
      "Test Prediction = 0.4478261\n",
      "=========== RUN 120=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 3.747\tAcc: 51.16279%\n",
      "Step:   100\tLoss: 1.073\tAcc: 72.67442%\n",
      "Step:   200\tLoss: 0.706\tAcc: 81.68604%\n",
      "Step:   300\tLoss: 0.546\tAcc: 82.26744%\n",
      "Step:   400\tLoss: 0.446\tAcc: 85.46512%\n",
      "Step:   500\tLoss: 0.378\tAcc: 87.79070%\n",
      "Step:   600\tLoss: 0.325\tAcc: 88.95349%\n",
      "Step:   700\tLoss: 0.283\tAcc: 90.69768%\n",
      "Step:   800\tLoss: 0.250\tAcc: 91.56977%\n",
      "Step:   900\tLoss: 0.224\tAcc: 92.73256%\n",
      "Step:  1000\tLoss: 0.203\tAcc: 94.18604%\n",
      "Step:  1100\tLoss: 0.186\tAcc: 94.47674%\n",
      "Step:  1200\tLoss: 0.172\tAcc: 95.34883%\n",
      "Step:  1300\tLoss: 0.159\tAcc: 95.63953%\n",
      "Step:  1400\tLoss: 0.147\tAcc: 95.63953%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  1500\tLoss: 0.138\tAcc: 96.22093%\n",
      "Step:  1600\tLoss: 0.130\tAcc: 96.80232%\n",
      "Step:  1700\tLoss: 0.122\tAcc: 97.09302%\n",
      "Step:  1800\tLoss: 0.116\tAcc: 97.09302%\n",
      "Step:  1900\tLoss: 0.110\tAcc: 97.09302%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9709302\n",
      "Test Prediction = 0.82608694\n",
      "=========== RUN 121=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 2.962\tAcc: 43.02326%\n",
      "Step:   100\tLoss: 0.702\tAcc: 76.74419%\n",
      "Step:   200\tLoss: 0.518\tAcc: 85.46512%\n",
      "Step:   300\tLoss: 0.430\tAcc: 89.82558%\n",
      "Step:   400\tLoss: 0.367\tAcc: 91.27907%\n",
      "Step:   500\tLoss: 0.323\tAcc: 91.27907%\n",
      "Step:   600\tLoss: 0.286\tAcc: 92.15117%\n",
      "Step:   700\tLoss: 0.254\tAcc: 93.60465%\n",
      "Step:   800\tLoss: 0.228\tAcc: 94.18604%\n",
      "Step:   900\tLoss: 0.205\tAcc: 95.05814%\n",
      "Step:  1000\tLoss: 0.187\tAcc: 95.63953%\n",
      "Step:  1100\tLoss: 0.172\tAcc: 96.22093%\n",
      "Step:  1200\tLoss: 0.160\tAcc: 96.80232%\n",
      "Step:  1300\tLoss: 0.148\tAcc: 96.80232%\n",
      "Step:  1400\tLoss: 0.138\tAcc: 97.38372%\n",
      "Step:  1500\tLoss: 0.129\tAcc: 97.38372%\n",
      "Step:  1600\tLoss: 0.122\tAcc: 97.67442%\n",
      "Step:  1700\tLoss: 0.116\tAcc: 97.96512%\n",
      "Step:  1800\tLoss: 0.111\tAcc: 97.96512%\n",
      "Step:  1900\tLoss: 0.106\tAcc: 97.96512%\n",
      "Step:  2000\tLoss: 0.102\tAcc: 98.25581%\n",
      "Step:  2100\tLoss: 0.099\tAcc: 98.25581%\n",
      "Step:  2200\tLoss: 0.095\tAcc: 98.54651%\n",
      "Step:  2300\tLoss: 0.092\tAcc: 98.83721%\n",
      "Step:  2400\tLoss: 0.089\tAcc: 98.83721%\n",
      "Step:  2500\tLoss: 0.087\tAcc: 98.83721%\n",
      "Step:  2600\tLoss: 0.084\tAcc: 99.12791%\n",
      "Step:  2700\tLoss: 0.082\tAcc: 99.41860%\n",
      "Step:  2800\tLoss: 0.080\tAcc: 99.41860%\n",
      "Step:  2900\tLoss: 0.078\tAcc: 99.70930%\n",
      "Step:  3000\tLoss: 0.076\tAcc: 99.70930%\n",
      "Step:  3100\tLoss: 0.075\tAcc: 99.70930%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.997093\n",
      "Test Prediction = 0.84347826\n",
      "=========== RUN 122=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 16.264\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 7.012\tAcc: 51.74419%\n",
      "Step:   200\tLoss: 2.728\tAcc: 54.36047%\n",
      "Step:   300\tLoss: 1.434\tAcc: 61.04651%\n",
      "Step:   400\tLoss: 0.999\tAcc: 69.47674%\n",
      "Step:   500\tLoss: 0.747\tAcc: 75.29070%\n",
      "Step:   600\tLoss: 0.601\tAcc: 77.03488%\n",
      "Step:   700\tLoss: 0.504\tAcc: 81.97674%\n",
      "Step:   800\tLoss: 0.438\tAcc: 84.59302%\n",
      "Step:   900\tLoss: 0.386\tAcc: 86.04651%\n",
      "Step:  1000\tLoss: 0.345\tAcc: 87.79070%\n",
      "Step:  1100\tLoss: 0.312\tAcc: 88.08140%\n",
      "Step:  1200\tLoss: 0.283\tAcc: 88.66279%\n",
      "Step:  1300\tLoss: 0.256\tAcc: 89.53488%\n",
      "Step:  1400\tLoss: 0.230\tAcc: 90.11628%\n",
      "Step:  1500\tLoss: 0.208\tAcc: 91.56977%\n",
      "Step:  1600\tLoss: 0.191\tAcc: 92.15117%\n",
      "Step:  1700\tLoss: 0.178\tAcc: 95.05814%\n",
      "Step:  1800\tLoss: 0.166\tAcc: 95.63953%\n",
      "Step:  1900\tLoss: 0.156\tAcc: 95.93023%\n",
      "Step:  2000\tLoss: 0.147\tAcc: 95.93023%\n",
      "Step:  2100\tLoss: 0.140\tAcc: 98.25581%\n",
      "Step:  2200\tLoss: 0.134\tAcc: 98.54651%\n",
      "Step:  2300\tLoss: 0.128\tAcc: 98.54651%\n",
      "Step:  2400\tLoss: 0.123\tAcc: 98.83721%\n",
      "Step:  2500\tLoss: 0.118\tAcc: 99.12791%\n",
      "Step:  2600\tLoss: 0.114\tAcc: 99.12791%\n",
      "Step:  2700\tLoss: 0.110\tAcc: 99.41860%\n",
      "Step:  2800\tLoss: 0.106\tAcc: 99.41860%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.99418604\n",
      "Test Prediction = 0.8608696\n",
      "=========== RUN 123=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 5.956\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 1.566\tAcc: 59.88372%\n",
      "Step:   200\tLoss: 0.926\tAcc: 71.80232%\n",
      "Step:   300\tLoss: 0.660\tAcc: 80.52326%\n",
      "Step:   400\tLoss: 0.513\tAcc: 84.88372%\n",
      "Step:   500\tLoss: 0.433\tAcc: 88.95349%\n",
      "Step:   600\tLoss: 0.379\tAcc: 90.40698%\n",
      "Step:   700\tLoss: 0.339\tAcc: 90.69768%\n",
      "Step:   800\tLoss: 0.306\tAcc: 93.02326%\n",
      "Step:   900\tLoss: 0.281\tAcc: 93.60465%\n",
      "Step:  1000\tLoss: 0.260\tAcc: 94.18604%\n",
      "Step:  1100\tLoss: 0.242\tAcc: 94.18604%\n",
      "Step:  1200\tLoss: 0.226\tAcc: 94.76744%\n",
      "Step:  1300\tLoss: 0.212\tAcc: 94.76744%\n",
      "Step:  1400\tLoss: 0.200\tAcc: 95.05814%\n",
      "Step:  1500\tLoss: 0.188\tAcc: 95.63953%\n",
      "Step:  1600\tLoss: 0.177\tAcc: 96.22093%\n",
      "Step:  1700\tLoss: 0.167\tAcc: 96.22093%\n",
      "Step:  1800\tLoss: 0.158\tAcc: 96.22093%\n",
      "Step:  1900\tLoss: 0.148\tAcc: 96.80232%\n",
      "Step:  2000\tLoss: 0.139\tAcc: 96.80232%\n",
      "Step:  2100\tLoss: 0.131\tAcc: 96.80232%\n",
      "Step:  2200\tLoss: 0.123\tAcc: 96.80232%\n",
      "Step:  2300\tLoss: 0.116\tAcc: 97.09302%\n",
      "Step:  2400\tLoss: 0.110\tAcc: 97.96512%\n",
      "Step:  2500\tLoss: 0.105\tAcc: 98.25581%\n",
      "Step:  2600\tLoss: 0.100\tAcc: 98.54651%\n",
      "Step:  2700\tLoss: 0.096\tAcc: 98.54651%\n",
      "Step:  2800\tLoss: 0.092\tAcc: 98.83721%\n",
      "Step:  2900\tLoss: 0.088\tAcc: 98.83721%\n",
      "Step:  3000\tLoss: 0.085\tAcc: 98.83721%\n",
      "Step:  3100\tLoss: 0.081\tAcc: 98.83721%\n",
      "Step:  3200\tLoss: 0.078\tAcc: 99.12791%\n",
      "Step:  3300\tLoss: 0.075\tAcc: 99.12791%\n",
      "Step:  3400\tLoss: 0.073\tAcc: 99.12791%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.99127907\n",
      "Test Prediction = 0.90434784\n",
      "=========== RUN 124=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 18.090\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 7.479\tAcc: 47.67442%\n",
      "Step:   200\tLoss: 3.050\tAcc: 50.00000%\n",
      "Step:   300\tLoss: 1.743\tAcc: 56.97674%\n",
      "Step:   400\tLoss: 1.152\tAcc: 65.40698%\n",
      "Step:   500\tLoss: 0.834\tAcc: 73.25581%\n",
      "Step:   600\tLoss: 0.641\tAcc: 80.52326%\n",
      "Step:   700\tLoss: 0.514\tAcc: 84.30232%\n",
      "Step:   800\tLoss: 0.433\tAcc: 85.75581%\n",
      "Step:   900\tLoss: 0.378\tAcc: 88.66279%\n",
      "Step:  1000\tLoss: 0.337\tAcc: 90.69768%\n",
      "Step:  1100\tLoss: 0.305\tAcc: 92.15117%\n",
      "Step:  1200\tLoss: 0.280\tAcc: 93.60465%\n",
      "Step:  1300\tLoss: 0.260\tAcc: 94.47674%\n",
      "Step:  1400\tLoss: 0.244\tAcc: 95.34883%\n",
      "Step:  1500\tLoss: 0.229\tAcc: 95.34883%\n",
      "Step:  1600\tLoss: 0.216\tAcc: 95.93023%\n",
      "Step:  1700\tLoss: 0.203\tAcc: 95.93023%\n",
      "Step:  1800\tLoss: 0.192\tAcc: 96.51163%\n",
      "Step:  1900\tLoss: 0.182\tAcc: 97.38372%\n",
      "Step:  2000\tLoss: 0.173\tAcc: 97.67442%\n",
      "Step:  2100\tLoss: 0.166\tAcc: 97.67442%\n",
      "Step:  2200\tLoss: 0.159\tAcc: 98.25581%\n",
      "Step:  2300\tLoss: 0.153\tAcc: 98.25581%\n",
      "Step:  2400\tLoss: 0.148\tAcc: 98.25581%\n",
      "Step:  2500\tLoss: 0.142\tAcc: 98.25581%\n",
      "Step:  2600\tLoss: 0.137\tAcc: 98.54651%\n",
      "Step:  2700\tLoss: 0.132\tAcc: 98.54651%\n",
      "Step:  2800\tLoss: 0.128\tAcc: 98.54651%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9854651\n",
      "Test Prediction = 0.84347826\n",
      "=========== RUN 125=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 7.738\tAcc: 47.96512%\n",
      "Step:   100\tLoss: 2.260\tAcc: 44.18605%\n",
      "Step:   200\tLoss: 1.160\tAcc: 63.95349%\n",
      "Step:   300\tLoss: 0.784\tAcc: 73.54651%\n",
      "Step:   400\tLoss: 0.611\tAcc: 78.48837%\n",
      "Step:   500\tLoss: 0.504\tAcc: 82.55814%\n",
      "Step:   600\tLoss: 0.431\tAcc: 85.46512%\n",
      "Step:   700\tLoss: 0.372\tAcc: 86.33721%\n",
      "Step:   800\tLoss: 0.331\tAcc: 89.24419%\n",
      "Step:   900\tLoss: 0.300\tAcc: 90.98837%\n",
      "Step:  1000\tLoss: 0.273\tAcc: 92.44186%\n",
      "Step:  1100\tLoss: 0.251\tAcc: 93.31396%\n",
      "Step:  1200\tLoss: 0.233\tAcc: 93.60465%\n",
      "Step:  1300\tLoss: 0.217\tAcc: 94.18604%\n",
      "Step:  1400\tLoss: 0.203\tAcc: 94.18604%\n",
      "Step:  1500\tLoss: 0.192\tAcc: 94.47674%\n",
      "Step:  1600\tLoss: 0.182\tAcc: 94.76744%\n",
      "Step:  1700\tLoss: 0.173\tAcc: 95.34883%\n",
      "Step:  1800\tLoss: 0.166\tAcc: 95.34883%\n",
      "Step:  1900\tLoss: 0.159\tAcc: 96.22093%\n",
      "Step:  2000\tLoss: 0.152\tAcc: 96.51163%\n",
      "Step:  2100\tLoss: 0.146\tAcc: 96.51163%\n",
      "Step:  2200\tLoss: 0.141\tAcc: 97.09302%\n",
      "Step:  2300\tLoss: 0.136\tAcc: 97.09302%\n",
      "Step:  2400\tLoss: 0.131\tAcc: 97.38372%\n",
      "Step:  2500\tLoss: 0.126\tAcc: 97.38372%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9738372\n",
      "Test Prediction = 0.87826085\n",
      "=========== RUN 126=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 8.267\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 1.963\tAcc: 57.55814%\n",
      "Step:   200\tLoss: 1.178\tAcc: 69.47674%\n",
      "Step:   300\tLoss: 0.822\tAcc: 74.41860%\n",
      "Step:   400\tLoss: 0.606\tAcc: 79.94186%\n",
      "Step:   500\tLoss: 0.456\tAcc: 85.46512%\n",
      "Step:   600\tLoss: 0.357\tAcc: 88.37209%\n",
      "Step:   700\tLoss: 0.294\tAcc: 89.82558%\n",
      "Step:   800\tLoss: 0.250\tAcc: 90.98837%\n",
      "Step:   900\tLoss: 0.219\tAcc: 93.31396%\n",
      "Step:  1000\tLoss: 0.195\tAcc: 94.18604%\n",
      "Step:  1100\tLoss: 0.175\tAcc: 95.05814%\n",
      "Step:  1200\tLoss: 0.160\tAcc: 95.34883%\n",
      "Step:  1300\tLoss: 0.147\tAcc: 95.63953%\n",
      "Step:  1400\tLoss: 0.136\tAcc: 96.22093%\n",
      "Step:  1500\tLoss: 0.127\tAcc: 97.67442%\n",
      "Step:  1600\tLoss: 0.118\tAcc: 97.67442%\n",
      "Step:  1700\tLoss: 0.112\tAcc: 97.96512%\n",
      "Step:  1800\tLoss: 0.106\tAcc: 97.96512%\n",
      "Step:  1900\tLoss: 0.101\tAcc: 98.25581%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  2000\tLoss: 0.097\tAcc: 98.25581%\n",
      "Step:  2100\tLoss: 0.094\tAcc: 98.25581%\n",
      "Step:  2200\tLoss: 0.091\tAcc: 98.25581%\n",
      "Step:  2300\tLoss: 0.088\tAcc: 98.54651%\n",
      "Step:  2400\tLoss: 0.085\tAcc: 98.54651%\n",
      "Step:  2500\tLoss: 0.083\tAcc: 98.54651%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9854651\n",
      "Test Prediction = 0.9\n",
      "=========== RUN 127=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 15.190\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 6.544\tAcc: 45.93023%\n",
      "Step:   200\tLoss: 2.461\tAcc: 50.00000%\n",
      "Step:   300\tLoss: 1.434\tAcc: 61.91860%\n",
      "Step:   400\tLoss: 0.888\tAcc: 68.60465%\n",
      "Step:   500\tLoss: 0.669\tAcc: 78.77907%\n",
      "Step:   600\tLoss: 0.549\tAcc: 83.43023%\n",
      "Step:   700\tLoss: 0.470\tAcc: 85.75581%\n",
      "Step:   800\tLoss: 0.411\tAcc: 88.08140%\n",
      "Step:   900\tLoss: 0.362\tAcc: 89.53488%\n",
      "Step:  1000\tLoss: 0.317\tAcc: 89.82558%\n",
      "Step:  1100\tLoss: 0.277\tAcc: 90.40698%\n",
      "Step:  1200\tLoss: 0.244\tAcc: 92.44186%\n",
      "Step:  1300\tLoss: 0.220\tAcc: 93.89535%\n",
      "Step:  1400\tLoss: 0.202\tAcc: 95.05814%\n",
      "Step:  1500\tLoss: 0.188\tAcc: 95.63953%\n",
      "Step:  1600\tLoss: 0.176\tAcc: 96.22093%\n",
      "Step:  1700\tLoss: 0.166\tAcc: 96.80232%\n",
      "Step:  1800\tLoss: 0.157\tAcc: 97.67442%\n",
      "Step:  1900\tLoss: 0.149\tAcc: 98.25581%\n",
      "Step:  2000\tLoss: 0.143\tAcc: 98.25581%\n",
      "Step:  2100\tLoss: 0.136\tAcc: 98.25581%\n",
      "Step:  2200\tLoss: 0.130\tAcc: 98.25581%\n",
      "Step:  2300\tLoss: 0.124\tAcc: 98.54651%\n",
      "Step:  2400\tLoss: 0.120\tAcc: 98.54651%\n",
      "Step:  2500\tLoss: 0.116\tAcc: 98.83721%\n",
      "Step:  2600\tLoss: 0.112\tAcc: 98.83721%\n",
      "Step:  2700\tLoss: 0.109\tAcc: 98.83721%\n",
      "Step:  2800\tLoss: 0.106\tAcc: 99.12791%\n",
      "Step:  2900\tLoss: 0.104\tAcc: 99.41860%\n",
      "Step:  3000\tLoss: 0.101\tAcc: 99.41860%\n",
      "Step:  3100\tLoss: 0.099\tAcc: 99.41860%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.99418604\n",
      "Test Prediction = 0.8304348\n",
      "=========== RUN 128=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 2.415\tAcc: 40.69767%\n",
      "Step:   100\tLoss: 0.988\tAcc: 69.47674%\n",
      "Step:   200\tLoss: 0.690\tAcc: 77.32558%\n",
      "Step:   300\tLoss: 0.535\tAcc: 82.26744%\n",
      "Step:   400\tLoss: 0.439\tAcc: 84.59302%\n",
      "Step:   500\tLoss: 0.371\tAcc: 88.08140%\n",
      "Step:   600\tLoss: 0.323\tAcc: 89.24419%\n",
      "Step:   700\tLoss: 0.287\tAcc: 90.40698%\n",
      "Step:   800\tLoss: 0.259\tAcc: 91.56977%\n",
      "Step:   900\tLoss: 0.238\tAcc: 92.44186%\n",
      "Step:  1000\tLoss: 0.221\tAcc: 93.60465%\n",
      "Step:  1100\tLoss: 0.207\tAcc: 93.89535%\n",
      "Step:  1200\tLoss: 0.196\tAcc: 95.05814%\n",
      "Step:  1300\tLoss: 0.185\tAcc: 95.05814%\n",
      "Step:  1400\tLoss: 0.176\tAcc: 95.34883%\n",
      "Step:  1500\tLoss: 0.168\tAcc: 95.63953%\n",
      "Step:  1600\tLoss: 0.161\tAcc: 95.93023%\n",
      "Step:  1700\tLoss: 0.155\tAcc: 95.93023%\n",
      "Step:  1800\tLoss: 0.149\tAcc: 96.51163%\n",
      "Step:  1900\tLoss: 0.143\tAcc: 96.51163%\n",
      "Step:  2000\tLoss: 0.138\tAcc: 96.80232%\n",
      "Step:  2100\tLoss: 0.132\tAcc: 97.09302%\n",
      "Step:  2200\tLoss: 0.127\tAcc: 97.38372%\n",
      "Step:  2300\tLoss: 0.122\tAcc: 97.67442%\n",
      "Step:  2400\tLoss: 0.118\tAcc: 97.67442%\n",
      "Step:  2500\tLoss: 0.114\tAcc: 97.96512%\n",
      "Step:  2600\tLoss: 0.110\tAcc: 98.25581%\n",
      "Step:  2700\tLoss: 0.106\tAcc: 98.25581%\n",
      "Step:  2800\tLoss: 0.103\tAcc: 98.25581%\n",
      "Step:  2900\tLoss: 0.100\tAcc: 98.54651%\n",
      "Step:  3000\tLoss: 0.097\tAcc: 98.54651%\n",
      "Step:  3100\tLoss: 0.094\tAcc: 98.54651%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9854651\n",
      "Test Prediction = 0.84347826\n",
      "=========== RUN 129=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 9.003\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 2.609\tAcc: 44.47674%\n",
      "Step:   200\tLoss: 1.136\tAcc: 60.46512%\n",
      "Step:   300\tLoss: 0.730\tAcc: 76.74419%\n",
      "Step:   400\tLoss: 0.568\tAcc: 81.10465%\n",
      "Step:   500\tLoss: 0.477\tAcc: 83.13953%\n",
      "Step:   600\tLoss: 0.415\tAcc: 84.01163%\n",
      "Step:   700\tLoss: 0.369\tAcc: 87.79070%\n",
      "Step:   800\tLoss: 0.334\tAcc: 88.66279%\n",
      "Step:   900\tLoss: 0.304\tAcc: 89.82558%\n",
      "Step:  1000\tLoss: 0.279\tAcc: 92.44186%\n",
      "Step:  1100\tLoss: 0.260\tAcc: 92.73256%\n",
      "Step:  1200\tLoss: 0.245\tAcc: 93.89535%\n",
      "Step:  1300\tLoss: 0.231\tAcc: 93.89535%\n",
      "Step:  1400\tLoss: 0.219\tAcc: 94.18604%\n",
      "Step:  1500\tLoss: 0.209\tAcc: 94.18604%\n",
      "Step:  1600\tLoss: 0.200\tAcc: 94.47674%\n",
      "Step:  1700\tLoss: 0.192\tAcc: 94.47674%\n",
      "Step:  1800\tLoss: 0.185\tAcc: 94.47674%\n",
      "Step:  1900\tLoss: 0.178\tAcc: 94.18604%\n",
      "Step:  2000\tLoss: 0.172\tAcc: 94.76744%\n",
      "Step:  2100\tLoss: 0.166\tAcc: 94.76744%\n",
      "Step:  2200\tLoss: 0.160\tAcc: 95.05814%\n",
      "Step:  2300\tLoss: 0.155\tAcc: 95.05814%\n",
      "Step:  2400\tLoss: 0.151\tAcc: 95.63953%\n",
      "Step:  2500\tLoss: 0.147\tAcc: 95.63953%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9563953\n",
      "Test Prediction = 0.84347826\n",
      "=========== RUN 130=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 15.289\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 6.510\tAcc: 47.67442%\n",
      "Step:   200\tLoss: 2.277\tAcc: 56.10465%\n",
      "Step:   300\tLoss: 1.206\tAcc: 66.27907%\n",
      "Step:   400\tLoss: 0.841\tAcc: 77.03488%\n",
      "Step:   500\tLoss: 0.612\tAcc: 79.65117%\n",
      "Step:   600\tLoss: 0.455\tAcc: 84.88372%\n",
      "Step:   700\tLoss: 0.350\tAcc: 87.79070%\n",
      "Step:   800\tLoss: 0.291\tAcc: 92.44186%\n",
      "Step:   900\tLoss: 0.245\tAcc: 93.31396%\n",
      "Step:  1000\tLoss: 0.209\tAcc: 93.89535%\n",
      "Step:  1100\tLoss: 0.181\tAcc: 94.76744%\n",
      "Step:  1200\tLoss: 0.159\tAcc: 95.34883%\n",
      "Step:  1300\tLoss: 0.143\tAcc: 96.80232%\n",
      "Step:  1400\tLoss: 0.131\tAcc: 97.96512%\n",
      "Step:  1500\tLoss: 0.121\tAcc: 98.25581%\n",
      "Step:  1600\tLoss: 0.113\tAcc: 98.25581%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.98255813\n",
      "Test Prediction = 0.8956522\n",
      "=========== RUN 131=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 2.554\tAcc: 54.36047%\n",
      "Step:   100\tLoss: 0.874\tAcc: 66.27907%\n",
      "Step:   200\tLoss: 0.600\tAcc: 77.03488%\n",
      "Step:   300\tLoss: 0.458\tAcc: 83.13953%\n",
      "Step:   400\tLoss: 0.377\tAcc: 86.04651%\n",
      "Step:   500\tLoss: 0.326\tAcc: 87.50000%\n",
      "Step:   600\tLoss: 0.290\tAcc: 89.24419%\n",
      "Step:   700\tLoss: 0.263\tAcc: 92.15117%\n",
      "Step:   800\tLoss: 0.241\tAcc: 93.02326%\n",
      "Step:   900\tLoss: 0.223\tAcc: 94.18604%\n",
      "Step:  1000\tLoss: 0.209\tAcc: 94.47674%\n",
      "Step:  1100\tLoss: 0.197\tAcc: 94.47674%\n",
      "Step:  1200\tLoss: 0.187\tAcc: 94.76744%\n",
      "Step:  1300\tLoss: 0.179\tAcc: 95.05814%\n",
      "Step:  1400\tLoss: 0.171\tAcc: 95.63953%\n",
      "Step:  1500\tLoss: 0.164\tAcc: 95.63953%\n",
      "Step:  1600\tLoss: 0.158\tAcc: 95.63953%\n",
      "Step:  1700\tLoss: 0.153\tAcc: 95.93023%\n",
      "Step:  1800\tLoss: 0.148\tAcc: 96.22093%\n",
      "Step:  1900\tLoss: 0.143\tAcc: 96.22093%\n",
      "Step:  2000\tLoss: 0.139\tAcc: 96.51163%\n",
      "Step:  2100\tLoss: 0.135\tAcc: 96.80232%\n",
      "Step:  2200\tLoss: 0.131\tAcc: 96.80232%\n",
      "Step:  2300\tLoss: 0.127\tAcc: 97.38372%\n",
      "Step:  2400\tLoss: 0.124\tAcc: 97.38372%\n",
      "Step:  2500\tLoss: 0.121\tAcc: 97.67442%\n",
      "Step:  2600\tLoss: 0.117\tAcc: 97.67442%\n",
      "Step:  2700\tLoss: 0.115\tAcc: 97.67442%\n",
      "Step:  2800\tLoss: 0.112\tAcc: 97.67442%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9767442\n",
      "Test Prediction = 0.87826085\n",
      "=========== RUN 132=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 5.840\tAcc: 45.93023%\n",
      "Step:   100\tLoss: 2.072\tAcc: 52.61628%\n",
      "Step:   200\tLoss: 1.099\tAcc: 64.82558%\n",
      "Step:   300\tLoss: 0.767\tAcc: 75.87209%\n",
      "Step:   400\tLoss: 0.595\tAcc: 81.68604%\n",
      "Step:   500\tLoss: 0.496\tAcc: 84.30232%\n",
      "Step:   600\tLoss: 0.432\tAcc: 86.04651%\n",
      "Step:   700\tLoss: 0.388\tAcc: 87.79070%\n",
      "Step:   800\tLoss: 0.354\tAcc: 89.24419%\n",
      "Step:   900\tLoss: 0.325\tAcc: 91.27907%\n",
      "Step:  1000\tLoss: 0.300\tAcc: 93.31396%\n",
      "Step:  1100\tLoss: 0.279\tAcc: 94.18604%\n",
      "Step:  1200\tLoss: 0.262\tAcc: 94.76744%\n",
      "Step:  1300\tLoss: 0.247\tAcc: 94.76744%\n",
      "Step:  1400\tLoss: 0.234\tAcc: 95.05814%\n",
      "Step:  1500\tLoss: 0.221\tAcc: 95.63953%\n",
      "Step:  1600\tLoss: 0.208\tAcc: 95.93023%\n",
      "Step:  1700\tLoss: 0.195\tAcc: 96.80232%\n",
      "Step:  1800\tLoss: 0.182\tAcc: 97.09302%\n",
      "Step:  1900\tLoss: 0.169\tAcc: 97.09302%\n",
      "Step:  2000\tLoss: 0.157\tAcc: 97.38372%\n",
      "Step:  2100\tLoss: 0.148\tAcc: 97.67442%\n",
      "Step:  2200\tLoss: 0.140\tAcc: 97.67442%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.9767442\n",
      "Test Prediction = 0.83913046\n",
      "=========== RUN 133=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 2.534\tAcc: 46.80233%\n",
      "Step:   100\tLoss: 1.017\tAcc: 70.34883%\n",
      "Step:   200\tLoss: 0.638\tAcc: 75.87209%\n",
      "Step:   300\tLoss: 0.476\tAcc: 81.10465%\n",
      "Step:   400\tLoss: 0.386\tAcc: 89.82558%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:   500\tLoss: 0.321\tAcc: 91.56977%\n",
      "Step:   600\tLoss: 0.277\tAcc: 93.31396%\n",
      "Step:   700\tLoss: 0.248\tAcc: 95.93023%\n",
      "Step:   800\tLoss: 0.224\tAcc: 96.22093%\n",
      "Step:   900\tLoss: 0.205\tAcc: 96.80232%\n",
      "Step:  1000\tLoss: 0.189\tAcc: 97.09302%\n",
      "Step:  1100\tLoss: 0.175\tAcc: 97.38372%\n",
      "Step:  1200\tLoss: 0.161\tAcc: 97.96512%\n",
      "Step:  1300\tLoss: 0.149\tAcc: 97.96512%\n",
      "Step:  1400\tLoss: 0.138\tAcc: 98.54651%\n",
      "Step:  1500\tLoss: 0.127\tAcc: 98.83721%\n",
      "Step:  1600\tLoss: 0.118\tAcc: 99.12791%\n",
      "Step:  1700\tLoss: 0.110\tAcc: 99.41860%\n",
      "Step:  1800\tLoss: 0.102\tAcc: 99.41860%\n",
      "Step:  1900\tLoss: 0.094\tAcc: 99.41860%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.99418604\n",
      "Test Prediction = 0.84347826\n",
      "=========== RUN 134=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 11.904\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 4.702\tAcc: 47.38372%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.45930234\n",
      "Test Prediction = 0.44347826\n",
      "=========== RUN 135=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 13.449\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 6.874\tAcc: 47.67442%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.45930234\n",
      "Test Prediction = 0.45217392\n",
      "=========== RUN 136=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 9.803\tAcc: 47.67442%\n",
      "Step:   100\tLoss: 3.117\tAcc: 50.29070%\n",
      "Step:   200\tLoss: 1.156\tAcc: 64.82558%\n",
      "Step:   300\tLoss: 0.817\tAcc: 74.41860%\n",
      "Step:   400\tLoss: 0.656\tAcc: 82.26744%\n",
      "Step:   500\tLoss: 0.554\tAcc: 84.30232%\n",
      "Step:   600\tLoss: 0.485\tAcc: 85.75581%\n",
      "Step:   700\tLoss: 0.434\tAcc: 88.66279%\n",
      "Step:   800\tLoss: 0.393\tAcc: 89.53488%\n",
      "Step:   900\tLoss: 0.359\tAcc: 89.82558%\n",
      "Step:  1000\tLoss: 0.329\tAcc: 90.40698%\n",
      "Step:  1100\tLoss: 0.303\tAcc: 90.69768%\n",
      "Step:  1200\tLoss: 0.280\tAcc: 90.69768%\n",
      "Step:  1300\tLoss: 0.261\tAcc: 91.86047%\n",
      "Step:  1400\tLoss: 0.243\tAcc: 92.15117%\n",
      "Step:  1500\tLoss: 0.226\tAcc: 92.15117%\n",
      "Step:  1600\tLoss: 0.212\tAcc: 92.44186%\n",
      "Step:  1700\tLoss: 0.197\tAcc: 92.73256%\n",
      "Step:  1800\tLoss: 0.187\tAcc: 93.31396%\n",
      "Step:  1900\tLoss: 0.178\tAcc: 93.89535%\n",
      "Step:  2000\tLoss: 0.170\tAcc: 93.89535%\n",
      "Step:  2100\tLoss: 0.163\tAcc: 94.47674%\n",
      "Step:  2200\tLoss: 0.157\tAcc: 94.76744%\n",
      "Step:  2300\tLoss: 0.151\tAcc: 95.05814%\n",
      "Step:  2400\tLoss: 0.146\tAcc: 95.34883%\n",
      "Step:  2500\tLoss: 0.141\tAcc: 95.63953%\n",
      "Step:  2600\tLoss: 0.137\tAcc: 95.63953%\n",
      "Step:  2700\tLoss: 0.133\tAcc: 95.93023%\n",
      "Step:  2800\tLoss: 0.129\tAcc: 95.93023%\n",
      "Step:  2900\tLoss: 0.125\tAcc: 97.38372%\n",
      "Step:  3000\tLoss: 0.121\tAcc: 97.38372%\n",
      "Step:  3100\tLoss: 0.118\tAcc: 97.38372%\n",
      "Step:  3200\tLoss: 0.115\tAcc: 97.67442%\n",
      "Step:  3300\tLoss: 0.113\tAcc: 97.67442%\n",
      "Step:  3400\tLoss: 0.110\tAcc: 97.96512%\n",
      "Step:  3500\tLoss: 0.108\tAcc: 97.96512%\n",
      "Step:  3600\tLoss: 0.105\tAcc: 97.96512%\n",
      "Step:  3700\tLoss: 0.103\tAcc: 97.96512%\n",
      "Step:  3800\tLoss: 0.101\tAcc: 98.83721%\n",
      "Step:  3900\tLoss: 0.099\tAcc: 99.12791%\n",
      "Step:  4000\tLoss: 0.097\tAcc: 99.12791%\n",
      "======== EARLY STOP =========\n",
      "\n",
      "============Results============\n",
      "Model Prediction = 0.99127907\n",
      "Test Prediction = 0.8608696\n",
      "=========== RUN 137=================================================\n",
      "\n",
      "============Processing============\n",
      "Step:     0\tLoss: 9.752\tAcc: 52.32558%\n",
      "Step:   100\tLoss: 0.829\tAcc: 66.27907%\n",
      "Step:   200\tLoss: 0.561\tAcc: 81.10465%\n",
      "Step:   300\tLoss: 0.428\tAcc: 83.43023%\n",
      "Step:   400\tLoss: 0.366\tAcc: 85.46512%\n",
      "Step:   500\tLoss: 0.314\tAcc: 86.91860%\n",
      "Step:   600\tLoss: 0.279\tAcc: 89.24419%\n",
      "Step:   700\tLoss: 0.255\tAcc: 90.98837%\n",
      "Step:   800\tLoss: 0.237\tAcc: 91.56977%\n",
      "Step:   900\tLoss: 0.223\tAcc: 92.44186%\n",
      "Step:  1000\tLoss: 0.210\tAcc: 92.73256%\n",
      "Step:  1100\tLoss: 0.198\tAcc: 93.31396%\n",
      "Step:  1200\tLoss: 0.187\tAcc: 93.89535%\n",
      "Step:  1300\tLoss: 0.176\tAcc: 93.89535%\n",
      "Step:  1400\tLoss: 0.167\tAcc: 94.18604%\n",
      "Step:  1500\tLoss: 0.157\tAcc: 94.47674%\n",
      "Step:  1600\tLoss: 0.149\tAcc: 95.34883%\n",
      "Step:  1700\tLoss: 0.142\tAcc: 95.63953%\n",
      "Step:  1800\tLoss: 0.135\tAcc: 95.93023%\n",
      "Step:  1900\tLoss: 0.129\tAcc: 96.22093%\n",
      "Step:  2000\tLoss: 0.123\tAcc: 96.22093%\n",
      "Step:  2100\tLoss: 0.117\tAcc: 96.51163%\n"
     ]
    }
   ],
   "source": [
    "print(\"===========Data Summary===========\")\n",
    "print(\"Training Data :\", X_train.shape)\n",
    "print(\"Testing Data :\", X_test.shape)\n",
    "\n",
    "acc_for_mean = []\n",
    "accur = []\n",
    "\n",
    "node1 = 600\n",
    "node2 = 300\n",
    "node3 = 300\n",
    "\n",
    "for i in range(150):\n",
    "    my_seed = random.randint(0, 12000)\n",
    "    stop = []\n",
    "    print(\"=========== RUN \" + str(i) + \"=================================================\")\n",
    "    X = tf.placeholder(tf.float32, [None, 1587])\n",
    "    Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "    #INPUT\n",
    "    W1 = tf.Variable(tf.random_normal([1587,node1], seed=my_seed), name='weight1')\n",
    "    b1 = tf.Variable(tf.random_normal([node1], seed=my_seed), name='bias1')\n",
    "    layer1 = tf.nn.sigmoid(tf.matmul(X,W1) + b1)\n",
    "\n",
    "    #HIDDEN 1\n",
    "    W2 = tf.Variable(tf.random_normal([node1,node2], seed=my_seed), name='weight2')\n",
    "    b2 = tf.Variable(tf.random_normal([node2], seed=my_seed), name='bias2')\n",
    "    layer2 = tf.nn.sigmoid(tf.matmul(layer1,W2) + b2)\n",
    "\n",
    "    #HIDDEN 2\n",
    "    W3 = tf.Variable(tf.random_normal([node2,node3], seed=my_seed), name='weight3')\n",
    "    b3 = tf.Variable(tf.random_normal([node3], seed=my_seed), name='bias3')\n",
    "    layer3 = tf.nn.sigmoid(tf.matmul(layer2,W3) + b3)\n",
    "\n",
    "    # output\n",
    "    W4 = tf.Variable(tf.random_normal([node3,1], seed=my_seed), name='weight4')\n",
    "    b4 = tf.Variable(tf.random_normal([1], seed=my_seed), name='bias4')\n",
    "\n",
    "    logits = tf.matmul(layer3,W4) + b4\n",
    "    hypothesis = tf.nn.sigmoid(logits)\n",
    "\n",
    "\n",
    "    cost_i = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=Y)\n",
    "    cost = tf.reduce_mean(cost_i)\n",
    "\n",
    "    train = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "    prediction = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "    correct_prediction = tf.equal(prediction, Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, dtype=tf.float32))\n",
    "\n",
    "    print(\"\\n============Processing============\")\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for step in range(500001):\n",
    "            sess.run(train, feed_dict={X: X_train, Y: y_train})\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={X: X_train, Y: y_train})\n",
    "            \n",
    "            if acc >= 100.0:\n",
    "                print('======== EARLY STOP 100 ============================================')\n",
    "                break\n",
    "                \n",
    "            if step % 100 == 0:\n",
    "                #loss, acc = sess.run([cost, accuracy], feed_dict={X: X_train, Y: y_train})\n",
    "                stop.append(acc)\n",
    "                if len(stop) == 3:\n",
    "                    if stop[1] + 0.00005 >= stop[2] and stop[1] - 0.00005 <= stop[0]:\n",
    "                        print('======== EARLY STOP =========')\n",
    "                        break\n",
    "                    else:\n",
    "                        stop = []\n",
    "\n",
    "                print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.5%}\".format(step, loss, acc))\n",
    "\n",
    "        train_acc = sess.run(accuracy, feed_dict={X: X_train, Y: y_train})\n",
    "        test_acc,test_predict,test_correct = sess.run([accuracy,prediction,correct_prediction], feed_dict={X: X_test, Y: y_test})\n",
    "\n",
    "        tupla = (train_acc*100, my_seed)\n",
    "        acc_for_mean.append(train_acc*100)\n",
    "        accur.append(tupla)\n",
    "        print(\"\\n============Results============\")\n",
    "        print(\"Model Prediction =\", train_acc)\n",
    "        print(\"Test Prediction =\", test_acc)\n",
    "\n",
    "print(\"\\n============Final Results============\")\n",
    "print(\"Best Model Prediction + Seed = \", max(accur))\n",
    "print(\"Worst Model Prediction + Seed = \", min(accur))\n",
    "print(\"Mean Model Prediction = \", np.mean(acc_for_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd2635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from twilio.rest import Client\n",
    "account_sid = \"ACe35044b0ba4a92ba23a03dfbc8de17e8\"\n",
    "auth_token = \"8637923fb32f1600af9eac9aadb017dd\"\n",
    "\n",
    "client = Client(account_sid, auth_token)\n",
    "\n",
    "from_whatsapp_number = \"+19705427800\"\n",
    "to_whatsapp_number = \"+5586994952240\"\n",
    "\n",
    "client.messages.create(\n",
    "    body=\"Best Model Prediction = \" + str(max(accur)) + \"\\n\"\n",
    "         + \"Worst Model Prediction = \" + str(min(accur)) + \"\\n\"\n",
    "         + \"Mean Model Prediction = \" + str(np.mean(acc_for_mean)) + \"\\n\",\n",
    "    from_= from_whatsapp_number,\n",
    "    to= to_whatsapp_number\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a055dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Cópia de Preprocesso_dados_IC_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
